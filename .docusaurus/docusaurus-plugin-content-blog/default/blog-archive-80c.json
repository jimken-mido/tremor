{
  "blogPosts": [
    {
      "id": "/2022/09/24/LFX-Blog-Carol",
      "metadata": {
        "permalink": "/blog/2022/09/24/LFX-Blog-Carol",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-09-24-LFX-Blog-Carol.md",
        "source": "@site/blog/2022-09-24-LFX-Blog-Carol.md",
        "title": "Hygienic error handling and validation for pipelines",
        "description": "Carol’s Tremor Mentorship Report",
        "date": "2022-09-24T00:00:00.000Z",
        "formattedDate": "September 24, 2022",
        "tags": [
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          }
        ],
        "readingTime": 6.43,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Carol Geng",
            "title": "Tremor 2022 Summer Mentee",
            "url": "https://www.linkedin.com/in/carolgeng/"
          }
        ],
        "frontMatter": {
          "Title": "Hygienic error handling and validation for pipelines",
          "author": "Carol Geng",
          "author_title": "Tremor 2022 Summer Mentee",
          "author_url": "https://www.linkedin.com/in/carolgeng/",
          "tags": [
            "cncf",
            "mentorship"
          ],
          "draft": false,
          "description": "Carol’s Tremor Mentorship Report"
        },
        "nextItem": {
          "title": "Support for the ClickHouse database in Tremor",
          "permalink": "/blog/2022/07/07/LFX-Blog-Sasha"
        }
      },
      "content": "## Introduction\n\nHello, my name's Carol Geng, a current sophomore pursuing a Bachelor's degree in Computer Science at Texas A&M University. Over Summer 2022, I have contributed to Tremor as part of the LFX Mentorship Program with my mentors Heinz Gies and Matthias Wahl, and this blog will show how valuable and enjoyable the experience was.\n\n# About the Project \n\nTremor is an event processing engine that uses pipelines and connectors for data to be passed through. However, errors could be made by the user when linking the ports of the pipelines, and those errors are not easily displayed to the user. There were cases where the location of the error wasn’t printed, nothing was printed at all, or even cases where the program would work as if everything was all fine. My mentorship project was focused on creating the messages that would be displayed to the user in a clear and concise manner through the console.\n\n# The Mentorship Journey\n\nBefore this mentorship, I had only worked in open-source a few times on projects and had no knowledge of how to code in Rust. This mentorship therefore allowed me to build on what I already knew while also giving me an opportunity to learn a new language. Throughout this mentorship, I was able to get a start in DevOps and learn how to work on the compiler and source code for a software program while contributing to the user experience of everyone who uses Tremor and whoever will use Tremor in the future.\n\n## Starting Tremor\n\nTo learn how to contribute to Tremor’s source code, I had to first understand how Tremor worked and what it did. I was introduced to pipelines, ports, and scripts and was allowed to mess around with the code. Tremor’s code allowed the user to go into several commands to process and change the input into the desired output. Through playing around with Tremor, I decided to add a function to reverse a string with Tremor’s pipelines. Because tremor did not have a built-in reverse string function, I went into the source code to implement a reverse function in Rust along with several tests and documentation for the reverse function. This relatively simple function is where I made my first pull request and also where I first started getting familiar with Tremor.\n\nAdditionally, I had used other programming languages in my academic career, and therefore did not have any experience with Rust beforehand. This is when I got introduced to Rustlings, which had small exercises to help me with starting with Rust syntax and writing code in Rust. There were also a lot of functions unique to Rust in terms of how the code worked, which included enums, move semantics, and structs. This also included constructs like `Ok()` and concepts like async/await which I would end up utilizing in my project.\n\n## Understanding Code\n\nA large portion of my mentorship focused on understanding the errors that were printed out. There were several different kinds of errors, such as ones that dealt with the console input, console output, pipeline input, and more, which validated whether the input or output existed in the code and where it led to, another connector or the console. While this may seem simple, this ended up leading me into the rabbit hole of the source code as I traversed through numerous files and functions to determine where the error went through and what I could do to the preexisting code to read and perform functions onto the error.\n\nTo do a lot of this, I learned the process of error logging. I defined each error there in great detail, such as what it is, what it does currently, what it’s supposed to do, and gradually updated it every time it was needed. Throughout implementing messages to these errors, I also learned more about version control with git. While I did have practice on the basics like git pull and git push, I also learned about git rebase, git merge, and more.\n\n## Error Handling\n\nError handling was the main focus of the project. As my mentor suggested, I focused on one error at a time from the error logs. First, I focused on the worst case- a case where nothing was printed and the program ran as if everything was normal, except there was no output. \n\n###### pipeline_out_error.troy\n```\n# Our main flow\ndefine flow main\nflow\n  # import the `tremor::connectors` module\n  use tremor::connectors;\n  use lib::pipelines;\n\n  # create an instance of the console connector\n  create connector console from connectors::console;\n\n  # create an instance of the passthrough pipeline\n  create pipeline main from pipelines::main;\n\n  # connect the console (STDIN) to our pipeline input\n  connect /connector/console/out to /pipeline/main;\n\n  # then connect the pipeline output to the console (STDOUT)\n\n  # no doesn't exist, bad error\n  connect /pipeline/main/no to /connector/console/in;\n\nend;\n# Deploy the flow so tremor starts it\ndeploy flow main;\n```\n\nThis error focused on the fact that the output did not exist, so to fix the error, I wrote a separate function that checked whether the output existed, then connected it to the `ConnectInput` structs while sending an error statement and a status report to the system. This process introduced me to focusing on small incremental steps rather than solving the problem as a whole and allowed me to not get overwhelmed. Additionally, `outputs` had to be added to the `Executable Graph` struct, which led me to implementing outputs in related functions and building a hashmap for the representation of its graph. With that, the basic problem of catching the errors was solved for that error problem.\n\nAfter that led to defining what the error was, which involved adding a `port` struct to both `ConnectInput` and `ConnectOutput` to connect inputs. This port struct wasn’t needed before but with changes that were made later on, `port` proved to be very useful in defining what the port was to be able to be used in other code. Because this field was added to the struct, changes then had to be made to all the functions that used this struct and a port had to be defined in those functions.\n\nLast was implementing where the code was to the user. This focused heavily on adding transmitters and receivers to output the status and mapping the status when the user’s code had errors. The transmitters and receivers, `tx` and `rx` had to be added to the `ConnectInput` and `ConnectOutput` structs, then weaved together with the other types of code to be defined and used. This involved many functions to be modified in order to return a result. In this process, there were also bugs to be fixed in the preexisting code and tests that had to be corrected in order to make sure `tx` and `rx` were properly working. Afterwards, [`Result::map_err`](https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err) was used in order to map out the results with its parameters through `rx` if a user inputted errors.\n\nThroughout the programming, I had to search for the files to determine where the code was and what function utilized the next function. This led me to search into files to see where the error travels through and trace where the error goes as I searched through the declarations, definitions, and references of variables and functions. I also got to learn several handy keyboard shortcuts throughout this process as demonstrated from my mentor.\n\n# Conclusion\n\nOverall, working with Tremor was extremely fun and valuable as I not only got to contribute to an incredible project, but also got to learn more about programming and the open-source world.  I was able to while meeting amazing people to guide me with my work, and I can not imagine it to be any other way."
    },
    {
      "id": "/2022/07/07/LFX-Blog-Sasha",
      "metadata": {
        "permalink": "/blog/2022/07/07/LFX-Blog-Sasha",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-07-07-LFX-Blog-Sasha.md",
        "source": "@site/blog/2022-07-07-LFX-Blog-Sasha.md",
        "title": "Support for the ClickHouse database in Tremor",
        "description": "Sasha's Mentorship experience",
        "date": "2022-07-07T00:00:00.000Z",
        "formattedDate": "July 7, 2022",
        "tags": [
          {
            "label": "Database",
            "permalink": "/blog/tags/database"
          },
          {
            "label": "ClickHouse",
            "permalink": "/blog/tags/click-house"
          }
        ],
        "readingTime": 5.215,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Sasha Pourcelot",
            "title": "Tremor 2022 Spring Mentee",
            "url": "https://github.com/scrabsha/"
          }
        ],
        "frontMatter": {
          "title": "Support for the ClickHouse database in Tremor",
          "author": "Sasha Pourcelot",
          "author_title": "Tremor 2022 Spring Mentee",
          "author_url": "https://github.com/scrabsha/",
          "tags": [
            "Database",
            "ClickHouse"
          ],
          "draft": false,
          "description": "Sasha's Mentorship experience"
        },
        "prevItem": {
          "title": "Hygienic error handling and validation for pipelines",
          "permalink": "/blog/2022/09/24/LFX-Blog-Carol"
        },
        "nextItem": {
          "title": "TDengine colaboration",
          "permalink": "/blog/2022/06/15/tdengine-colaboration"
        }
      },
      "content": "I'm Sasha, a Computer Science student living in south-eastern France. I contributed to Tremor as part of the [Database Connector mentorship][dcm] proposed by the [LFX Mentorship Program][lfx] for Spring 2022. I was mentored by Matthias Wahl and got help from Darach Ennis, Heinz Gies and Ramona Łuczkiewicz.\n\n[dcm]: https://mentorship.lfx.linuxfoundation.org/project/5c828028-f91c-4969-b4de-9efdb27bb869\n[lfx]: https://lfx.linuxfoundation.org/tools/mentorship/\n\nThis blogpost summarizes my work at Tremor as a mentee and shows what could be done next.\n\n\n# About Tremor\n\nTremor is an event processing system with the goal of allowing users to handle a high volume of messages by viewing them as a stream flowing between different nodes of a graph. Events go in and out of this graph thanks to connectors.\n\nThe interactions between each node and the connector configuration are defined using the [`troy`] programming language.\n\n[`troy`]: https://www.tremor.rs/docs/edge/language/\n\n\n# Abstract\n\nMy mentorship at Tremor was focused on building a connector for the [ClickHouse] database engine. More specifically, I was focused on the *sink* part, the one that allows data to flow out of the Tremor application.\n\n[ClickHouse] is a database management system designed to allow for real-time analysis of high volumes of non-aggregated data. Its initial goal was to power the Yandex.Metrica analytics platform.\n\n[ClickHouse]: https://clickhouse.com/\n\n\n# The ClickHouse connector\n\nThe next subsections describe what I did during the mentorship.\n\n\n## Interacting with a ClickHouse database in Rust\n\nMy first goal was to find a way to send requests to a ClickHouse node from a Rust program. It was a good start because it allowed me to experiment on the ClickHouse side without caring about what was happening in Tremor. I spent around three weeks playing on a separate repository named [`scrabsha/plays-with-clickhouse`] and getting extensive knowledge from Matthias about how Tremor works from the inside.\n\n[`scrabsha/plays-with-clickhouse`]: https://github.com/scrabsha/plays-with-clickhouse\n\nI found two Rust crates that could help us send requests to a ClickHouse database: [`clickhouse`] and [`clickhouse-rs`]. `clickhouse` is the first one I considered. I had to discard it because it was focused on concrete Rust types and needed to know *at compile time* what each datatype is composed of. The second crate was a bit more low-level and allowed us to do what we need.\n\n[`clickhouse`]: https://crates.io/crates/clickhouse\n[`clickhouse-rs`]: https://crates.io/crates/clickhouse-rs\n\n\n## Writing a super simple sink\n\nOnce I got every ClickHouse detail right, I started playing with the Tremor side. There were multiple connectors already implemented in Tremor. I picked the simplest ones and started copying parts of it and quickly got something working.\n\nThe only challenge I encountered is that Tremor defines its own `Value` type, representing a value whose type is not really known at compile time, and uses it *a lot*. It was a bit disconcerting doing such things in Rust, as I felt I was writing dynamically-typed code in a statically-typed language, but I managed to get through it.\n\n\n## Converting Tremor values to ClickHouse values\n\nOnce I was able to insert data in a database from Tremor, I started writing a conversion bridge for ClickHouse types, i.e. something that would handle the conversion of native Tremor values to their corresponding ClickHouse types. \n\nMost of the conversions are quite simple: an integer can be obtained from an integer, a string can be obtained from any string, and so on.\n\nSome other conversions were less obvious. For instance, in order to create a ClickHouse IPv4 type, we could either use a string representing the address, or an array of four integers. The goal was to make every ClickHouse type constructible from a Tremor value. I tried to make every conversion as obvious as possible, and to document them as much as possible.\n\nThe first implementation of this mapping function was huge. It was about 250 lines of tricky and slightly incorrect code. I managed to rewrite it from scratch using another approach and it got way better.\n\nWorking on this specific part led me to open three pull request to the `clickhouse-rs` crate:\n  - [Make Value fully constructible (#171)][#171]\n  - [Compare IP adresses properly (#172)][#172]\n  - [Allow for Enum8 and DateTime64 value comparison (#173)][#173]\n\n[#171]: https://github.com/suharev7/clickhouse-rs/pull/171\n[#172]: https://github.com/suharev7/clickhouse-rs/pull/172\n[#173]: https://github.com/suharev7/clickhouse-rs/pull/173\n\n\n\n## Testing\n\nThe conversion function described in the previous subsection was fairly complex. Each possible conversion and cast has been carefully tested in order to ensure that it behaves correctly. These tests were greatly simplified thanks to the use of declarative macro.\n\nSome other tests were focused on testing the sink as a whole, and how it would interact with a ClickHouse database. In this kind of test, we would run ClickHouse Docker containers, create a ClickHouse sink, plug the sink to the container, send some events, and see what has been inserted in the ClickHouse side.\n\n\n# What to do next?\n\n\n## Improving the sink\n\n### Automatically getting the table schema\n\nIt turns out that ClickHouse has a [`DESCRIBE TABLE` statement][describe-table], which allows to gather information about each column of a specific table. We currently rely on the end-user to provide us valid information about the table columns. Using this statement would reduce the amount of information we require from them, hence making it simpler to use.\n\n[describe-table]: https://clickhouse.com/docs/en/sql-reference/statements/describe-table\n\n### Inserting data concurrently\n\nThe current implementation of the ClickHouse container uses a single database connection object, which is reused across insertions. A good way to improve this system is to use multiple concurrent connections, so that we could insert multiple batch of events at once.\n\nA similar pattern has already been implemented in Tremor as part of the [`elastic`] connector. As such, most of the required machinery is already there.\n\n[`elastic`]: https://www.tremor.rs/docs/edge/reference/connectors/elastic\n\n## The source part\n\nThis mentorship was focused on building a sink for ClickHouse. The next step could be to add a source connector, so that coming from a ClickHouse database can be ingested directly into a Tremor application.\n\nClickHouse has a feature allowing to watch for updates in a given table. This way, we can simulate a stream of data, and make it flow in the Tremor system. Each time some data is inserted in the table, we can retrieve it, convert it into Tremor value and make it flow into the graph of nodes described earlier.\n\nThis is something that we totally want to see in Tremor in the future. We can't wait for the [`WATCH` statement][watch] to be considered stable.\n\n[watch]: https://clickhouse.com/docs/en/sql-reference/statements/watch/"
    },
    {
      "id": "/2022/06/15/tdengine-colaboration",
      "metadata": {
        "permalink": "/blog/2022/06/15/tdengine-colaboration",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-06-15-tdengine-colaboration.md",
        "source": "@site/blog/2022-06-15-tdengine-colaboration.md",
        "title": "TDengine colaboration",
        "description": "The best aspect of open source software is collaboration, not only of systems but of the people involved. It is wonderful to see them come together to take multiple parts to build something bigger out of them.",
        "date": "2022-06-15T00:00:00.000Z",
        "formattedDate": "June 15, 2022",
        "tags": [
          {
            "label": "collaboration",
            "permalink": "/blog/tags/collaboration"
          },
          {
            "label": "tdengine",
            "permalink": "/blog/tags/tdengine"
          }
        ],
        "readingTime": 1.83,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "TDengine colaboration",
          "tags": [
            "collaboration",
            "tdengine"
          ],
          "author": "Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Support for the ClickHouse database in Tremor",
          "permalink": "/blog/2022/07/07/LFX-Blog-Sasha"
        },
        "nextItem": {
          "title": "Automating the tremor release process",
          "permalink": "/blog/2022/06/03/LFX-Blog-Prashant"
        }
      },
      "content": "The best aspect of open source software is collaboration, not only of systems but of the people involved. It is wonderful to see them come together to take multiple parts to build something bigger out of them.\n\nIn this spirit, we had the chance to collaborate on a little project with the crew from [TDengine](https://tdengine.com/). For those that don’t know them yet, TDengine is an exciting new time-series database focusing on scalability, performance, and using SQL as a way to interact. Better yet using the [adapter](https://docs.tdengine.com/reference/taosadapter) allows using a number of protocols including the Influx Line Protocol.\n\nThis does compliment tremor extremely well, as what we build can be described as an event processing engine focusing on performance and usability, using SQL as a way to manipulate data. I’m pretty sure you can already see how those two pieces fit together.\n\nBut, we don’t want to go much into the technical details here the post over at the [TDengine blog](https://tdengine.com/2022/06/14/6434.html) does a wonderful job at that.\n\nWorking with Shuduo on this was a lot of fun, it was a fascinating forth and back of ideas and possible improvements. The integration was super painless with both systems supporting the same protocols, and it was really great to learn some tricks from the experts, like how queries work best in TDengine.\n\nThe most interesting part of this is however that both systems not only create the proverbial, larger sum than their parts are but also grow in the process.\n\nAnd the speed the folks at TDengine do that is amazing, during the time of the collaboration, they not only released [an official grafana data source](https://grafana.com/grafana/plugins/tdengine-datasource/), released a [new version of TDengine itself](https://github.com/taosdata/TDengine/releases/tag/ver-2.6.0.1), but also created and published a [grafana dashboard](https://grafana.com/grafana/dashboards/16388) for system monitoring that made it extremely easy to add this.\n\nFor tremor we have discovered that we’re really starting to miss sliding windows, they have been on the roadmap for a while, but never with any direct requirement other than “it would be nice to have them”. While talking about real-time alerting, sliding windows have significant advantages over tumbling windows, so this collaboration revived that discussion - which means we’ll hopefully add them sooner rather than later."
    },
    {
      "id": "/2022/06/03/LFX-Blog-Prashant",
      "metadata": {
        "permalink": "/blog/2022/06/03/LFX-Blog-Prashant",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-06-03-LFX-Blog-Prashant.md",
        "source": "@site/blog/2022-06-03-LFX-Blog-Prashant.md",
        "title": "Automating the tremor release process",
        "description": "Prashant's Mentorship experience",
        "date": "2022-06-03T00:00:00.000Z",
        "formattedDate": "June 3, 2022",
        "tags": [
          {
            "label": "DevOps",
            "permalink": "/blog/tags/dev-ops"
          },
          {
            "label": "CI",
            "permalink": "/blog/tags/ci"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          },
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          }
        ],
        "readingTime": 4.035,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Prashant",
            "title": "Tremor 2022 Spring Mentee",
            "url": "https://www.linkedin.com/in/prashantpm20/"
          }
        ],
        "frontMatter": {
          "title": "Automating the tremor release process",
          "author": "Prashant",
          "author_title": "Tremor 2022 Spring Mentee",
          "author_url": "https://www.linkedin.com/in/prashantpm20/",
          "tags": [
            "DevOps",
            "CI",
            "mentorship",
            "cncf"
          ],
          "draft": false,
          "description": "Prashant's Mentorship experience"
        },
        "prevItem": {
          "title": "TDengine colaboration",
          "permalink": "/blog/2022/06/15/tdengine-colaboration"
        },
        "nextItem": {
          "title": "Tremors - May '22",
          "permalink": "/blog/2022/06/02/tremor-tremors"
        }
      },
      "content": "It was a pleasant night. I was waiting for LFX to send acceptance/rejection e-mails. And there it was, `\"Congratulations! You were accepted to CNCF - Tremor\"` . It was a great and exciting feeling to start this journey! And here I am, at the end of it, writing this blog. It was wonderful, everything that I expected it to be, and even more so in the 3 months! I am writing this blog about my experience in this mentorship.\n\n## Introduction\n\nMy name's Prashant (Also known as Pimmy on the internet), a 2nd-year university student pursuing my Bachelor's degree in Information Technology. This blog will talk about my project experience in contributing to [Tremor](https://www.tremor.rs) as part of LFX Mentorship Program Spring 2022.\n\n## The Problem\n\nWe all hate manual tasks, don't we? No seriously if anyone loves doing things on their own, it's totally fine. Of course not everything can be automated. But in this case, it was something more tedious. Here's a flowchart for basic explanation: \n\n![Flow](https://user-images.githubusercontent.com/23097199/171433037-99f4d443-7b84-4dc0-b026-972831108889.png)\n\nThis is how it was done, but manually. Each process had to be checked by someone to ensure a smooth sailing. It was quite the work, and so making a release candidate was never easy.\n\n## The Approach\n\nThe first thing was to divide the tasks into smaller sections and work on this. As my mentors at tremor always used to say, make notes! Keep documenting stuff, really helps. These notes helped me divide the tasks of the current CI process into individual sets of goal, and then I started working on it. \n\nNow I did have to test *a lot*, 400+ workflows just to get this finally done. So I will explain how the release process works. \n\n### Drafting the release\n\n1. We select which version we want to release, as shown in the code snippet taken from github actions workflow yaml file.\n\n```yaml\non:\n  workflow_dispatch:\n    inputs:\n      new-version:\n        type: choice\n        description: \"Which version you'd like to release?\"\n        options:\n        - major (_.X.X)\n        - minor (X._.X)\n        - patch (X.X._)\n        - rc (X.X.X-rc)\n        - release (removes rc)\n        required: true\n```\n2. Extract the version input (we want major, minor, patch, etc without the brackets), and bumping cargo packages, as shown below. As you can see I extracted the old version before the bump, and put it into `$GITHUB_ENV` , which is creating env variables with these values. Similarly done for new version after the bump. They are needed for creating the PR. \n\n```yaml\n      - name: Extracting version from input\n        run: |\n          VERSION=$(echo \"${{github.event.inputs.new-version}}\" | sed 's/ (.*)$//')\n          echo \"VER=$VERSION\" >> $GITHUB_ENV\n      - name: Bump new version in TOML files\n        run: |\n          OLD_VERSION=$(cargo pkgid | cut -d# -f2 | cut -d: -f2)\n          echo \"OLD=$OLD_VERSION\" >> $GITHUB_ENV\n          cargo set-version --workspace --bump ${{ env.VER }}\n          NEW_VERSION=$(cargo pkgid | cut -d# -f2 | cut -d: -f2)\n          echo \"NEW=$NEW_VERSION\" >> $GITHUB_ENV   \n```\n3. Commit, push, and Pull Request is created automatically with `Release` tag for the release. From there, the maintainers will do all the necessary reviews, and merge once the CI passes.\n\n### Publishing Release\n\n- So, the Draft Release pull request is merged, great! It automatically triggers the release workflow, which by the way only works if the PR has the `Release` tag, and ignores all other. This is achieved using the conditional statement:\n\n```yaml\n if: github.event.pull_request.merged && contains( github.event.pull_request.labels.*.name, 'Release')\n```\n\n- Changelog is automatically extracted using this [great workflow action](https://github.com/ffurrer2/extract-release-notes), and the release is made.\n\n```yaml\n      - name: Extract release notes\n        id: extract-release-notes\n        uses: ffurrer2/extract-release-notes@v1\n      - name: Create release\n        uses: actions/create-release@v1\n```\n\n- To trigger the publish crates workflow, I used this [workflow dispatch action](https://github.com/benc-uk/workflow-dispatch) as shown below:\n\n```yaml\n      - name: Trigger publish crates workflow\n        uses: benc-uk/workflow-dispatch@v1\n        with:\n          workflow: Publish crates\n          token: ${{ secrets.PAT_TOKEN }}\n```\nAnd that's it for the release!\n\n### Publishing crates\n\nThe Publish crates workflow is now triggered as mentioned in the previous state. There are 4 main crates to be published, and one job to trigger the draft release workflow for tremor-language-server repo (All automated!). Github actions makes it really great to see which job is interconnected.\n\n![image](https://user-images.githubusercontent.com/23097199/171507584-c8a1bb81-0cbc-4a70-966e-b998758e6430.png)\n\nWith all the crates published, including the language-server which follows the exact same process. Tremor has successfully released a new version! Congratulations!\n\n## My thoughts\n\nThe tremor community has been extremely helpful in guiding me through the entire mentorship. They have this principle of \"Never *worry*, have fun\" that will always stay forever with me, and forward in my career. Special mention for [Heinz](https://github.com/Licenser) who mentored me throughout the months and helped me. And to the tremor community in general, my thanks to all of them! \nI didn't know much about github actions or DevOps in general. But now I can confidently say that I can indeed, _make processes boring by automating them_. I will continue to engage in open source projects, and guide others to the same, cheers!"
    },
    {
      "id": "/2022/06/02/tremor-tremors",
      "metadata": {
        "permalink": "/blog/2022/06/02/tremor-tremors",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-06-02-tremor-tremors.md",
        "source": "@site/blog/2022-06-02-tremor-tremors.md",
        "title": "Tremors - May '22",
        "description": "Welcome, Tremor Enthusiasts! This post is another in a series intended to inform and entertain Tremor Technologists with recent changes in the tremor project. We'll mostly focus these posts on Pull Requests and other notable developments. With these posts, you can stay informed and learn more about the project without having to read pull requests, or wait for release notes.",
        "date": "2022-06-02T00:00:00.000Z",
        "formattedDate": "June 2, 2022",
        "tags": [
          {
            "label": "collaboration",
            "permalink": "/blog/tags/collaboration"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          },
          {
            "label": "tremors",
            "permalink": "/blog/tags/tremors"
          }
        ],
        "readingTime": 3.575,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Gary + The Tremor Team",
            "url": "https://github.com/GaryPWhite",
            "imageURL": "https://avatars.githubusercontent.com/u/7660110?v=4"
          }
        ],
        "frontMatter": {
          "title": "Tremors - May '22",
          "tags": [
            "collaboration",
            "wayfair",
            "tremors"
          ],
          "author": "Gary + The Tremor Team",
          "author_url": "https://github.com/GaryPWhite",
          "author_image_url": "https://avatars.githubusercontent.com/u/7660110?v=4",
          "draft": false,
          "hide_table_of_contents": true
        },
        "prevItem": {
          "title": "Automating the tremor release process",
          "permalink": "/blog/2022/06/03/LFX-Blog-Prashant"
        },
        "nextItem": {
          "title": "Tremors - April '22",
          "permalink": "/blog/2022/05/03/tremor-tremors"
        }
      },
      "content": "Welcome, Tremor Enthusiasts! This post is another in a series intended to inform and entertain Tremor Technologists with recent changes in the `tremor` project. We'll mostly focus these posts on Pull Requests and other notable developments. With these posts, you can stay informed and learn more about the project without having to read pull requests, or wait for release notes.\n\nHave you ever cleaned the house for company, to make it seem like nobody lives there? That’s basically what we’ve been up to getting ready for 0.12.0. It’s a big deal. We're trying to make the codebase spotless with plenty of sweeping up. We also thank our contributors for all the hard work put into automation and new stuff this month!\n\n## New Stuff\n\nMost exciting of all: [We made the 0.12.0 release](https://github.com/tremor-rs/tremor-runtime/releases/tag/v0.12.0)! We put a lot of cool stuff in right before releasing, so finish the article before you jump in!\n\nBeing able to make a new tremor project has been a pain point from some of our users. We wanted [getting started](https://www.tremor.rs/docs/0.12/getting-started/) to be as easy as typing a command. Now it is! You can simply call our [fancy new command](https://github.com/tremor-rs/tremor-runtime/pull/1671) to make a `new` tremor template. Quick and easy!\n\nOur elasticsearch integrations got some upgrades with support for [raw elastic payloads](https://github.com/tremor-rs/tremor-runtime/pull/1653) through our connector, and [native support for auth](https://github.com/tremor-rs/tremor-runtime/pull/1663) between elastic <-> tremor. No more need for custom headers on connectors! Check out the links provided for more details, and we'll update the docs soon.\n\n## CI\n\nThe CI has been changed heavily in the last month. We have [PrimalPimmy](https://github.com/PrimalPimmy) on GitHub to thank for much of the contributions. Thank you!\n\nWe've tweaked our CI when we [create a release](https://github.com/tremor-rs/tremor-runtime/pull/1679) that should prevent creating crates unexpectedly. We also trigger [many workflows across our projects](https://github.com/tremor-rs/tremor-runtime/pull/1673) from a release flow in tremor-runtime. We also decided that publishing in [many steps](https://github.com/tremor-rs/tremor-runtime/pull/1649) would help to prevent [single points](https://github.com/tremor-rs/tremor-runtime/pull/1644) of failure.\n\nWe can also better provide [descriptive options](https://github.com/tremor-rs/tremor-runtime/pull/1624) when we create a release. We can also provide [better options for publishing](https://github.com/tremor-rs/tremor-runtime/pull/1609).\n\nLastly, we tweaked [how much we use sed](https://github.com/tremor-rs/tremor-runtime/pull/1682/files) when we cut a release. This one is great for a quick example:\n\n```bash\ncd tremor-script\nsed -e \"s/^tremor-common = { version = \\\"${old}\\\"/tremor-common = { version = \\\"${new}\\\"/\" -i.release \"Cargo.toml\"\nsed -e \"s/^tremor-influx = { version = \\\"${old}\\\"/tremor-common = { version = \\\"${new}\\\"/\" -i.release \"Cargo.toml\"\nsed -e \"s/^tremor-value = { version = \\\"${old}\\\"/tremor-common = { version = \\\"${new}\\\"/\" -i.release \"Cargo.toml\"\n```\n\nWhere we used to manually edit each project's `.toml` file, we now do this as part of our [GitHub Actions workflow](https://github.com/tremor-rs/tremor-runtime/actions) elsewhere.\n\n## Sweeping Up\n\nAs we mentioned before, there was a lot of sweeping up we wanted to finish before the newest release.\n\nOne of the more interesting fixes we put in was a small bug for `tremor run`. Something that had gone unnoticed for a while was an [upper limit](https://github.com/tremor-rs/tremor-runtime/pull/1582) when running tremor scripts. After 150 seconds, the script would time out. A strange and small feature limitation we didn't notice.\n\nWe had a lot of work specifically to do on connectors.\n\n- Some connectors wrote [more events](https://github.com/tremor-rs/tremor-runtime/pull/1662) than they should\n- Edge cases existed where we would acknowledge error events [without processing them](https://github.com/tremor-rs/tremor-runtime/pull/1670).\n- Some [bench connectors](https://github.com/tremor-rs/tremor-runtime/pull/1651) would not stop as expected.\n- Show errors on [unknown connector](https://github.com/tremor-rs/tremor-runtime/pull/1606) types, instead of silently failing.\n- Make destructive connector actions [much more difficult](https://github.com/tremor-rs/tremor-runtime/pull/1668) to accidentally stumble upon.\n\nWe also removed a limitation we had for code coverage. Where our contributors would have to avoid [functionally any drop at all](https://github.com/tremor-rs/tremor-runtime/pull/1666) in code coverage, we now allow a `.1` percent drop.\n\nIf you were a using the `tremor api` sub command, you should be aware that we've [completely deprecated](https://github.com/tremor-rs/tremor-runtime/pull/1650) the subcommand.\n\n## Bug Fixes\n\nOur bug fixes were pretty few over ht elast month. We had some [publishing](https://github.com/tremor-rs/tremor-runtime/pull/1655), [connecting](https://github.com/tremor-rs/tremor-runtime/pull/1702), and [regular expressions](https://github.com/tremor-rs/tremor-runtime/pull/1677) patches. We updated our new [code coverage tool](https://github.com/tremor-rs/tremor-runtime/pull/1676), codecov, to more accurately track our coverage. We also found that piping information to tremor would [sometimes cause issues](https://github.com/tremor-rs/tremor-runtime/pull/1701) and fixed that.\n\n## Thank You\n\nThe Tremor project as strong as the community around it. Reading this article, making contributions, and generally being involved in the project makes us more successful. Thank you for reading and contributing! See you next time.\n\n- Gary, and the Tremor team."
    },
    {
      "id": "/2022/05/03/tremor-tremors",
      "metadata": {
        "permalink": "/blog/2022/05/03/tremor-tremors",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2022-05-03-tremor-tremors.md",
        "source": "@site/blog/2022-05-03-tremor-tremors.md",
        "title": "Tremors - April '22",
        "description": "Welcome, Tremor Enthusiasts! This is the first post in a series intended inform and entertain Tremor Technologists with recent changes in the tremor project. We'll mostly focus these posts on Pull Requests and other notable developments. With these posts, you can stay informed and learn more about the project without having to read pull requests, or wait for release notes.",
        "date": "2022-05-03T00:00:00.000Z",
        "formattedDate": "May 3, 2022",
        "tags": [
          {
            "label": "collaboration",
            "permalink": "/blog/tags/collaboration"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          },
          {
            "label": "tremors",
            "permalink": "/blog/tags/tremors"
          }
        ],
        "readingTime": 3.625,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Gary + The Tremor Team",
            "url": "https://github.com/GaryPWhite",
            "imageURL": "https://avatars.githubusercontent.com/u/7660110?v=4"
          }
        ],
        "frontMatter": {
          "title": "Tremors - April '22",
          "tags": [
            "collaboration",
            "wayfair",
            "tremors"
          ],
          "author": "Gary + The Tremor Team",
          "author_url": "https://github.com/GaryPWhite",
          "author_image_url": "https://avatars.githubusercontent.com/u/7660110?v=4",
          "draft": false,
          "hide_table_of_contents": true
        },
        "prevItem": {
          "title": "Tremors - May '22",
          "permalink": "/blog/2022/06/02/tremor-tremors"
        },
        "nextItem": {
          "title": "Collaboration - Using Redpanda with Tremor",
          "permalink": "/blog/2021/12/13/redpanda"
        }
      },
      "content": "Welcome, Tremor Enthusiasts! This is the first post in a series intended inform and entertain Tremor Technologists with recent changes in the `tremor` project. We'll mostly focus these posts on Pull Requests and other notable developments. With these posts, you can stay informed and learn more about the project without having to read pull requests, or wait for release notes.\n\nThis posts' theme is _open and improved communication_.\n\n## Release Candidates\n\nWhere's the next release of Tremor?!\n\nTremor's release schedule is becoming a bit more regular. We're releasing [about twice a year](https://github.com/tremor-rs/tremor-runtime/releases), every 6 to eight months. The next release of Tremor should include an exciting new way to write plugins with the [plugin development kit](https://github.com/tremor-rs/tremor-runtime/issues/791), along with other goodies for faster, [well understood tremor scripts](https://github.com/tremor-rs/tremor-runtime/pull/1571/files) and plenty of other [performance](https://github.com/tremor-rs/tremor-runtime/pull/1539) and [bug fixes](https://github.com/tremor-rs/tremor-runtime/pull/1537).\n\nMost notable as an update for us all is that Tremor has a [release candidate](https://github.com/tremor-rs/tremor-runtime/releases/tag/v0.12.0-rc.1) live. If we're pleased with it, then a new version of tremor is soon to be released!\n\nIn this article, Let's dive into three topics: [CI](#ci), [PDK](#pdk-plugin-development-kit), and [performance](#performance)!\n\n## CI\n\nOne of my favorite parts of working with tremor, or any project, is using automation. Running a bunch of stuff on my machine can be quicker, but less reliable than a well established automation platform. Tremor makes an effort to improve Continuous integration regularly; and this month is no exception.\n\nOne of our active members of the Tremor Community, [Pimmy](https://github.com/PrimalPimmy) has taken it upon himself to dramatically improve the CI and relase process for `tremor-runtime`.\n\nThe [new process](https://github.com/tremor-rs/tremor-runtime/pull/1545/files) will automatically publish a release when we're ready. Using this automatino, we can bump versions appropriately with specially named branches and some fancy [GitHub Actions](https://github.com/tremor-rs/tremor-runtime/runs/6026528631?check_suite_focus=true). This lets the Tremor team take full advantage of the seamless GitHub experience from merge -> release, complete with logs and links directly from the Pull Request. We can even extract release notes and [bump versions automatically](https://github.com/tremor-rs/tremor-runtime/pull/1563/files). Once again, truly great work from our community here!\n\n## PDK (Plugin Development Kit)\n\nI won't spend too much time on this point, since the lovely [marioortizmanero](https://github.com/marioortizmanero) has already taken the time to write out [a full blog post](https://nullderef.com/blog/plugin-abi-stable/) or [two](https://nullderef.com/blog/plugin-impl/) on the topic. We'll give a full breakdown another time. For now: know that Tremor is currently in the works of creating an easier way for developers to plug their own binaries into the system to run connectors and pipelines.\n\n## Performance\n\nTremor cares [a lot about performance](https://www.tremor.rs/community/development/benchmarks/LogstashBenchmark). As you may already know from [TremorCon 2021's fabulous talks](https://www.youtube.com/watch?v=xsowS5hEKRg&list=PLNTN4J6tdf20vy14FVOazLTdou_8xyvfe&index=4); it was originally created and adopted for performance gains in Wayfair's event processing infrastructure. There are plenty of performance gains to make in a project as large as Tremor, both inside the project and through dependencies.\n\nOne such dependency we depend on [to parse gigabytes of JSON per second](https://simdjson.org/) is [simd_json](https://docs.rs/simd-json/0.3.18/simd_json/index.html). `simd_json` is a port of the simdjson c++ library into rust. It can not only parse from JSON into Rust, but aid the `serde` library that can easily serialize and deserialize Rust data structures. That's pretty handy for an event processing project that will have to marshal plenty of events from disparate sources of all data forms! As you might imagine, a project like `simd_json` comes with a lot of configuration options, and optimizations behind those options.\n\nFurther than just the configuration that you might give `serde`, or `simd_json`, is the options you may give to the [rust compiler](https://github.com/simd-lite/simd-json/blob/main/.cargo/config). The compiler, by default, [compiles for the largest compatability.](https://docs.rs/simd-json/latest/simd_json/index.html) For best performance on a specific plaform, we make use of the `target-feature` flag. This will allow us to target specific features available on different platforms and CPUs.\n\nIt should be no surprise that we continue this effort within the Tremor team. Know that we also depend on our community, such as a [pull request from scarabsha](https://github.com/tremor-rs/tremor-runtime/pull/1522). Sasha idenfitifed additional target-features for the target `x86_64-unknown-linux-gnu` that speed up the performance of `simd-json`. There's not a benchmark to show exactly how much faster this made json processing, but we appreciate the fact that it will undoubtedly increase performance for some clients of Tremor.\n\n## Thank You\n\nThe Tremor project as strong as the community around it. Reading this article, making contributions, and generally being involved in the project makes us more successful. Thank you for reading and contributing! See you next time.\n\n- Gary, and the Tremor team."
    },
    {
      "id": "/2021/12/13/redpanda",
      "metadata": {
        "permalink": "/blog/2021/12/13/redpanda",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-12-13-redpanda.md",
        "source": "@site/blog/2021-12-13-redpanda.md",
        "title": "Collaboration - Using Redpanda with Tremor",
        "description": "Like all good projects in the open source community, great collaborations start with ad hoc interactions.",
        "date": "2021-12-13T00:00:00.000Z",
        "formattedDate": "December 13, 2021",
        "tags": [
          {
            "label": "collaboration",
            "permalink": "/blog/tags/collaboration"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 3.065,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Collaboration - Using Redpanda with Tremor",
          "tags": [
            "collaboration",
            "wayfair"
          ],
          "author": "Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/redpanda-rocket.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Tremors - April '22",
          "permalink": "/blog/2022/05/03/tremor-tremors"
        },
        "nextItem": {
          "title": "Connectors for Streaming to AWS S3",
          "permalink": "/blog/2021/12/04/LFX-Blog-Daksh"
        }
      },
      "content": "Like all good projects in the open source community, great collaborations start with ad hoc interactions.\r\n\r\n![Redpanda Rocket](./media/redpanda-rocket.png)\r\n\r\nA recent set of discussions between the Tremor maintainers and our community brought [Redpanda](https://redpanda.com/) to our attention.\r\n\r\nSome of our community would like to replace their Kafka deployments with [Redpanda](https://redpanda.com/), a Kafka API-compatible streaming\r\ndata platform, to realize gains in performance and reduce their total cost of operations. . As we already have Kafka\r\nconnectivity, enabling this shouldn’t be too complex, right? Let’s find out.\r\n\r\n## Context\r\n\r\nWe are always looking out for interesting technology, and recently we read a [very interesting article](https://vectorized.io/blog/wasm-architecture/) on the Redpanda\r\nblog about using WASM as server-side filters for subscription. Being as excitable as we are, we obviously had to give\r\nRedpanda a shot.\r\n\r\nTo our joy this turned out to be painless, Redpanda reuses the Kafka API so our existing connectors for Kafka work\r\nout of the box — and as a bonus we could get rid of a whole bunch of docker-compose YAML dancing that we needed to\r\nset up Zookeeper.\r\n\r\nAlex Gallego, founder of Redpanda, reached out to us and we started experimenting with Tremor and Redpanda in this\r\nrepo: [github.com/tremor-rs/tremor-redpanda](https://github.com/tremor-rs/tremor-redpanda)\r\n\r\n## Setting up Tremor and Redpanda\r\n\r\nSo, let’s get our hands dirty and actually connect Redpanda and tremor in a real-world project.\r\n\r\nWe have prepared a fully equipped workshop for this occasion. Give it a shot [here](https://www.tremor.rs/docs/0.11/recipes/redpanda_elastic_correlation/README)\r\nif you are impatient.\r\n\r\nTremor can flexibly act as a Redpanda/Kafka consumer or producer, make use of auto-commit for offset management or manually commit\r\nwhen events are completely handled by the tremor pipeline. Here we are configuring Tremor only committing offsets when events have been successfully handled.\r\n\r\n```yaml\r\nonramp:\r\n  - id: redpanda-in\r\n    type: kafka\r\n    codec: json\r\n    config:\r\n      brokers:\r\n        - redpanda:9092\r\n      topics:\r\n        - tremor\r\n      group_id: redpanda_es_correlation\r\n      retry_failed_events: false\r\n      rdkafka_options:\r\n        enable.auto.commit: false\r\n```\r\n\r\nThis tremor application is reporting success or failure of ingesting the received events into elasticsearch via another Redpanda topic.\r\nConfiguring this is also straightforward, here we have a [Redpanda](https://redpanda.com/) consumer ready for copy-pasting:\r\n\r\n```yaml\r\nofframp:\r\n  - id: redpanda-out\r\n    type: kafka\r\n    codec: json\r\n    config:\r\n      group_id: tremor-in\r\n      brokers:\r\n        - redpanda:9092\r\n      topic: tremor\r\n```\r\n\r\nHere you go. A fully working setup for orchestrating document ingestion with [Redpanda](https://redpanda.com/) delivering the documents and receiving acknowledgements.\r\nFor more details check out this Redpanda [recipe](/docs/0.11/recipes/redpanda_elastic_correlation) on our website.\r\n\r\nTremor is designed to be robust when faced with high volumetric data streams. It comes with batteries included for traffic shaping,\r\nQoS and data distribution. With those tremor can guarantee at-least-once message delivery. We try to reduce CPU and memory footprint\r\nfor a given workload and at the same time provide a “just works” experience for operators. And we think we found a soulmate project in [Redpanda](https://redpanda.com/).\r\n\r\nAnd most importantly, it is working like a charm. In fact we just dropped in [Redpanda](https://redpanda.com/) and expected some hours of troubleshooting, but this hope\r\nwas cut short by a smooth transition:\r\n\r\n```bash\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.828694200+00:00 INFO tremor_runtime::system - Binding onramp tremor://localhost/onramp/redpanda-in/01/out\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.830056300+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Starting kafka onramp\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.831848100+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Subscribing to: [\"tremor\"]\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.832735600+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Subscription initiated...\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.833342+00:00 INFO tremor_runtime::onramp - Onramp tremor://localhost/onramp/redpanda-in/01/out started.\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.828694200+00:00 INFO tremor_runtime::system - Binding onramp tremor://localhost/onramp/redpanda-in/01/out\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.830056300+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Starting kafka onramp\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.831848100+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Subscribing to: [\"tremor\"]\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.832735600+00:00 INFO tremor_runtime::source::kafka - [Source::tremor://localhost/onramp/redpanda-in/01/out] Subscription initiated...\r\n104_redpanda_elastic_correlation-tremor_out-1     | 2021-12-10T15:17:01.833342+00:00 INFO tremor_runtime::onramp - Onramp tremor://localhost/onramp/redpanda-in/01/out started.\r\n...\r\n```\r\n\r\n\r\nBoth in terms of operator friendliness and performance we root for [Redpanda](https://redpanda.com/).\r\n\r\n\r\nWe started using it in our integration test suite, so users can be 100% sure [Redpanda](https://redpanda.com/) connectivity just works."
    },
    {
      "id": "/2021/12/04/LFX-Blog-Daksh",
      "metadata": {
        "permalink": "/blog/2021/12/04/LFX-Blog-Daksh",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-12-04-LFX-Blog-Daksh.md",
        "source": "@site/blog/2021-12-04-LFX-Blog-Daksh.md",
        "title": "Connectors for Streaming to AWS S3",
        "description": "Daksh's Mentorship summary report",
        "date": "2021-12-04T00:00:00.000Z",
        "formattedDate": "December 4, 2021",
        "tags": [
          {
            "label": "connectors",
            "permalink": "/blog/tags/connectors"
          },
          {
            "label": "s3",
            "permalink": "/blog/tags/s-3"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          },
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          }
        ],
        "readingTime": 3.295,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Daksh",
            "title": "Tremor 2021 Fall Mentee",
            "url": "https://www.linkedin.com/in/dak-x"
          }
        ],
        "frontMatter": {
          "title": "Connectors for Streaming to AWS S3",
          "author": "Daksh",
          "author_title": "Tremor 2021 Fall Mentee",
          "author_url": "https://www.linkedin.com/in/dak-x",
          "tags": [
            "connectors",
            "s3",
            "mentorship",
            "cncf"
          ],
          "draft": false,
          "description": "Daksh's Mentorship summary report"
        },
        "prevItem": {
          "title": "Collaboration - Using Redpanda with Tremor",
          "permalink": "/blog/2021/12/13/redpanda"
        },
        "nextItem": {
          "title": "Case Study - Dead Code Detection in PHP",
          "permalink": "/blog/2021/11/09/php-dead-code-detection"
        }
      },
      "content": "### Introduction\nHi folks, I'm Daksh, a senior year CS student at Indian Institute of Technology, Jammu. This blog talks about my project and experience contributing to [Tremor](https://www.tremor.rs) as part of LFX Mentorship Program Fall 2021.\n\n### Learning about Tremor\nI came across [rust](https://www.rust-lang.org/) in early 2020, and I absolutely loved its design,  the syntax and how approachable it was to a beginner. I discovered Tremor while looking for open source projects written in rust. Tremor is an event processing system (think kafka) for unstructured data with rich support for structural pattern-matching, filtering and transformation. Over the summers, I did a few minor PR's. Going through the examples and the [docs](https://www.tremor.rs/docs/index/) I could set up Tremor and start hacking on!!\n\n### My Project\n\nIt is very common in event processing to stream data to a persistent storage engine for later processing or archival purposes. My job was to add connectors to stream data to AWS S3. You may find more information in the github [issue](https://github.com/tremor-rs/tremor-runtime/issues/1176).\n \nSo what is a connector?\nA connector is the component of an Event Processing System that provides the functionality of communicating with the outside world. This would enable current, and future users of Tremor to now connect and stream events to any endpoint which supports the S3 API.\n\n#### AWS S3 Connectors\nI would explain the sink via an example. To connect to S3, one would require the s3 credentials. Due to lack of support from the sdk only public-secret key credentials are supported _(to be extended once the sdk supports other means for credentials)_.\nTremor would read the key names specified in the config from the environment.\n\n###### s3demo.troy\n``` \ndefine flow s3demo\nflow\n    define connector s3conn from s3 with\n    codec=\"json\",\n    config={\n        \"aws_access_token\": \"AWS_ACCESS_KEY_ID\",\n        \"aws_secret_access_key\": \"AWS_SECRET_ACCESS_KEY\",\n        \"aws_region\": \"AWS_REGION\",\n        \"bucket\": \"tremordemo\",\n        \"min_part_size\": 5242880,\n    }\n    end;\n\n    define connector files3 from file with\n    code=\"json\",\n    config={\n        \"mode\": \"read\",\n        \"path\": \"sample.json\",\n    },\n    preprocessors=[\"lines\"]\n    end;\n\n    define pipeline s3pipe\n    pipeline\n        define script s3Event\n            script\n            let e = event;\n            let $s3 = {\n                \"key\": e.key\n                };\n            let payload = e.payload;\n            payload\n            end;\n\n        create script s3Event;\n\n        select event from in into s3Event;\n        select event from s3Event into out;\n\n    end;\n\n    create connector s3conn;\n    create connector files3;\n    create pipeline s3pipe;\n\n    connect /connector/files3 to /pipeline/s3pipe;\n    connect /pipeline/s3pipe to /connector/s3conn;\n\nend;\n\ndeploy flow s3demo;\n```\n###### sample.json\n```json\n{\"key\": \"key1\", \"payload\": {\"event1\": \"hello1\", \"key2\":[1,2,3,4,5]} }\n{\"key\": \"key2\", \"payload\": {\"event3\": {\"nested Obj\": [\"vec1\", \"vec2\", \"vec3\"]}} }\n{\"key\": \"key3\", \"payload\": {\"event3\": null}}\n```\nThis configuration reads the file `sample.json` _delimited by lines_ for events. The `s3pipe` pipeline destructures the line contents to set the `data` for the object to upload and its `key` as meta-data. The s3-sink would then upload the data to AWS S3 with key set to $key inside the bucket `tremordemo` _or anything that is given in the config_\n\n![Sample Working](/img/blog-images/LFX-blog-daksh/s3diagram.png)\n\nThe sink also has the `min_part_size` configuration parameter. S3 support uploading larger objects in multiple parts. One can send multiple events with the same __key__ consecutively, and Tremor would append the content of all those events, and whenever the content size gets larger than the __min_part_size__, a part is uploaded to s3. Whenever the key changes or Tremor stops, the upload for the previous key is completed.\n\n#### Ending Thoughts\n\nI had a very productive and fun time with the Tremor Community. The Tremor principle of \"never __worry__ about it\" has helped me to deal with clueless moments during this mentorship. I would like to express my regards and gratitude to Matthias, Heinz, and Darach for giving me this wonderful opportunity and helping me develop as an open-source contributor and as a joyful person. A special thanks to Matthias for being there to clarify my doubts and fix my mistakes and for being really helpful. \nI would continue to be a part of the Tremor Community and hope to engage with more newcomers to open-source. I would wish to be part of future CNCF events. You may see me around at the Tremor [Discord](https://chat.tremor.rs)."
    },
    {
      "id": "/2021/11/09/php-dead-code-detection",
      "metadata": {
        "permalink": "/blog/2021/11/09/php-dead-code-detection",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-09-php-dead-code-detection.md",
        "source": "@site/blog/2021-11-09-php-dead-code-detection.md",
        "title": "Case Study - Dead Code Detection in PHP",
        "description": "Identified Need",
        "date": "2021-11-09T00:00:00.000Z",
        "formattedDate": "November 9, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 1.185,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Ramona Łuczkiewicz",
            "url": "https://github.com/Agares",
            "imageURL": "https://avatars.githubusercontent.com/u/303398?v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Dead Code Detection in PHP",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "Ramona Łuczkiewicz",
          "author_url": "https://github.com/Agares",
          "author_image_url": "https://avatars.githubusercontent.com/u/303398?v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Connectors for Streaming to AWS S3",
          "permalink": "/blog/2021/12/04/LFX-Blog-Daksh"
        },
        "nextItem": {
          "title": "Case Study - Unified Observability Platform",
          "permalink": "/blog/2021/11/08/uop"
        }
      },
      "content": "## Identified Need\r\nWe have a humongous PHP application - around 20 million lines of code. It’s believed that there are certain parts of the codebase that are no longer used, but it’s hard to reliably find out which ones. Due to the dynamic nature of PHP, attempts at static analysis have failed. We decided that dynamic analysis was needed, and created a PHP extension that logs all the calls to all functions and methods. That’s a lot of data, and we used tremor to aggregate it.\r\n\r\n## Required Outcome\r\nWe need to be able to aggregate a lot of data (the extension sends one message for each HTTP request, which can be at the order of hundreds per second for some servers), counting the number of calls to each function or method in the codebase and send it to our service which does further aggregation and presents the data.\r\n![High Level Architecture](./media/dead_code_detection_diagram.png)\r\n\r\n## Characteristics\r\nWe used Unix Sockets (which were added as a source to tremor during this project) and then a simple script that aggregates the data. We’re hoping to use custom aggregate functions in the future (there’s an open RFC, waiting for the official voting) to further simplify the pipeline.\r\n\r\n## Conclusion\r\nWe are currently testing the solution with smaller applications, seeing minimal performance impact and no impact on stability. We were able to delete unused code from those applications without affecting their operation."
    },
    {
      "id": "/2021/11/08/uop",
      "metadata": {
        "permalink": "/blog/2021/11/08/uop",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-08-uop.md",
        "source": "@site/blog/2021-11-08-uop.md",
        "title": "Case Study - Unified Observability Platform",
        "description": "As Wayfair's technology organization modernizes its infrastructure services to meet",
        "date": "2021-11-08T00:00:00.000Z",
        "formattedDate": "November 8, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 5.5,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Unified Observability Platform",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Dead Code Detection in PHP",
          "permalink": "/blog/2021/11/09/php-dead-code-detection"
        },
        "nextItem": {
          "title": "Case Study - Multi-Participant Transaction Orchestration",
          "permalink": "/blog/2021/11/07/search"
        }
      },
      "content": "As Wayfair's technology organization modernizes its infrastructure services to meet\nnew volumetric peaks they continually adapt, adopt and atrophy out systems and services.\n\nThis is particularly difficult with shared infrastructure and services that are ever-present\nbut seldom seen by many of the engineers in the organization.\n\nThe rise of OpenTelemetry provides an opportunity for developers to consolidate on SDKs that\nare consistent across programming languages and frameworks. For our SRE's and operators it\noffers ease of integration and ease of migration of services.\n\nTremor is a core enabling component of Wayfair's migration strategy. Tremor supports\nbut is endpoint, protocol and service agnostic. This allows our operational teams to\nswitch from on-premise to cloud native services with minimal coordination with others.\n\nThis also allows switching from in-house to managed or out of the box services supported\nby cloud providers.\n\nMoving 1000s of developers to a new technology stack when you are operating continuously\nwith no downtime and at a large scale is hard.\n\n## Identified Need\n\nTremor emerged from production needs in existing systems, specifically\nin the logging and metrics or observability domains in a large\nhypergrowth and heavily speciated and specialized production environment\nthat operates 24x7x365.\n\nAs this infrastructure is migrated from a largely on-premise data-centre\nbased environment to a cloud native environment and the wider technology\norganization it operates within doubles in size, change is inevitable.\nYou can bet your roadmap on it.\n\nOne great emerging de facto standard is the observability sub-domain\nthat cloud-native computing is propelling forward with standards such as\nthe CNCF’s OpenTelemetry.\n\nTremor added initial support for OpenTelemetry in February 2021.  \n  \nFor decades, observability - whether logging, metrics or distributed\ntracing has been common. But, lacking in a unified approach, lacking in\na core set of interoperable and interworking standards.\n\nOpenTelemetry has good support for capturing and distributing logs,\nmetrics and trace spans. It has sufficient out of the box to suit the\nmost common needs, most of the time. It affords developers an\nopportunity to rationalize libraries and frameworks around shared\nconcepts, shared understanding and shared effort. This is especially\nvaluable in large, complex production operations such as Wayfair’s\neCommerce production estate.\n\nLanguages and platforms change over time. System and component\ninfrastructure are continuously evolving. As SaaS environments continue\nto evolve and innovate new forms of observability; or production\noperations, system reliability engineers or network operations teams who\noften need to move faster than the pace of application or infrastructure\ndevelopers can develop new software and systems - this is a hard\nproblem.\n\nBy targeting OpenTelemetry - developers can depend on a consistent set\nof SDKs for most common observability needs. Production focused teams\ncan depend on a consistent wire-format and protocol allowing them to\nmove from data-centre to the cloud, and rewire the infrastructure and\nservices just in time.  \n  \nThrough OpenTelemetry, we can normalize the concepts, the code and the\ninner workings of our cloud-based systems and services - whilst\nintroducing far more flexibility than ever before as observability\nservices and software vendors provide a standards-based and\ninteroperable path.  \n  \nIt is a win-win for all concerned.\n\n## Required Outcome\n\n![High level architecture - current system](./media/uop/image1.png)\n\nIn production at Wayfair, logging and metrics data distribution\npipelines are all handled by tremor. With OpenTelemetry, distributed\ntracing can now be standardized across our production estate.\n\n### Solution\n\nStandardize an Tremor and OpenTelemetry together.\n\n### Characteristics\n\nThe introduction of OpenTelemetry allows developers to standardize on\nObservability in applications, services and code for logging, metrics\nand distributed tracing. As OpenTelemetry is natively supported in\ntremor, it means only minor configuration changes to our existing\nlogging and metrics services.\n\n![The new OpenTelemetry normal](./media/uop/image2.png)\n\nWith OpenTelemetry, distributed tracing can benefit from the same\ntraffic shaping and adaptive rate limiting as the rest of our\nobservability stack. The unification of the source, collector and\ndistribution tiers via kafka provides scalable and recoverable telemetry\nshipping and distribution.\n\nTremor adds adaptive load shedding and traffic shaping that are tunable\nin production. Tremor also allows legacy observability frameworks to\nco-exist with OpenTelemetry for a gradual migration across the\nprogramming languages and frameworks in production use. Finally, tremor\nenables multiple downstream services to participate in the overall\nsolution.\n\nAs a heterogeneous ecosystem of interconnected services - the unified\nobservability platform based on tremor has no preferred upstream or\ndownstream endpoint. It is system and service agnostic. It is\nbendable.  \n  \nThis allows teams that prefer the GCP ecosystem to normalize to those\nnative services for visualization, debugging and troubleshooting. For\nour ElasticSearch population, Elastic’s APM may be a better alternative.\nFor other teams, and our operational staff and folk with more ad hoc\nneeds - DataDog may be preferable.\n\nIt’s a cloud native decentralized rock’n’roll observability world out\nthere. Getting 5000 and growing engineers to choose a single\nobservability path is impossible. So, as the population cannot bend, the\nunified observability leans on tremor for this purpose.\n\nAs improved services, frameworks and methods are onboarded our\ntremor-based systems can be incrementally adjusted to meet changing\ndemands.\n\n### Insights\n\nThis application of tremor does not introduce new features or\ncapabilities per se.\n\nHowever, it is the first unified tremor-based system that spans the\nentire observability spectrum. It centralizes common capabilities and\nfacilities for greater operational freedom, whilst decentralizing the\npoint-to-point endpoint connectivity for the widest applicability across\nour production estate.\n\nAs tremor exposes OpenTelemetry as a client, and as an embedded server -\nit is effectively used to disintermediate, interpose and intework with\nlegacy environments and to standardise on OpenTelemetry.  \n  \nIt does this as an incremental update. Existing users have time to\nmigrate their systems to the new OpenTelemetry-based best-practice.\nExisting processes, practices and battle-tested systems are\nmaintained.  \n  \nOperators have better tools to manage the production estate and to tune\ncapacity, performance and cost.\n\nThis is also the first tremor-based system where tremor is a key\narchitectural primitive allowing our observability community to\nbend to the changing needs of our development and operational community\nwith minimal effort, and at short notice.\n\n## Conclusion\n\nAs tremor expands to new domains such as search, service orchestration\nand supply-chain and logistics to name but a few - our early adopters in\nthe logging domain have evolved from using tremor as a point solution\nfor traffic shaping - to building our entire observability\ninfrastructure based on tremor.  \n  \nNew domains will extend tremor’s capabilities in multi-participant\ntransaction processing and distributed orchestration. The now unified\nobservability domain will further expand and extract capabilities that\nenhance modularity and flexibility of tremor to build large distributed\nsystems with a relatively simple and easy to program and growing set of\nlanguages designed for large-scale event-based processing."
    },
    {
      "id": "/2021/11/07/search",
      "metadata": {
        "permalink": "/blog/2021/11/07/search",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-07-search.md",
        "source": "@site/blog/2021-11-07-search.md",
        "title": "Case Study - Multi-Participant Transaction Orchestration",
        "description": "The support for multi-participant transaction orchestration in tremor",
        "date": "2021-11-07T00:00:00.000Z",
        "formattedDate": "November 7, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 8.67,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Multi-Participant Transaction Orchestration",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Unified Observability Platform",
          "permalink": "/blog/2021/11/08/uop"
        },
        "nextItem": {
          "title": "Case Study - Modularity, Oh My",
          "permalink": "/blog/2021/11/06/modularity"
        }
      },
      "content": "The support for multi-participant transaction orchestration in tremor\noriginates with this use case from Wayfair's Search platform services\nteam.\n\n## Identified Need\n\nOne of the frequent requests made of the tremor team by peers in the\nInfrastructure organization at Wayfair has come from the search domain.\nSearch is a critical service at Wayfair and it is the powerplant behind\nmany other services - ranging from recommendation engines through to\nauditing of data streams that are continually being ingested and indexed\ninto multiple searchable databases.\n\nAt a very high level - streams of documents need to be elementized and\nbroken down into one or many indexable items of interest - these items\nthen need to be indexed ( successfully ) into one or many search\nengines.\n\nMany of the use cases that are battle tested with tremor are relevant in\nthis domain:\n\n- Cleansing, normalization and enrichment of documents and indexable\n  elementization and tracking documents and elementized items\n- Rate limiting, capacity-based load-shedding, with domain classification\n  similar to the traffic shaping use cases where tremor started\n- Sourcing, transformation and distribution of documents and the\n  synthetic events in real-time at low or very low latencies\n\nBut, for the use case at hand, there are additional needs:\n\n- All documents must be processed transactionally, without loss and\n  with proper reporting of processing outcome to upstream services and\n  the documents must be processed in arrival order. The guaranteed\n  delivery and circuit-breaker mechanisms in tremor now need to be\n  multi-pipeline.\n- All indexable elements of all documents must be indexed in multiple\n  downstream engines successfully ( or operator errors produced for\n  exceptions ) while all possible error cases need to be caught and\n  reported upstream in order to issue retries or let operators\n  intervene. This is a reasonably orchestration mapping processed elements and tracing\n  back to the documents the elements were produced from before publication\n  down stream.\n- There is significant variability, variant on a case by case basis, to the exact semantics\n  required for different document types to be processed to a varying number of downstream\n  indexing systems and technologies. The solution needs to be modular\n\nGathering and aggregating multiple parallel processing outcomes and\nsubsuming them under a common transaction is outside of the baseline\nscope of message-based and message-like systems as they typically only\nsupport point-to-point transactions. Correlation across multiple event\nstreams usually needs to be solved on the application level. Where\nsystems support orchestrated transactions - these are typically\nconstrained by transport/protocol or other factors beyond the\napplication authors control, and therefore inflexible under variant (\nand often fast-changing ) production needs.\n\n## Required Outcome\n\nExpand on tremor’s QoS facilities so that multi-participant transaction\norchestration is possible, easily composable and user programmable.\n\n### Characteristics\n\nThe original use cases for tremor were relatively straightforward and\ndata distribution applications with a requirement for traffic shaping\nand rate limiting for data streams when downstream systems were prone to\nbeing overwhelmed at peak traffic conditions.\n\nThese occurrences were rare - but their impact was high when they\nhappened. And in an infrastructure with higher high peaks year on year\nthis is an ever-present hazard of doing business.\n\nMore recently, delivery guarantees are expanding as new domains adopt\ntremor in production. In these domains data loss, even user defined and\nstrictly capacity managed traffic shaping, is not tolerable.  \n  \nLike with many real-time systems - the percentage of the overall\nin-flight volumetric that requires transactional delivery is typically a\nsmall subset of the overall firehose. Take financial trading systems for\nexample - orders and trades are transactional and they need to be\nprocessed, each and every one, correctly - as there are fiscal and\nregulatory conditions that need to be strictly met.  \n  \nBut pricing - the ability to buy or sell and equity, or the current\ncurrency rate is often naturally continuously changing due to supply and\ndemand, and naturally redundant - as you can buy or sell the same stock\non many different venues.\n\nThe search case stretches the QoS mechanisms in tremor and the internal\nmechanisms used to track events as they are processed from a single set\nof flows and a small set of participants - to larger and more complex\nuser defined flows that orchestrate transactions of arbitrary\ncomplexity.  \n  \nThis is compounded by tremor-based applications today being large,\nincreasingly sophisticated and modular. So the QoS mechanisms that were\noriginally constrained to the boundary of a single pipeline - now need\nto be preserved and propagated across an entire deployment.\n\n## Solution\n\nTremor’s core processing element - pipelines - are executable\ndirected-acyclic graphs.\n\nA tremor user designs a workflow or pipeline using the tremor query\nlanguage.\n\nTremor converts this to a directed graph and makes sure that it is\nacyclic.\n\nTremor transforms and optimizes the user defined graph to an executable\nform that is well-structured for easily supporting easy to understand\nand easy to define qualities of service.\n\nIf we imagine the pipeline graph as a single larger directed-acyclic\ngraph we have what tremor actually uses for event distribution\ninternally. Tremor can distribute and process user defined events -\nthese are business or data events that originate from connectors or user\ndefined logic.  \n  \nTremor can inject control events - these are runtime events that tremor\nuses for quality of service and they are not ordinarily user visible.\nTremor can also inject events originating at outputs ( or that propagate\nfrom downstream systems ) backwards to inputs ( or for propagation to\nupstream systems ). But, we can do so without introducing cycles.\n\nThe user-defined graph is acyclic. But the tremor runtime has, in\neffect, the ability to coordinate acknowledgements for user-defined\nevents and an ability to signal upstream breaks in connectivity to\ndownstream systems, or downstream breaks to upstream systems. These\nruntime control events - we call them signal-flow and contra-flow - are\ntransparent to users.  \n  \nOur `wal` ( write-ahead-log ) operator produces and consumes\nsignal-flow and contra-flow events.  \n  \nSo, given a simple tremor application that has no defined QoS ( it does\nnot use guaranteed delivery )  \n  \n```trickle title=\"/etc/tremor/config/lossy.trickle\"\nselect patch event of\n  insert hostname = system::hostname()\nend\nfrom in into out;\n```\n\n### We can configure the `wal` operator\n\n```trickle title=\"/etc/tremor/config/mostly_guaranteed.trickle\"\n\nuse tremor::system;\n\ndefine qos::wal operator in_memory_wal\n\nwith  \n read_count = 20,\n  max_elements = 1000, # Capacity limit of 1000 stored events\n  max_bytes = 10485760 # Capacity limit of 1MB of events\nend;\n\ncreate operator in_memory_wal;\nselect patch event of\n  insert hostname = system::hostname()\nend\nfrom in into in_memory_wal;\n\nselect event from in_memory_wal into out;\n```\n\nThis is a logically equivalent application - but we can tolerate a lag\nof up to 1000 events or 1 megabyte of data before losing data. Under the\nhood of course - events are now tracked and traced. If connectors are\nQoS aware then we now have a more robust application.\n\nSo if we are consuming from a kafka cluster upstream and distributing to\nanother kafka cluster downstream ( such as in another data center ) -\nthose systems can go offline briefly or be disconnected. The connectors\nthemselves handle lossless delivery ( that’s handled by kafka in both\ncases in this example ). Connectors with less strong guarantees can\nstill be ( mostly ) lossless - so if our downstream system is HTTP-based\n( like elasticsearch ) - we can tolerate transient service loss and\nfully recover.  \n  \nWhat if tremor or the host it is deployed on is rebooted?\n\n```trickle title=\"/etc/tremor/config/mostly_guaranteed.trickle\"\nuse tremor::system;\ndefine qos::wal operator in_memory_wal\nwith  \n  dir = ”./recovery”, # Persistent file-based recovery file\n  read_count = 20,\n  max_elements = 1000, # Capacity limit of 1000 stored events\n  max_bytes = 10485760 # Capacity limit of 1MB of events\nend;\n\ncreate operator in_memory_wal;\nselect patch event of\n  insert hostname = system::hostname()\nend\n\nfrom in into in_memory_wal;\n\nselect event from in_memory_wal into out;\n```\n\nThe tremor developer doesn’t need to be too concerned with the internal\nmechanisms, or their implementation. And for simple applications with a\nsingle primary data flow, its as easy as the examples above to\nselectively introduce grades of guaranteed delivery with a spectrum of\nrobustness that derives from choice of connectivity ( kafka vs http ) or\nhow the [qos](https://www.tremor.rs/docs/tremor-query/operators/)\noperators are chosen, placed in a flow, and configured.\n\nOrchestration however, is different. In an orchestrated transaction the\nuser defined logic provided by the tremor developer also needs to do\nsome tracking. This is achieved through using tremor’s state mechanism\nalongside the `qos` capabilities and operators that tremor provides to\ncompose a solution.  \n  \nSo, in our search case - let us say we have two downstream search\nengines - and both need to index a different set of items of interest\nelementized from a single document - we use the state mechanism to track\nprogress of the items for each participant - and when all participants\nhave indexes up to date - we issue a synthetic event ( that can be\nrecorded in a wal ) that publishes the document processing status\ndownstream.\n\n![search logic](./media/search/image1.png)\n  \nSo our document source is kafka, our indexing engines for elementized\nitems and our destination for successfully elementized documents ( which\nmay now be enriched with elementization metadata and index metadata )\ncan now be published ( let’s assume kafka again for simplicity ) to an\naudited topic.  \n  \nThe state mechanism in tremor is a readable/writable value - so\npersistent and recoverable state is a relatively simple composition:  \n\n```trickle\ndefine script remember\nscript\n  let state = event;\n  event\nend;\n\ndefine qos::wal operator forget_me_not\nwith\n  dir = \"./brain\",\n  read_count = 1,\n  max_elements = 1000, # Capacity limit of 1000 stored events\n  max_bytes = 10485760 # Capacity limit of 1MB of events\nend;\n\ncreate script remember;\ncreate operator forget_me_not;\nselect event from in into remember;\nselect event from remember into forget_me_not;\nselect event from forget_me_not into out;\n```\n\nPlease don’t run out of disk space!\n\n## Conclusion\n\nMost of the changes required to evolve tremor form supporting great qos\nfor simple single pipeline applications to complex multi-pipeline and\nmulti-participant stateful orchestrations did not expose new features to\nthe tremor developer or user.  \n  \nIt has been a significant change to tremor internals, however and the\nwork reaches a stable point with our `0.12` release - the ability to\n`pause` and `resume` connectors, and the ability for the tremor\nruntime itself to detect and act on `quiescence` will mean that tremor\nis flexible enough for the demands and use cases that originated in the\nsearch domain."
    },
    {
      "id": "/2021/11/06/modularity",
      "metadata": {
        "permalink": "/blog/2021/11/06/modularity",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-06-modularity.md",
        "source": "@site/blog/2021-11-06-modularity.md",
        "title": "Case Study - Modularity, Oh My",
        "description": "Identified Need",
        "date": "2021-11-06T00:00:00.000Z",
        "formattedDate": "November 6, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 4.315,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Modularity, Oh My",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Multi-Participant Transaction Orchestration",
          "permalink": "/blog/2021/11/07/search"
        },
        "nextItem": {
          "title": "Case Study - Kubernetes and Tremor Sidecars",
          "permalink": "/blog/2021/11/05/kubernetes-sidecars"
        }
      },
      "content": "## Identified Need\n\nThe adoption growth of tremor inside Wayfair is such that we have\nproduction customers with 3.5 years of experience operating tremor in\nproduction with very large, complex tremor-based services - and fresh\ndemands from new domains such as Search - whose requirements for\nmulti-participant transaction orchestration are driving enhancements to\nqualify of service, guaranteed delivery and circuit breaker capabilities\nwithin tremor’s core processing engine.\n\nSome usage patterns are becoming common enough that sharing tremor\napplication logic across teams, across organizations, and across domains\nis now common. For example - tremor has good support for HTTP based\ninteractions and already interfaces with a number of HTTP-based and REST\nAPIs, and it can expose HTTP-based interfaces to participants and act as\na REST-based or HTTP-based service. Many of these services share the\nsame needs around handling HTTP errors and routing errors and alerts.\n\nAt the event flow or query level - similar levels of sophistication are\nemerging in the installed user base.\n\n## Required Outcome\n\nExpand tremor’s domain specific languages to support modularity,\nstarting with the scripting language but extending into the query\nlanguage to maximise reuse of user-defined processing logic.\n\n### Characteristics\n\nProvide standard mechanism and syntax to discover, reference and consume\nfunctional units of logic that can be shared by all tremor domain\nspecific languages.\n\nA new lexical preprocessing phase has been introduced allowing source to\nbe packaged within a modular set of paths through a `TREMOR_PATH` environment\nvariable. Since V0.8 of tremor the scripting and query languages both\nsupport modules, and share the same module syntax and semantics.\n\nThe tremor API was upgraded to supported preprocessed or non-modular\nsource so that no API changes were required to extend the deployment\nmechanisms to support modularity.\n\n### Modular scripting\n\nIn a nutshell - this added support for user defined constants and user\ndefined functions.\n\n```tremor title=\"my_mod.tremor\"\n# Tail recursive implementation of fibonacci\n#\nfn fib_(a, b, n) of\n  case (a, b, n) when n > 0 => recur(b, a + b, n - 1)\n  default => a\nend;\n\nfn fib(n) with\n  fib_(0, 1, n)\nend;\n```\n\nThe module can be loaded via the module path and used in other script or query sources:  \n\n```trickle title=\"fib.trickle\"\n# A streaming fibonacci service*\n\ndefine script fibber\nscript\n  use my_mod;\n    my_mod::fib(event)\nend;\n\ncreate script fib from fibber;\n\nselect event from in into fib;\n\nselect event from fib into out;\n```\n\nModules can be file-based, or defined inline in the scripting or query\nlanguage. A standard set of system modules is provided by tremor out of the box.\n\n[Tremor Modules](https://www.tremor.rs/docs/tremor-script/modules)  \n  \n### Modularity in the query language\n\nIn the query language windows, scripts and pluggable operators may be\ndefined and shared across queries.\n\nThere is an RFC for modular sub-query to allow query sub-graphs to be\ndefined and shared which is being delivered as part of a tremor LFX\nmentorship.\n  \n### Modularity in the deployment language\n  \nModular deployments through replacing the YAML configuration syntax with\na deployment language will embed the modular query language, which in turn\nembeds the modular scripting language.  \n  \nThis work is under development and will span multiple releases - but it\nis being designed in such a way that as clustering capabilities are added to tremor, that\nclustered or  distributed deployments will be modularly composable by end users using\nthe same  tooling as the other DSLs within tremor.\n\n## Solution\n\nThe support for modularity is thematic. The scripting language now\nsupports a functional programming paradigm and file-based or nested\ninline modules. The query language can embed modular scripts using the\nsame module mechanism and definitions in the query language are also\nmodular.\n\nModular sub-query and the introduction of the deployment language are\nplanned and in progress and will extend modularity to the administration\nof running tremor nodes.\n\nAnd, in the fullness of time, clustering will further extend modularity\nin tremor to maximize operator and tremor developer productivity through\nefficient reuse and sharing of common tasks.\n\nThe first set of connectivity to benefit from modularity is the support\nfor CNCF OpenTelemetry. This is the first set of tremor connectors to be\ndelivered that ships with its own set of modules designed to make\ndesigning OpenTelemetry based services in tremor easier.\n\n## Conclusion\n\nAs tremor grows into new domains, and the algorithm and solution\ncomplexity of traditional production domains for tremor increase in\nsophistication, size, complexity, the subject of modularity has evolved\nand new demands continue to emerge.  \n  \nWe expect the `modularity` theme to be long-lived, but its origins\nderive from production needs. When tremor was developed the user defined\nlogic was small, relatively simple and applications built with tremor\nwere fairly monolithic.  \n  \nToday, multi-pipeline and medium to large tremor-based applications are\ncommon. And adoption of the modular scripting and query language\nprimitives is now driving larger and more sophisticated use cases.\n\nAnother dimension of modularity is the ongoing expansion of connectivity\nin tremor. Modularity here reflects a different production-driven need (\nand a few maintainer conveniences ). A plugin development kit is being\ndeveloped that will allow connectors and other plugins to be developed\nin separately managed and maintained projects. This in turn allows the\ncore of tremor to be managed independently of connectivity."
    },
    {
      "id": "/2021/11/05/kubernetes-sidecars",
      "metadata": {
        "permalink": "/blog/2021/11/05/kubernetes-sidecars",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-05-kubernetes-sidecars.md",
        "source": "@site/blog/2021-11-05-kubernetes-sidecars.md",
        "title": "Case Study - Kubernetes and Tremor Sidecars",
        "description": "Happened Before",
        "date": "2021-11-05T00:00:00.000Z",
        "formattedDate": "November 5, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          },
          {
            "label": "k8s",
            "permalink": "/blog/tags/k-8-s"
          }
        ],
        "readingTime": 2.765,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Kubernetes and Tremor Sidecars",
          "tags": [
            "case-study",
            "wayfair",
            "k8s"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Modularity, Oh My",
          "permalink": "/blog/2021/11/06/modularity"
        },
        "nextItem": {
          "title": "Case Study - Data Flow with Tremor",
          "permalink": "/blog/2021/11/04/data-flow"
        }
      },
      "content": "## Happened Before\n  \nThe simplified architecture of our systems is currently:\n  \n![old pipeline](./media/kubernetes-sidecars/image1.png)\n\n## Identified Need\n\nWayfair’s technology organization is continuously expanding, evolving\nand growing. When work on tremor began we were running almost entirely\nin our own data centres, on our own hardware.\n\nToday, we are running largely in the cloud. Whether cloud-native or\nbare-metal the sidecar pattern has proven to be a significantly popular\ndeployment pattern with tremor-based systems in production at Wayfair.  \n  \nTremor is equally happy with clustered ( just a bunch of event\nprocessors ) centralized deployments or with sidecar deployments; on\ncontainerized virtual machines, or alongside our growing Kubernetes\nestate.\n\nWith the rise of Kubernetes and cloud-native at Wayfair - we had an\ninteresting challenge as an infrastructure organization serving the\n1000’s of developers in our wider technology group. How do we continue\nto deliver a single pane of glass to our developers?  \n  \nAlthough the over-simplified architecture diagram above looks simple -\nits far more complex in practice. We have multiple independent search\nand visualization clusters. And we have many more infrastructure\nservices and clusters sitting behind these frontends.  \n  \nFor our application developers - this looks like a vanilla installation\nof ElasticSearch and Kibana. In reality its an always-changing and\nforever-speciating set of services running 24x7x365 offering a\nsingle-pane-of-glass for our developers convenience.  \n  \nBy this state of use case evolution and adoption of Tremor at Wayfair -\ntremor is at the centre of a lot of the internal data distribution and\nprocessing - whilst offering no protocols, APIs or transports of its\nown - entirely invisible to our target developer community.  \n  \nOur Kubernetes team developed helm charts for tremor to preserve the\nconvenience of this illusion; whilst accelerating the operationalisation\nof our emergent cloud-native infrastructure services.\n\n## Required Outcome\n\nBoldly go cloud-native, in such a way that no-one truly notices.\n\n### Characteristics\n\nNo new features or capabilities were developed for this use case by the\ntremor team.\n\n### Solution\n\nAdopt helm-based deployments of tremor for our cloud-native and\nkubernetes-enabled applications and services. The helm charts have since\nbeen open sourced in collaboration with our Kubernetes Team as a part of\ntremor, and have been extended to support OpenShift by the tremor\ncommunity ( waves to **Anton Whalley** of [Rust Dublin](https://www.meetup.com/Rust-Dublin/) fame! ).\n\n[Tremor Helm Charts](https://github.com/tremor-rs/tremor-k8s-helm)\n\n## Conclusion\n\nShortly before tremor was open-sourced and donated to the Linux\nFoundation it became cloud-native itself through the combined efforts of\nthe Infrastructure group at Wayfair - especially our Platform\nEngineering, SRE’s and our Kubernetes teams' hard work.  \n  \nWe hope to productize and open source other solution packs that enable\nthe wider tremor community to quickly bootstrap production environments\nbased on the tremor-based systems we already have in productioning in\nour Logging, Metrics, Observability, Kubernetes and Search teams.  \n  \nIn a large way - the early successes of tremor and our adoption of\ncloud-native and cloud-based computing aligned the goals of the tremor\nproject with those of the Linux Foundation and the Cloud Native Compute\nFoundation where tremor is now an early stage sandbox project.  \n  \nIf you’re reading this - and the work and philosophy resonates with your\norganization, your people and you believe similar benefits could elevate\nyour production environments - then please reach out to us in the tremor\ncommunity and get involved, join us and help us shape tremor’s future."
    },
    {
      "id": "/2021/11/04/data-flow",
      "metadata": {
        "permalink": "/blog/2021/11/04/data-flow",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-04-data-flow.md",
        "source": "@site/blog/2021-11-04-data-flow.md",
        "title": "Case Study - Data Flow with Tremor",
        "description": "Happened Before",
        "date": "2021-11-04T00:00:00.000Z",
        "formattedDate": "November 4, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 5.34,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Data Flow with Tremor",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Kubernetes and Tremor Sidecars",
          "permalink": "/blog/2021/11/05/kubernetes-sidecars"
        },
        "nextItem": {
          "title": "Case Study - Data Distribution",
          "permalink": "/blog/2021/11/03/data-distribution"
        }
      },
      "content": "## Happened Before\n  \nThe simplified architecture of our systems is currently:  \n  \n![old pipeline](./media/data-flow/image1.png)\n\n\n## Identified Need\n\nThe need to route and process data from multiple sources to multiple\ndestinations with one or many potentially overlapping streams of data\nprocessing is already evident in the first 2 phases of Tremor’s\nemergence as a mission critical piece of infrastructure at Wayfair.\n\nGrowing adoption and the increased sophistication of processing needs\nnow results in the emergence of event/data flow or pipeline processing\nby our production users. We summarise multiple phases of evolution here\nand conflate them into a single case study.  \n  \nIn reality the use case captured in this synopsis composes multiple\nsmaller projects related by the same identified need spanning multiple\nreleases into a single case study.\n\n## Required Outcome\n\nOur systems specialists are writing increasingly complex, layered and\nrich business logic within tremor’s domain specific language\n`tremor-script` and are inhibited by our pipeline model which uses the\nYAML format for describing data flow graphs.\n\nYAML is hard to write, and hard to debug, and the embedded scripting\nlanguage is an odd fit into the pipeline configuration which is\ndescribed in YAML.\n\nPreserving the internal pipeline processing and execution mechanisms -\nreplace the verbose YAML syntax with a statement oriented query language\nthat extends the expression oriented scripting language.  \n  \nThis allows hygienic and helpful error reporting with suggested\nworkarounds and fixes, better IDE integration and a more intuitive means\nto express data flow operations on multiple data streams that the\npipeline mechanisms expose to tremor systems application developers.  \n  \nA structured query-like language suitably captures the directed-acyclic\ngraph nature of data flows but we need to support rich nested JSON-like\ndata structures with leverage of the processing capabilities of the\nscripting language - whilst opening up new capabilities to extend the\nprocessing capabilities through custom operators, embeddable scripting\nlogic and extensions and enhancements to QoS and non-functional\nprimitives.\n\nFor the metrics domain - the ability to aggregate tumbling windows of\nevents and to provide multiple aggregation dimensions with flexible\ngrouping policies is a new requirement.\n\n### Characteristics\n\nReplace the YAML-based pipeline configuration with a structured\nquery-like language that embeds the scripting language, providing top\ngrade support for processing rich data structures, extensibility through\ncustom operators, and windowing semantics to support multi-resolution\nevent aggregation.\n\nThe initial solution was the introduction of the tremor query language.\n\n### Solution\n\nThe query language not only replaces the YAML-based event flow syntax\nfor describing data flow pipelines and processing - which is useful for\nevery domain using tremor in production at Wayfair - but, it has special\nconsiderations for the metrics or other analytic domains that require\nrich means of grouping and aggregate processing of in-flight streaming\ndata. The embedding of scripting logic allows the traditional domain of\nETL and data processing and transformation to be natively supported with\na more intuitive syntax.\n\nA rate limiting or traffic shaping example ( common to multiple usage\ndomains ):\n\n```trickle\n# File traffic.trickle\n# Very basic traffic shaping algorithm\n\n# Define a bucket grouping operator\ndefine grouper::bucket operator kfc;\n\n# Logic for categorizing events\n\ndefine script categorize\nscript\n  let $rate = 1;\n  let $class = event.`group`;\n  { \"event\": event, \"rate\": $rate, \"class\": $class };\nend;\n\n# An instance of the grouper\ncreate operator kfc from kfc;\n\n# An instance of the categorizer\ncreate script categorize;\n\n# Stream ingested events into the categorizer\nselect event from in into categorize;\n\n# Stream categorized events into the grouper\nselect event from categorize into kfc;\n\n# Stream categorized and group batched events downstream\nselect event from kfc into out;\n```\n\nThe relatively simple structured query-like language allows script and\nwindow definitions to be reused. The `define` statements do not create\noperator instances in the data flow graph; they create named reusable\ndefinitions that encompass the desired semantics. The `create`\nstatements create the nodes of the directed acyclic graph. The\n`select` statement is a builtin operator that is used for linking\nnodes in the graph together to form a data flow or event processing\ngraph.\n\nAlthough the sample logic in the example is a simplified version of what\nour logging and metrics service teams actually develop and maintain for\nour production systems - it replaces 1000s of lines of cryptic YAML with\nhundreds of lines of easy to debug and reason about query code.\n\nAn aggregation example from the metrics or analytics domain. This example\nis a complete but simplified example of a tremor event processing application:  \n\n```trickle title=\"aggregator.trickle\"\n# Aggregate events using a high dynamic range histogram with 10 second, 1 minute, 10 minute\n# and 1 hour aggregate summaries.*\n\nselect {\n  \"measurement\": event.measurement,\n  \"tags\": patch\n    event.tags of insert \"window\" => window \n  end,\n  # Windowed histogram - for median and a selection of quartiles\n  \"stats\": aggr::stats::hdr(event.fields[group[2]], [ \"0.5\",\"0.9\", \"0.99\", \"0.999\" ]),\n  \"class\": group[2],\n  \"timestamp\": aggr::win::first(event.timestamp),\n}\n# The higher resolution aggregates are merged into lower resolution aggregates to conserve memory\nfrom in[`10secs`, `1min`, `10min`, `1h`]\nwhere event.measurement == \"udp_lb\"\nor event.measurement == \"kafka-proxy.endpoints\"\nor event.measurement == \"burrow_group\"\nor event.measurement == \"burrow_partition\"\nor event.measurement == \"burrow_topic\"\n# The operator maintains a user defined composited set of group partitions.\n# Each group maintains its own set of aggregation windows\ngroup by set(event.measurement, event.tags,\neach(record::keys(event.fields)))\ninto normalize\n# Discard computed events with a small sample set\nhaving event.stats.count \\> 100;\n```\n\nIn most real world tremor-based systems - the synthetic events computed\nin processing pipelines are tailored to conform to the schemas expected\nby multiple downstream systems:  \n\n```trickle  title=\"normalize.trickle\"\n# Prepare computed histogram summaries for downstream systems ( eg: telegraf/influx )\nselect {\n  \"measurement\": event.measurement,\n  \"tags\": event.tags,\n  \"fields\": {\n    \"count_#{event.class}\": event.stats.count,\n    \"min_#{event.class}\": event.stats.min,\n    \"max_#{event.class}\": event.stats.max,\n    \"mean_#{event.class}\": event.stats.mean,\n    \"stdev_#{event.class}\": event.stats.stdev,\n    \"var_#{event.class}\": event.stats.var,\n    \"p42_#{event.class}\": event.stats.percentiles[\"0.42\"],\n    \"p50_#{event.class}\": event.stats.percentiles[\"0.5\"],\n    \"p90_#{event.class}\": event.stats.percentiles[\"0.9\"],\n    \"p99_#{event.class}\": event.stats.percentiles[\"0.99\"],\n    \"p99.9_#{event.class}\": event.stats.percentiles[\"0.999\"]\n  }\n}\nfrom normalize\ninto out;\n```\n\nCompared to the disparate services and software elements that tremor\nreplaces - the query language affords an intuitive and easy to reason\nabout high level domain specific language to configure rich event\nprocessing and data enrichment and transformation pipelines - with a\nminimally terse yet easy to read form.\n\n## Conclusion\n\nTremor’s core mission and mandate includes the efficient declaration of\narbitrarily complex directed-acyclic pipeline processing graphs that are\nmemory and compute efficient under the hood whilst preserving\ntransparency or remaining `hidden` to most of the developers in our\norganization by continuing to conform to external transports, protocols\nand service interfaces in the surrounding production infrastructure\nestate."
    },
    {
      "id": "/2021/11/03/data-distribution",
      "metadata": {
        "permalink": "/blog/2021/11/03/data-distribution",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-03-data-distribution.md",
        "source": "@site/blog/2021-11-03-data-distribution.md",
        "title": "Case Study - Data Distribution",
        "description": "Happened Before",
        "date": "2021-11-03T00:00:00.000Z",
        "formattedDate": "November 3, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 5.355,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Data Distribution",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Data Flow with Tremor",
          "permalink": "/blog/2021/11/04/data-flow"
        },
        "nextItem": {
          "title": "Case Study - Traffic Shaping",
          "permalink": "/blog/2021/11/02/traffic-shaping"
        }
      },
      "content": "## Happened Before\n\nAfter the initial production success of tremor as a point solution for capacity\nmanagement during our peak trading cycles at Wayfair, the focus shifted a little\nto the next key set of issues with our traditional observability platforms.\n\nThe simplified architecture of our logging systems is currently:  \n  \n![old pipeline](./media/data-distribution/image1.png)\n\nThe traffic shaping use case was a huge win for Wayfair's SRE and operational\nteams who manage our production estate.\n\n## Identified Need\n\nBut we could do a lot better. The development lifecycle to capture, normalize,\nenrich, enhance and standardize logs from 1000's of engineers, 1000's of applications\nbuilt in a diversity of programming languages was a have task for our observability\nengineers.\n\nTheir environment still looks pretty grim:\n\n![new pipeline](./media/data-distribution/image3.png)\n\nDisplace and replace a plethora of in-house, open-source and commercial\noff the shelf log capture, metrics capture and data distribution\ntechnologies with a single cost-effective at hyperscale dynamically\nload-adaptive solution.\n\nThe decision was taken to expand the processing capabilities of tremor beyond\ntraffic shaping, classification and rate limiting rules to general purpose\ndata processing of unstructured hierarchic JSON-like data streams. The shape\nof data most common within the observability domain we were focused upon.\n\n## Required Outcome\n\nOur systems specialists and service reliability engineers can\nconsolidate knowledge and tune to a unified operating experience and\ncenter of excellence in our production estate based on a single well\nknown and cost efficient easy to operate alternative.\n\n### Characteristics\n\nIt is understood that data will be captured from and distributed to a\ndiverse and ever-changing set of production systems - built in many\nprogramming languages and environments and distributed to an unknowable\nset of destination systems.  \n  \nThese systems include, but are not limited to: Graylog Extended Log\nFormat, Syslog,  \nKafka, TCP, UDP, Telegraf, Influx Line Protocol, ElasticSearch and many\nmore...\n\n> Connectivity must be flexible enough to capture data from and\n> distributed data to synchronous, asynchronous protocols, transports\n> and systems without developers needing to learn or integrate with a\n> new technology. The solution must be invisible to developers.\n\nThe unit economics of the existing system is hard to measure, hard to\nplan and hard to remediate; especially given the rising year on year\nfirehose volumetrics, with rising velocity and rising peak loads.\n\n> 99% of the data either originates as JSON, or is transformed to JSON\n> just in time.\n\nThe target systems for displacement and replacement have very well\nunderstood and extract, load, transform, enrichment and normalization\nalgorithms that are coded and configured differently in each system.\nThis is difficult to maintain, enhance and evolve in an environment\nwhere infrastructure and services are continuously evolving.\n\n> A rich set of ETL and data manipulation and mutation primitives are\n> required so that all existing methods used for data processing across\n> the target systems can be replaced by a single easy to understand,\n> easy to program and optimized alternative.\n\n### Solution\n\nTremor has already established itself in the traffic shaping domain in\nthe logging and metrics domains - adding just-in-time traffic shaping\ncapabilities when needed; and preserving the original system’s\noperational semantics and behaviours during normal operating conditions\nwhen the system is operating within planned capacity constraints.\n\n![new pipeline](./media/data-distribution/image2.png)\n\nThe mandate now expands to replacing many of our event capture systems\ndeployed on on-premise and cloud-native operating environments across\nmultiple data-centres globally.\n\nInstead of our operations and service reliability teams needing to learn\nand manage the service deployment and administrative lifecycle of\nmultiple components in this evolution we displace and replace those\nsystems - typically operating as sidecars on source systems where our\napplications run on virtual machines, bare metal or containerized\nenvironments with tremor.\n\nThe relatively primitive domain specific language developed as part of\nthe initial solution for traffic shaping is replaced with a new domain\nspecific language `tremor-script` designed for expressive data\nfiltration, extraction, enrichment and transformation to support:\n\n-   Classification, Categorization and rate limiting for Traffic Shaping\n-   Enrichment, Normalization and micro-format parsing\n-   Structural pattern matching over hierarchical nested JSON-like data\n-   The ability to patch, merge and iterate over JSON-like data\n-   A familiar expression language like in regular programming languages\n    with arithmetic, multiplicative and other common operations on\n    numeric and string data\n-   Testing string encoded data for regular expression and other\n    micro-formats such as the logstash `grok`, `dissect`, `kv`\n    or stringified embedded json\n\nThe resulting language and interpreter for `tremor-script` forms the\nbasis of the solution and is largely designed around the needs of the\nlogging domain - but delivered in a more generally useful incarnation\nthat is more widely applicable to other domains - such as in flight data\nanalytics, in flight ETL or processing metrics to name a few.\n\nMost of the in-flight events are JSON or JSON-like. Inspired by a tweet\nthe tremor team happens upon the work of Daniel Lemire et al and\nSIMD-accelerated JSON processing. Heinz ports this to rust and tremor’s\nsister project and organization simd-lite is born. The tremor team also\nmaintains the rust port of simd-json with other maintainers interested\nin fast and efficient data parallel parsing of JSON.\n\nFinally, tremor undergoes a steady pace of innovation with benchmark\ndriven performance optimizations. The combined effect of an efficient\ninterpreter, the ability to easily benchmark synthetic analogs of real\nworld use cases in our benchmark system, and the adoption of more\nworkload appropriate and efficient low level memory allocators such as\n`jemalloc`, then `mimalloc`, then `snmalloc` by Microsoft Research\nresults an order of magnitude level of infrastructure cost savings. The\nproduction estate shrinks by 10x in terms of the number of deployed\nsystems, the compute capacity required, and the committed memory\nrequired when compared to the displaced and replaced systems.  \n  \nFurther - tremor uses far less memory and resources on the source\nsystems making it a much improved sidecar on our source hosts.\n\n## Conclusion\n\nTremor’s core mission and mandate now extends from high quality of\nservice data distribution with load-adaptive traffic management for the\n1% ( and typically less ) of time our systems are under-resourced; and,\nthe other 99% of the time is 10x more cost efficient.\n\nTremor preserves its facility to remain invisible to developers during\nthis phase of expansion whilst drastically improving the lives of our\noperational engineers and service reliability engineers. The measured\nand validated cost-efficiencies offer compounding value that further\ndrives the mandate of the project and pushes it into its next phase of\nevolution."
    },
    {
      "id": "/2021/11/02/traffic-shaping",
      "metadata": {
        "permalink": "/blog/2021/11/02/traffic-shaping",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-02-traffic-shaping.md",
        "source": "@site/blog/2021-11-02-traffic-shaping.md",
        "title": "Case Study - Traffic Shaping",
        "description": "Happened Before",
        "date": "2021-11-02T00:00:00.000Z",
        "formattedDate": "November 2, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 4.265,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Case Study - Traffic Shaping",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Data Distribution",
          "permalink": "/blog/2021/11/03/data-distribution"
        },
        "nextItem": {
          "title": "Wayfair Case Study",
          "permalink": "/blog/2021/11/01/wayfair-case-studies"
        }
      },
      "content": "## Happened Before\n\nThis is our origin story. The simplified high level architecture of our\nlogging systems at  the time of tremor’s birth is:\n\n![old pipeline](./media/traffic-shaping/image1.png)\n\n## Identified Need\n\nEnable load shedding and consistent capacity management at production\nscale of the logging and metrics firehoses within Wayfair’s production,\nstaging and development environments; even when our live production\nworking set exceeds planned capacity, but especially when catastrophic\nfailure of infrastructure overwhelms our storage tier.\n\n## Required Outcome\n\nOur network operations center, system reliability and service\norganization engineers should never be in a position where in-flight\nmission-critical events are unavailable or lagging ( seconds or even\nminutes ) the live working set state of our production systems.\n\nStale operational events direct limited resources under time constraints\nand production service level objective pressures to curing or tending to\nthe wrong problems, at the wrong times and lead to missed opportunities\nfor early and cheap resolution.\n\n### Characteristics\n\nIt is understood that, if a critical system ( such as a production\ndatabase ) fails - query failures won’t have a single point of origin in\nthe logs - whether over time, or across application or business units.\nWhen under extreme load beyond capacity - only a subset of the firehose\nis required for in-flight diagnostics of our production estate.\n\n> In-flight categorization, classification & rate limiting enables\n> **just-in-time traffic shaping**, load-shedding and bending critical\n> infrastructure to available capacity even as capacity   changes in\n> planned or surprising ways.\n\nIt is understood that, regardless of the system state - that some logs\nfrom a subset of systems, applications or services are relatively more\nimportant than others. This is even more true when our systems and\nservices are under extraordinary strain due to unplanned failures and\noutages. Unplanned failures and outages are expected at Wayfair\nproduction scale.\n\n> The **relative priority** of classified and categorized events is known\n> and the relative priority is subject to change over time, as are the event\n> classifications and categorizations.\n\nIt is likely impossible to convince thousands of engineers in hundreds\nof teams across our technology organization to stop using JSON format in\nthe short, medium and possibly even longer term.\n\nSnot. It’s a JSON rock’n’roll world. I guess we’ll just have to deal\nwith it\n\n### Solution\n\nThis works fine 99% of the time - but under extreme load it just does\nnot work at our scale and the impact to our network operations and\nservice reliability and technical communities is severe at the exact\nmoments when we are at peak trading periods and impact to the business\nis highest - a perfect storm.\n\n![old pipeline](./media/traffic-shaping/image2.png)\n\nIn our ELK ( ElasticSearch, Logstash, Kibana ) based logging and Influx\n( Telegraf, Chronograf, InfluxDB ) based metrics environments there are\nlimited means to dynamically tune the production system to accommodate\nhighly variant working sets. As we are an online eCommerce system we\noften go through sustained periods of nominal activity followed by\ninsane periods of extreme peak activity - often hitting peaks we’ve\nnever before experienced.\n\nWe do however, have a very experienced infrastructure and platform\nengineering organization that are deeply attuned to our working set and\nchanging business and operational needs.\n\nThe initial version of tremor simply preserved the overall pipeline:\n\n-   Applications in a number of programming languages generate logs\n-   A Logstash sidecar receives, normalizes and forwards logs to\n    elasticsearch\n-   ElasticSearch indexes logs for display by SRE’s and developers in\n    Kibana\n\nThe processing stages remained unchanged ( and largely serviced by\nLogstash ):\n\n-   Enrich raw logs with business unit, organization, application and\n    environment metadata\n-   Normalize schemas - map logs to a common structure and well known\n    field names\n-   Known unknowns - isolate user defined fields and extensions to a\n    well known slush field\n\nBut added an extra processing stage, a tremor cluster that added\nback-pressure detection and load-adaptive rate-limiting based on\nin-flight analysis of the business events in the firehose based on\nreal-time categorization and classification of those event streams.\n\nNow, in the ( significantly less than 1% ) of time when our systems are\nover-capacity or experiencing catastrophic unplanned events - tremor can\n*discard* events based rate limits and event classifications that can be\ntuned by our SRE, NOC and systems architects and developers.\n\n## Conclusion\n\nTremor’s core mission and mandate started out with, and continues to be\nthe non-functional quality of service of mission critical at scale event\nbased systems. Providing system operators with first class means to\nshape and tune capacity, load and production countermeasures of the\nproduction firehose without compromising the business with system\ndowntime is the core requirement.\n\nThe most effective way to achieve this in a highly fluid and ever\nchanging environment is what has yielded the tremor project as it became\nto be - a general purpose event processing system designed for at scale\ndistributed mission critical systems.\n\nWhen at or over capacity systems no longer bend to the business - tremor\nis how we inject a little elasticity into our production quality of\nservice - enriching our systems and services with just-in-time\nload-adaptive bendability.\n\n![new pipeline](./media/traffic-shaping/image3.png)"
    },
    {
      "id": "/2021/11/01/wayfair-case-studies",
      "metadata": {
        "permalink": "/blog/2021/11/01/wayfair-case-studies",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-11-01-wayfair-case-studies.md",
        "source": "@site/blog/2021-11-01-wayfair-case-studies.md",
        "title": "Wayfair Case Study",
        "description": "wayfair",
        "date": "2021-11-01T00:00:00.000Z",
        "formattedDate": "November 1, 2021",
        "tags": [
          {
            "label": "case-study",
            "permalink": "/blog/tags/case-study"
          },
          {
            "label": "wayfair",
            "permalink": "/blog/tags/wayfair"
          }
        ],
        "readingTime": 6.025,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Wayfair Case Study",
          "tags": [
            "case-study",
            "wayfair"
          ],
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "image": "./media/wayfair.png",
          "draft": false,
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Case Study - Traffic Shaping",
          "permalink": "/blog/2021/11/02/traffic-shaping"
        },
        "nextItem": {
          "title": "Property Based Testing of Tremor Script",
          "permalink": "/blog/2021/07/06/Blog-Rohit-Property-Based-Testing"
        }
      },
      "content": "![wayfair](./media/wayfair.png)\n\nDevelopment on Tremor started in the autumn of 2018 as a point solution\nfor introducing a configurable traffic-shaping mechanism for our\ninfrastructure platform engineering organization.\n\nThere were two use cases being considered at the time- the traffic-shaping use case, which had the highest priority; and a distributed data replication use case for our Kafka-based environments.\n\n## The Origin of Tremor\n\nThe [Traffic Shaping](./2021-11-02-traffic-shaping.md)\nuse case required that log information streaming from various systems be\ncategorized and classified in-flight, so that temporally bound rate\nlimits could be applied when our production estate has a\nworking set that is in excess of our current capacity. As a\n24x7x365 eCommerce environment with year-on-year higher peaks,\nhigher volumetrics and higher loads on our systems, this is a frequent\noccurrence. Tremor was designed to remove the burden of scaling these\nsystems from our system reliability and network operations center\nengineers.  \n  \nThis use case saw the birth of Tremor, which was delivered in 6 weeks,\njust in time for Cyber 5 (the long bank-holiday weekend in the US centered around Thanksgiving,\nwhere US folk go peak shopping!). At the time, Tremor was inflexible; only\nsupported connectivity to Kafka for Ingres and Elasticsearch downstream; and, the classification\nand rate-limiting logic was more or less hardwired- but it worked flawlessly!\n\nAlthough designed with our logging systems in mind, our metrics systems\nteam saw that Tremor would work for their environment (InfluxDB downstream rather than Elasticsearch, but the logic was\nbasically the same). Tremor was designed to detect backpressure on downstream systems, and to intelligently- based on user defined\nlogic- react by adaptively tuning the data distribution to\nselectively discard or forward data based on a classification system and rate limits.\n\n## The Rise of Event Processing\n\nThe user-defined logic required by our logging and metrics teams very\nquickly became sophisticated. A fairly quick succession of releases saw\nthe logic change from fairly simple filtering, classification (enrichment)\nand rate limiting (selective dropping due to backpressure) to richer needs to slice and dice nested JSON-like data, to normalize\nthese datasets. This rising need for sophistication in processing along with the adoption of Tremor to replace Logstash and other log shipping frameworks in our\nsource nodes, and to replace Telegraf in our metrics environments, gave birth to Tremor as an [event processing engine](./2021-11-03-data-distribution.md) in its own right.\n\nWith richer programming primitives, Tremor advanced from traffic shaping,\nand log and metrics shipping to log and metrics cleansing, normalisation,\nenrichment and transformation, to impose a common symbology and structure\non logs and metrics generated from many different programming languages,\nplatforms and tools across our production estate- from system logs\noriginated via Syslog, to those via GELF, or Prometheus.\n\nThe YAML-based configuration of the query pipelines quickly became error-prone and cumbersome as the sophistication, complexity and size of\napplication logic grew. In addition, the success of our scripting\nlanguage, [tremor-script](docs/0.11/tremor-script/index),\nand its hygienic set of tooling and IDE integration encouraged the addition a\nquery language, thus enabling [data flow processing](./2021-11-04-data-flow.md) with Tremor.\n\n## Cloud Native Migration\n\nAt the same time, our technology organisation was preparing for migration\nfrom on-premise data centres to cloud-based systems. Our legacy VM-based\nsystems were now being containerised and deployed via Kubernetes in our\non-premise environments. Simultaneously, our Cloud-native infrastructure, configuration as code,\nsecrets management, developer scaling and many other infrastructure and\ndevelopment platform teams were building out the services that would\nallow our line of business service engineers to migrate to the cloud.\n\nTremor was already battle-hardened as a sidecar deployment, and this was\nextended to Cloud-native deployments by our kubernetes team who packaged\nTremor for kubernetes as a set of [helm charts](./2021-11-05-kubernetes-sidecars.md).\n\nAs a relatively fast-paced technology organisation, our logging and\nmetrics teams weren’t stalled- the scripting and query languages\nenabled rapid development. However, lack of native support in Tremor to\nmodularise and reuse logic became a limiting factor. Thus, over the span of approximately a year, most of the [modularity mechanisms](./2021-11-06-modularity.md), now standard in Tremor, were developed.\n\nTremor was now battle-tested, battle-hardened and widely adopted, having\ngone through many enhancements and replacing many disparate tools and\nframeworks with a single, easy-to-operate solution.  \n  \nTremor is the first major component of in-house critical infrastructure\nthat was open-sourced by Wayfair and contributed to the Linux Foundation\nunder the Cloud Native Computing Foundation.\n\nThe Tremor team then selected a panel of experts and friends, who had early\naccess to Tremor, to assist with the open-sourcing process.\n\n## Tremor Today\n\nToday, Tremor is planned and progresses in the open. Anyone can\ncontribute, and with contribution comes maintainership. Tremor is now a CNCF\ncommunity (sandbox) project, and maintainership has grown beyond\nWayfair.\n\nAt Wayfair, Tremor has been adopted for our search environments. Our\nsearch domain has some complex use cases for audited document\nelementisation and indexing that are multi-participant and that need to\noccur transactionally.\n\nTremor’s QoS mechanisms were extended to support [transaction orchestration](./2021-11-07-search.md) to enable this and similar use cases. Our search teams are also\nleveraging Tremor for its traditional areas of strength in traffic\nshaping and adaptive rate limiting.\n\nOur logging and metrics teams are now recalibrating our technology\norganisation's philosophy and core infrastructure that supports\nobservability across our production estate. The rise of CNCF\nOpenTelemetry offers developers a consistent and stable set of\nprimitives for logs, metrics and distributed tracing. It’s a lingua\nfranca that offers developers consistency.  \n  \nEven more important to large or extreme scale organisations is\nflexibility to make infrastructure and service decisions based on\ncapacity, cost, or other concerns. Through CNCF OpenTelemetry as a core\nbuilding block, now natively supported in Tremor, our observability\nteams can now unify our production support, operations and services\naround Tremor-based OpenTelemetry- preserving the key values that\nTremor adds, whilst opening up the Cloud Native new possibilities that\nOpenTelemetry and [OpenTelemetry-based services](./2021-11-08-uop.md) offer.\n\n## Tremor Tomorrow\n\nAs the tremor community grows, we have seen great contributions from the\ngrowing tremor community adding support for many different types of\nsystems - ranging from the addition of AMQP support by Nokia\nCommunications through to our ongoing collaboration with Microsoft\nResearch on the `snmalloc` allocator which tremor defaults to. \n\nThe latest production solution based on tremor at Wayfair is from our\nDeveloper Platforms technology organization - who have used an extension\nto PHP to identify [dead code](./2021-11-09-php-dead-code-detection.md) in our legacy PHP monolith. This solution is\nbased on tremor and included contributions to tremor in the form of the\n`unix_socket` connectivity. Thank you Ramona!\n\nThe Tremor maintainers also work on the Rust port of simd-json- SIMD\naccelerated JSON, which is a sister project to Tremor. Mentorships via\nthe Linux Foundation are also producing some wonderful new capabilities\nand enhancements to the system, ranging from better support for\ndeveloping gRPC-based connectors in Tremor, to GCP connectivity,\nor work to add a plugin development kit to Tremor.  \n  \nWayfair is already benefiting from community interest and contributions\nto the project - and the Tremor team has hired its newest member as a\nresult of open-sourcing the project. We are hoping to package and open-source more components of Wayfair’s Tremor-based systems through the\nTremor Project, and through other open-source projects at Wayfair\nthrough our new Open Source Program Office.\n\nIf you are interested, hop on over to our [community chat\nserver](https://chat.tremor.rs/) and say hello!"
    },
    {
      "id": "/2021/07/06/Blog-Rohit-Property-Based-Testing",
      "metadata": {
        "permalink": "/blog/2021/07/06/Blog-Rohit-Property-Based-Testing",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-07-06-Blog-Rohit-Property-Based-Testing.md",
        "source": "@site/blog/2021-07-06-Blog-Rohit-Property-Based-Testing.md",
        "title": "Property Based Testing of Tremor Script",
        "description": "Rohit's Experience working with Tremor as a LFX Spring 2021 Mentee.",
        "date": "2021-07-06T00:00:00.000Z",
        "formattedDate": "July 6, 2021",
        "tags": [
          {
            "label": "testing",
            "permalink": "/blog/tags/testing"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          },
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          },
          {
            "label": "tremorscript",
            "permalink": "/blog/tags/tremorscript"
          }
        ],
        "readingTime": 7.495,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "Rohit Dandamudi",
            "title": "Tremor 2021 Spring Mentee",
            "url": "https://www.linkedin.com/in/kurious-diru/"
          }
        ],
        "frontMatter": {
          "title": "Property Based Testing of Tremor Script",
          "author": "Rohit Dandamudi",
          "author_title": "Tremor 2021 Spring Mentee",
          "author_url": "https://www.linkedin.com/in/kurious-diru/",
          "tags": [
            "testing",
            "mentorship",
            "cncf",
            "tremorscript"
          ],
          "draft": false,
          "hide_table_of_contents": false,
          "description": "Rohit's Experience working with Tremor as a LFX Spring 2021 Mentee."
        },
        "prevItem": {
          "title": "Wayfair Case Study",
          "permalink": "/blog/2021/11/01/wayfair-case-studies"
        },
        "nextItem": {
          "title": "Support for the Syslog Protocol",
          "permalink": "/blog/LFX-Blog-Nupur"
        }
      },
      "content": "### Introduction\n\nHey, I am [Rohit Dandamudi](https://www.linkedin.com/in/kurious-diru/) from India, about to complete my undergrad in CSE and will be working as a Software Engineer soon. I will be sharing my expereince at Tremor :)\n\n### Main motivation for applying\n\nMy work involved writing \"Property-based tests for tremor-script\" and some of the reasons for applying are:\n\n- It involved a new type of testing I never heard of\n- Be part of a sandbox project where I can learn and grow with the community\n- The concept of learning Erlang + Rust was very interesting to me and frankly out of my comfort zone, as a person used to Python and web development in general.\n\n### New concepts I learned specific to my work\n\n<!-- alex ignore his -->\n- Erlang and Rust\n    - My work mostly revolved around Erlang and a little Rust and I was completely new to this ecosystem, it didn't help to not find much resources or actively accessible community for Erlang.\n    - I took this as a challenge and went through [various resources to learn Erlang](https://github.com/diru1100/learn_erlang), functional programming in general and I was able to see why this Language was involved to do the task at hand, [my mentor](https://twitter.com/heinz_gies) is very passionate about Erlang and shared his thought-process, experience which helped me broaden my knowledge and how to approach any concept while learning something completely new.\n\n<!--truncate-->\n\n- Tremor-script\n    - It is an interpreted expression-oriented language designed for the filtering, extraction, transformation and streaming of structured data in a stream or event-based processing system which is explicitly turing incomplete used to write programs specific to Tremor use-cases.\n    - It is written using Rust but tested using Erlang\n- Property based testing\n    - We have seen various types of testing approaches like Unit testing, Integration testing, End2End testing etc.\n    - The purpose of tests is to check if our code is failing anywhere and test the same with various inputs.\n    - Fig 1 shows different types of tests to help understand which features are specialised in what.\n\n        ![](/img/blog-images/LFC-blog-diru/tests-comparison-graph.png)\n\n        Fig 1. Showing various tests wrt Feature compilance and Input scope covered [1]\n\n    - Property based testing takes a new appraoch which has the right balance of randomness and examples. They also have this nice feature of called shrinking which shows a simplified version of sample input which is failing your tests. However, Property based testing is not an ideal solution to use everywhere but it fits our use-case here i.e testing features of a custom-language.\n    - Some of the resources I kept below may help understand Property based testing better\n\n### Property Based testing in tremor-script\n\n- Property based testing is implemented using [EQC](http://quviq.com/documentation/eqc/)\n- Quickcheck is the original library written for Haskell to do property based testing ( similar to xUnit for unit-tests) and EQC is the Erlang version of it\n- Erlang quickcheck or EQC is the version used here\n    - Implemented by QuviQ\n    - Free version is [quickcheck mini](http://www.quviq.com/downloads/)\n- Components in Property based test\n    - Property is an abstraction of a test case\n    - Properties are written in erlang in tremor\n- The files shown in Fig 2 make the [eqc part of Tremor](https://github.com/tremor-rs/tremor-runtime/tree/main/tremor-script/eqc)\n\n    ![](/img/blog-images/LFC-blog-diru/eqc-files.png)\n\n    Fig 2. Files related to eqc\n\n    - **gen_script:** This file contains functions which create the structure of the expected expression for a partticular feature/operation that we will be testing in tremor-script\n    - **model.erl:** Here, we run the model specification of each operation implemented in Erlang natively.\n    - **pbt.erl:** Some supporting headers needed by other files\n    - **spec.erl:** We make use of EQC functions here to create the input generators to test a feature.\n    - **test_eqc.erl:** The main property of the property based test is kept here.\n    - **util.erl:** Utility functions to support operations for easier handling.\n- On a high level Fig 3 explains how the property we consider is checked\n\n![](/img/blog-images/LFC-blog-diru/tremor-script-testing-workflow.png)\n\nFig 3. Highlevel overview of Property based testing in termor-script\n\n### Example thought process\n\n- Here, I will explain about property based testing by going through a step-by-step approach on how a Property based test is written for an operation in termor-script\n- [Patch](docs/0.11/tremor-script/index#patch) is a operation in tremor-script that is performed on Expressions(everthing in tremor-script is an expression :p ) which contains multiple record(data-type) level field operations to be applied to a target record in order to transform a targetted record.\n- As patch has multiple operations inside it which have to be seperately created in every step, here is where the concept of incremental implementation comes into picture, if one makes sures if the PatchOperation is implemented before, we can take advantage of that here. For example: Merge is a seperate operation on records but it also is one of the patch operation.\n- gen_script.erl: The following code creates the structure needed for a patch operation as shown in Fig 4.\n\n    ![](/img/blog-images/LFC-blog-diru/patch-structure.png)\n\n    Fig 4. Diagram showing Patch operation [4]\n\n    ```erlang\n    %% the input are 'patch' keyword, an Expression \n    %% and the Operation to be performed\n    gen_({patch, Expr, PatchOperation}) ->\n        [\"(\", \"patch \", gen_(Expr), \" of \",\n         lists:join(\",\",\n    \t\t[[patch_operation(Operation)]\n    \t\t || Operation <- PatchOperation]),\n         \" end\", \")\"];\n    ```\n\n- model.erl:\n    - One of the ast_eval function in this file matches with patch_operation where the following input is passed  ```{patch, Expr, PatchOperation}```.\n    - An anonymous function is there to update the PatchOperatoin into the respective structure needed for us to evaluate.\n    - At the end we take advantage of floding in lists to implemente the Erlang implementation to get the required output.\n\n    ```erlang\n    % Operations covered by the folowing patch_operation are\n    % {merge, Value}\n    % {merge, Key, Value}\n    % {insert, Key, Value}\n    % {upsert, Key, Value}\n    % {update, Key, Value}\n    % {erase, Key}\n\n    patch_operation({insert, Key, Value}, Acc) ->\n        maps:put(Key, Value, Acc);\n    patch_operation({merge, Key, Value}, Acc) ->\n        maps:fold(fun combine_values/3, #{Key => Value}, Acc);\n    patch_operation({upsert, Key, Value}, Acc) ->\n        % does what we expect from upsert\n        maps:put(Key, Value, Acc);\n    patch_operation({erase, Key}, Acc) ->\n        maps:remove(Key, Acc).\n\n    -spec ast_eval(#vars{}, {}) -> {#vars{},\n    \t\t\t\tinteger() | float() | boolean() | binary()}.\n\n    ast_eval(#vars{} = S, {patch, Expr, PatchOperation}) ->\n        {_, ExprUpdate} = ast_eval(S, Expr),\n        UpdatdPatchOperation = lists:map(fun ({erase, Key}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {erase, UpdatedKey};\n    \t\t\t\t\t ({merge, Key}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {merge, UpdatedKey};\n    \t\t\t\t\t ({insert, Key, Value}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {_, UpdatedValue} = ast_eval(S,\n    \t\t\t\t\t\t\t\t\t  Value),\n    \t\t\t\t\t     {insert, UpdatedKey, UpdatedValue};\n    \t\t\t\t\t ({upsert, Key, Value}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {_, UpdatedValue} = ast_eval(S,\n    \t\t\t\t\t\t\t\t\t  Value),\n    \t\t\t\t\t     {upsert, UpdatedKey, UpdatedValue};\n                         ({update, Key, Value}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {_, UpdatedValue} = ast_eval(S,\n    \t\t\t\t\t\t\t\t\t  Value),\n    \t\t\t\t\t     {update, UpdatedKey, UpdatedValue};\n    \t\t\t\t\t ({merge, Key, Value}) ->\n    \t\t\t\t\t     {_, UpdatedKey} = ast_eval(S, Key),\n    \t\t\t\t\t     {_, UpdatedValue} = ast_eval(S,\n    \t\t\t\t\t\t\t\t\t  Value),\n    \t\t\t\t\t     {merge, UpdatedKey, UpdatedValue};\n    \t\t\t\t\t (X) -> X\n    \t\t\t\t     end,\n    \t\t\t\t     PatchOperation),\n        {S,\n         lists:foldl(fun patch_operation/2, ExprUpdate,\n    \t\t UpdatdPatchOperation)};\n    ```\n\n- spec.erl:\n    - The randomised input that we provide to test patch-feature comes from here, patch falls as a unary operation which can be performed on a records and has sub operations.\n    - The randomisation is obtained by the frequency function we calls different generators.\n\n    ```erlang\n    % Operations generated by patch_operation\n    % {merge, Value}\n    % {merge, Key, Value}\n    % {insert, Key, Value}\n    % {upsert, Key, Value}\n    % {update, Key, Value}\n    % {erase, Key}\n    patch_operation(S, N) ->\n        frequency([{1,\n    \t\t{insert, spec_inner_string(S, N - 1),\n    \t\t spec_inner_no_float(S, N - 1)}},\n    \t       {1,\n    \t\t{upsert, spec_inner_string(S, N - 1),\n    \t\t spec_inner_no_float(S, N - 1)}},\n    \t\t {1,\n    \t\t{update, spec_inner_string(S, N - 1),\n    \t\t spec_inner_no_float(S, N - 1)}},\n    \t       {1,\n    \t\t{merge, spec_inner_string(S, N - 1),\n    \t\t spec_inner_record(S, N - 1)}},\n    \t       {1, {erase, spec_inner_string(S, N - 1)}},\n    \t\t   {1, {merge, spec_inner_string(S, N - 1)}}]).\n\n    % spec_uop_record function returns {patch, generated_record, patch_operations}\n    spec_uop_record(S, N) when N =< 1 ->\n        ?SHRINK({patch, literal_record(S, N - 1),\n    \t     ?SUCHTHAT(X, (list(1, patch_operation(S, N - 1))),\n    \t\t       (length(X) >= 1))},\n    \t    [literal_record(S, N - 1)]);\n    spec_uop_record(S, N) ->\n        ?SHRINK({patch, spec_inner_record(S, N - 1),\n    \t     ?SUCHTHAT(X, (list(1, patch_operation(S, N - 1))),\n    \t\t       (length(X) >= 1))},\n    \t    [spec_inner_record(S, N - 1)]).\t\n    ```\n\n### Ending thoughts and future plans:\n\nAll in all, I had/will have wonderful time at Tremor. Over the past 3-months I learned how to learn new tech-stack, got developer wisdom and understood what truely working as a team is. I want to thank Heinz, Matthias, Darach and Ana for making it fun, collaborative and inclusive environment. Although, I didn't had a lot of knowledge in this area before, I am now confident I have the right mindset to pickup new things and grow together with the team.\n\nI would like to continue contributing to the project and explore the rust part of it more. Apart from that I want to take more responsibilty, engage with new-comers and be part of other CNCF community events.\n\n---\n\n### Other resources I compiled while going through the mentorship which y'all might find useful 🙂\n\n1. [Introduction to Property Based Testing](https://medium.com/criteo-engineering/introduction-to-property-based-testing-f5236229d237)\n2. [Why isn't functional programming the norm](https://www.youtube.com/watch?v=QyJZzq0v7Z4)\n3. [https://github.com/kurious-diru/learn_rust](https://github.com/kurious-diru/learn_rust)\n4. [Tremor script patch](docs/0.11/tremor-script/index#patch)\n5. Better to use tools: \n    - * cat - bat - [https://github.com/sharkdp/bat](https://github.com/sharkdp/bat)\n    - * grep - ripgrep - [https://github.com/BurntSushi/ripgrep](https://github.com/BurntSushi/ripgrep)\n    - * top - htop - [https://github.com/hishamhm/htop](https://github.com/hishamhm/htop)\n    - * hexdump - hexyl - [https://github.com/sharkdp/hexyl](https://github.com/sharkdp/hexyl)\n6. Related to EQC:\n    - [https://www.erlang-factory.com/upload/presentations/19/quickchecktutorial_tartsjhughes.pdf](https://www.erlang-factory.com/upload/presentations/19/quickchecktutorial_tartsjhughes.pdf)\n    - Resources mentioned in this issue [https://github.com/tremor-rs/tremor-runtime/issues/721](https://github.com/tremor-rs/tremor-runtime/issues/721)"
    },
    {
      "id": "LFX-Blog-Nupur",
      "metadata": {
        "permalink": "/blog/LFX-Blog-Nupur",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-07-05-LFX-Blog-Nupur.md",
        "source": "@site/blog/2021-07-05-LFX-Blog-Nupur.md",
        "title": "Support for the Syslog Protocol",
        "description": "Nupur's experience contributing to Tremor and work overview.",
        "date": "2021-07-05T00:00:00.000Z",
        "formattedDate": "July 5, 2021",
        "tags": [
          {
            "label": "codecs",
            "permalink": "/blog/tags/codecs"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          },
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          }
        ],
        "readingTime": 3.855,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "Nupur Agrawal",
            "title": "Tremor 2021 Spring Mentee"
          }
        ],
        "frontMatter": {
          "title": "Support for the Syslog Protocol",
          "slug": "LFX-Blog-Nupur",
          "author": "Nupur Agrawal",
          "author_title": "Tremor 2021 Spring Mentee",
          "tags": [
            "codecs",
            "mentorship",
            "cncf"
          ],
          "categories": [
            "general"
          ],
          "draft": false,
          "hide_table_of_contents": false,
          "description": "Nupur's experience contributing to Tremor and work overview."
        },
        "prevItem": {
          "title": "Property Based Testing of Tremor Script",
          "permalink": "/blog/2021/07/06/Blog-Rohit-Property-Based-Testing"
        },
        "nextItem": {
          "title": "Google Cloud Storage and Pub/Sub Connectors",
          "permalink": "/blog/2021/06/29/T17-LFX-Blog-Jigyasa-gcloud"
        }
      },
      "content": "## Introduction\n\nHey folks, I am Nupur Agrawal, a third year student at Indian Institute of Technology Roorkee. This blog describes my experience of contributing to Tremor,\nCNCF sandbox project in the 2021 spring chapter of [LFX Mentorship Program](https://lfx.linuxfoundation.org/tools/mentorship/), under the mentorship of\nMatthias Wahl, Anup Dhamala and Heinz Gies.\n\n## Project Abstract\n\n[Tremor](https://www.tremor.rs/) is an event processing system originally designed for the needs of platform engineering and infrastructure. It is built for\nthe users that have a high message volume to deal with and want to build pipelines to process, route, or limit this event stream.\n\n<!-- alex ignore he -->\nAt the beginning of the program, I was given walkthrough of the project by Matthias and he patiently explained me the components and working of tremor.\nTremor is nicely documented and the [docs](https://www.tremor.rs/) can be very useful for referring many things.\n\n## My Project\n\nMy project's aim was to enable tremor to receive and send [Syslog Protocol Messages](https://tools.ietf.org/html/rfc5424), a standard protocol used to send \nsystem log or event messages. It was desired to support both the standard IETF format and the old BSD format via UDP and TCP/TLS. More detailed description\ncan be found [here](https://github.com/tremor-rs/tremor-runtime/issues/12).\n\n<!--truncate-->\n\n## Work-Summary\n\n### Syslog codec (support via UDP)\n\nThe syslog codec encodes and decodes sylog messages (IETF and BSD format) to and from `Value` respectively. Tremor can now receive syslog data via UDP (onramp) and turn syslog messages into structured events. Also, structured events can be turned into textual syslog messages and send out via UDP (offramp).\n\nFor example, the following Syslog message \n\n```text\n<165>1 2021-03-18T20:30:00.123Z mymachine.example.com evntslog - ID47 [exampleSDID@32473 iut=\\\"3\\\" eventSource=\\\"Application\\\" eventID=\\\"1011\\\"] BOMAn\napplication event log entry...\"\n```\n\ngets translated to:\n\n```json\n{\n  \"severity\": \"notice\",\n  \"facility\": \"local4\",\n  \"hostname\": \"mymachine.example.com\",\n  \"appname\": \"evntsog\",\n  \"msg\": \"BOMAn application event log entry...\",\n  \"procid\": null,\n  \"msgid\": \"ID47\",\n  \"protocol\": \"RFC5424\",\n  \"protocol_version\": 1,\n  \"structured_data\": {\n              \"exampleSDID@32473\" :\n              [\n                {\"iut\": \"3\"},\n                {\"eventSource\": \"Application\"},\n                {\"eventID\": \"1011\"}\n              ]\n            },\n  \"timestamp\": 1616099400123000000\n}\n```\n\nCode for the syslog codec can be found [here](https://github.com/tremor-rs/tremor-runtime/pull/856).\n\n### textual-length-prefix pre and postprocessor \n\nIn order to support syslog messages over TCP, it was needed to add support for the [RFC 5425](https://datatracker.ietf.org/doc/html/rfc5425) transport protocol, that contains a textual length prefix before each message.\ntextual-length-prefix `preprocessor` and `postprocessor` were implemented to handle the buffers accordingly. The message starts with a number of digits, denoting the message length followed by a space and then the message. The processor gets the length and then wait until the buffer is long enough, to extract the right amount of bytes.\nThe implementation can be found [here](https://github.com/tremor-rs/tremor-runtime/pull/957).\n\n[Proptest](https://github.com/altsysrq/proptest) is something new and amazing I learnt while working on this. It is a property testing framework which allows to test certain properties of code for arbitrary inputs. We utilised this for testing the functioning of our preprocessor for all types of inputs possible.\n\n### TLS support for TCP\n\nUnlike UDP, Tremor did not support TLS over TCP onramp, which was needed to add. This work can be broadly divided into two parts:\n\n**Add support for receiving TLS encrypted data via TCP onramp**\n\n`tls` option was added to the tcp onramp configuration options which addresses the keys and certificate required for authentiction.\n\nAn example of TCP onramp config with TLS is as follows:\n\n```yaml\nonramp:\n  - id: tls\n    type: tcp\n    preprocessors:\n      - lines\n    codec: string\n    config:\n      host: \"127.0.0.1\"\n      port: 65535\n      tls:\n        cert: \"path/to/cert.pem\"\n        key: \"path/to/key.pem\"\n```\n\nThe code can be found [here](https://github.com/tremor-rs/tremor-runtime/pull/1055).\n\n**Add support for sending TLS encrypted data via TCP offramp**\n\n`tls` option added to offramp tls config contains either the tls config or boolean value indiacting the use of TLS session for transport level encryption. If false is provided then the default TCP stream will be used and if true is provided then TLS stream will be used with default certificates and domain same as hostname. Other option is to provide tls config with `domain` and `cafile`. In case of `domain` not being specified, the hostname will be used.\n\nAn example of TCP offramp config with TLS:\n\n```yaml\nofframp:\n  - id: tls\n    type: tcp\n    codec: json\n    config:\n      host: \"127.0.0.1\"\n      port: 65535\n      tls:\n        cafile: \"path/to/cafile\"\n```\n\nThe code can be found [here](https://github.com/tremor-rs/tremor-runtime/pull/1057).\n\n## Concluding Thoughts\n\nThe tremor community is very helpful and friendly. The mentors helped me a lot from silly rust doubts to nerve breaking code debugging and testing. There were periodic code reviews and live coding sessions which motivated me to improvise and keep going. The key focus was always on the learning rather than getting the work done.\n\nIt was undoubtedly one of the most fruitful and learning experiences I had have and I wish to continue the contribution to community and project."
    },
    {
      "id": "/2021/06/29/T17-LFX-Blog-Jigyasa-gcloud",
      "metadata": {
        "permalink": "/blog/2021/06/29/T17-LFX-Blog-Jigyasa-gcloud",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-06-29T17-LFX-Blog-Jigyasa-gcloud.md",
        "source": "@site/blog/2021-06-29T17-LFX-Blog-Jigyasa-gcloud.md",
        "title": "Google Cloud Storage and Pub/Sub Connectors",
        "description": "Jigyasa's LFX spring Mentorship experience report.",
        "date": "2021-06-29T00:00:00.000Z",
        "formattedDate": "June 29, 2021",
        "tags": [
          {
            "label": "connectors",
            "permalink": "/blog/tags/connectors"
          },
          {
            "label": "mentorship",
            "permalink": "/blog/tags/mentorship"
          },
          {
            "label": "cncf",
            "permalink": "/blog/tags/cncf"
          },
          {
            "label": "gpc",
            "permalink": "/blog/tags/gpc"
          }
        ],
        "readingTime": 12.335,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "Jigyasa Khaneja",
            "title": "Tremor 2021 Spring Mentee"
          }
        ],
        "frontMatter": {
          "title": "Google Cloud Storage and Pub/Sub Connectors",
          "author": "Jigyasa Khaneja",
          "author_title": "Tremor 2021 Spring Mentee",
          "tags": [
            "connectors",
            "mentorship",
            "cncf",
            "gpc"
          ],
          "draft": false,
          "hide_table_of_contents": false,
          "description": "Jigyasa's LFX spring Mentorship experience report."
        },
        "prevItem": {
          "title": "Support for the Syslog Protocol",
          "permalink": "/blog/LFX-Blog-Nupur"
        },
        "nextItem": {
          "title": "Releasing Tremor v0.10!",
          "permalink": "/blog/2021/02/12/v010-release"
        }
      },
      "content": "### Introduction\n\n<!--alex ignore gals-men gals-men -->\nHello folks! I'm Jigyasa, a final-year computer science engineering student at Indira Gandhi Delhi Technical University for Women pursuing my bachelor's in Technology. This blog is about my experience contributing to [Tremor](https://www.tremor.rs/) as part of the LFX Mentorship program.\ni\n### Learning about Tremor\n\nTremor is an event processing system for unstructured data with rich support for structural pattern matching, filtering, and transformation. It is built for users that have a high message volume to deal with and want to build pipelines to process, route, or limit this event stream. It has a scripting language called tremor-script and a query language as well called tremor-query or trickle.\n\nI had never worked on an event processing system before this internship. In fact, my first major contribution to open-source was through this mentorship program. To get started with it, my mentor [Darach Ennis](https://www.linkedin.com/in/darach-ennis-789866?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_all%3BnRZIYeLfRAWJpWsDNlzweA%3D%3D), suggested me some documents that helped me learn more about it:\n\n[/docs/overview/ (deprecated)](https://github.com/tremor-rs/tremor-www-docs/blob/main/docs/overview.md)\n\n[/docs/course (deprecated)](https://github.com/tremor-rs/tremor-www-docs/tree/main/course)\n\nApart from that, learning more about the tremor-query, tremor-script, and going through the workshops in the docs can be really helpful.\n\nThe codebase of Tremor is in Rust, and since I had no prior experience with Rust, I started learning the language.\n\n<!--truncate-->\n\n### Learning Rust\n\nGetting started with Rust was very intimidating. It involved working with things like memory management, borrow checker, lifetimes, and the expressive types which was very new to me and hence, confusing\n\nWhile getting started with a new language, I try to follow along some interactive tutorials/videos. These are some resources that I found helpful: \n\n[https://serokell.io/blog/learn-rust](https://serokell.io/blog/learn-rust)\n\n[https://fasterthanli.me/articles/a-half-hour-to-learn-rust](https://fasterthanli.me/articles/a-half-hour-to-learn-rust)\n\n[https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)\n\nHowever, while coding I used to run into a lot of errors. My mentor suggested me a good practice which is to document those errors and always make good notes of anything and everything I learn. So the next time I come across something similar, I can refer to my notes instead of searching that up on the internet. I used to document the little things like a new `vi` or `git` command that I learned and found helpful. It's also very important to keep those notes organized so that it's faster and easier to find what you're looking for. Compiling notes of all the new things learned in a day can be very helpful.\n\nAt times when I used to get stuck with some Rust errors, I used to reach out to my mentor or anyone from the Tremor community and they would help me. Apart from that, these discord servers can be of great help too:\n\n[Rust programming language community server](https://discord.gg/rust-lang-community)\n\n[Firepit](https://discord.gg/4BUXJEB2)\n\n### My Project\n\nMy task during the internship was to add support for the Google Cloud connectors in Tremor. I worked on adding the Google Cloud Storage and Google Cloud Pub/Sub connectors. A detailed description of it can be found here:\n\n[https://github.com/tremor-rs/tremor-runtime/issues/724](https://github.com/tremor-rs/tremor-runtime/issues/724)\n\nBefore explaining more about it, here's what a connector involves:\n\n**Sources:** Ingest data from the outside world and deserialise to events ( onramps )\n\n**Sinks:** Send serialised events to the outside world ( offramps )\n\nConnectors serve the purpose of sending events to and receiving events from the outside world. A connector can be an event `source` (a.k.a. `onramp`) or an event `sink` (a.k.a. `offramp`) or both.\n\n![Connector](/img/blog-images/LFX-blog-jigyasa/connector.png)\n\n#### Google Cloud Storage connector:\n\nI wrote a GCS sink that can issue the basic GCS Operations such as list buckets and objects, create, insert and delete objects from the Google Cloud Platform cloud storage service. The docs can be found here: [GCS offramp docs](/docs/0.11/artefacts/offramps#gcs)\n\n#### Google Cloud Pub/Sub connector:\n\nThe gpub sink can issue the operation of sending a message to a Google Cloud Pub/Sub topic. It also allows creating a subscription to a topic to receive messages in it, with the option to enable/disable message ordering. The gsub source allows receiving messages via a subscription in batches as well as one after another. The docs can be found here:\n[gpub offramp](/docs/0.11/artefacts/offramps#gpub) and [gsub onramp](/docs/0.11/artefacts/onramps#gsub)\n\n## Walk-Through Guide\n\nTo get started, you need a service account on GCP and you will need a GCP pem file for certificates authentication and a service token json file.\n\nThe command used to get the service token `json` file:\n```bash\ngcloud iam service-accounts keys create key-file.json -iam-account=<iam-account-name>@<project-id>.iam.gserviceaccount.com\n```\nor \n```bash\ngcloud iam service-accounts keys create key-file.json -iam-account=<mail-id-of-service-account>\n```\n\nGo to GCP dashboard → IAM & Admin → Service Accounts and get the email-id mentioned which is the `<mail-id-of-service-account>`\n\n### Google Cloud Storage\n\nThe following is a usage example of the gcs connector. The following files are required:\n\n**outbound.trickle**\n\n```trickle\nselect event from in into out\n```\n\n**inbound.trickle**\n\n```trickle\nselect event from in into out\n```\n**test.yaml**\n\n```yaml\nofframp:\n  - id: stdout\n    type: stdout\n    codec: json\n    config:\n  - id: gcs\n    type: gcs\n    codec: json\n    postprocessors:\n      - gzip   \n    preprocessors:\n      - gzip \n    linked: true\n    config:\n      pem: <path-to-pem-file>\nonramp:\n  - id: stdin\n    type: file\n    codec: json\n    config:\n      source: /dev/stdin   \nbinding:\n  - id: example\n    links:\n      '/onramp/stdin/{instance}/out':\n        - '/pipeline/outbound/{instance}/in'\n      '/pipeline/outbound/{instance}/out':\n        - '/offramp/stdout/{instance}/in'\n        - '/offramp/gcs/{instance}/in'\n      '/offramp/gcs/{instance}/out':\n        - '/pipeline/inbound/{instance}/in'\n      '/pipeline/inbound/{instance}/out':\n        - '/offramp/stdout/{instance}/in'\nmapping:\n  \"/binding/example/passthrough\":\n    instance: \"passthrough\"\n```\nThe above config receives `json` on stdin, sends it to Google Cloud Storage service (and stdout) and writes the response received from GCS (since `linked: true`) to stdout.\n\nThe instance variable (in the binding) is replaced by the value passthrough in the mapping upon deployment, so it is possible to define multiple bindings (deployments) for a single mapping (template).\nSupported preprocessors, that can be configured in yaml file can be found here: [preprocessors](/docs/0.11/artefacts/preprocessors). Supported postprocessors and more about it: [postprocessors](/docs/0.11/artefacts/postprocessors).\nSupported codecs, that can be configured in yaml file can be found here: [codecs](/docs/0.11/artefacts/codecs)\n\n- Set the env variable\n\n```bash\nexport GOOGLE_APPLICATION_CREDENTIALS=\"<path-to-service-token-json-file>\"\n```\n\n- Command used to run tremor:\n\n```bash\ntremor server run -f outbound.trickle inbound.trickle test.yaml | jq .\n```\nFor a detailed guide on the Operations that can be performed, refer the [docs](/docs/0.11/artefacts/offramps#gcs).\n\n### Google Cloud Pub/sub\n\nGoogle Cloud Pub/Sub guarantees delivery of all messages, whether low throughput or high throughput, so there should be no concern about messages being lost.\n\nPub/Sub guarantees at-least-once message delivery, which means that occasional duplicates are to be expected since we acknowledge the messages once they are received.\n\nThe following is a usage example of the pub/sub connector. These are the files required:\n\n**outbound trickle:** \n\n```trickle\nselect event from in into out\n```\n\n**inbound.trickle:**\n\n```trickle\nselect {\"data\": event, \"meta\": $} from in into out;\n```\n\n**test.yaml:**\n\n```yaml\nofframp:\n  - id: stdout\n    type: stdout\n    codec: json\n    config:\n  - id: gpub\n    type: gpub\n    codec: json\n    postprocessors:\n      - gzip    \n    linked: true \n    config:\n      pem: <path-to-pem-file>\nonramp:\n  - id: stdin\n    type: file\n    codec: json\n    config:\n      source: /dev/stdin  \n  - id: gsub\n    type: gsub\n    codec: json  \n    preprocessors:\n      - gzip\n    config:\n      pem: <path-to-pem-file>\n      subscription: '<name-of-subscription>'\nbinding:\n  - id: example\n    links:\n      '/onramp/stdin/{instance}/out':\n        - '/pipeline/outbound/{instance}/in'\n      '/pipeline/outbound/{instance}/out':\n        - '/offramp/stdout/{instance}/in'\n        - '/offramp/gpub/{instance}/in'\n      '/offramp/gpub/{instance}/out':\n        - '/pipeline/inbound/{instance}/in'\n      '/pipeline/inbound/{instance}/out':\n        - '/offramp/stdout/{instance}/in'\n      '/onramp/gsub/{instance}/out':\n        - '/pipeline/inbound/{instance}/in'\nmapping:\n  \"/binding/example/passthrough\":\n    instance: \"passthrough\"\n```\nThe above config receives `json` on stdin, sends it to Google Pub/sub service (and stdout) and writes the response received from Google Pub/sub (since `linked` is set to true) to stdout. At the same time, it also receives the messages for the configured subscription from Google pub/sub and writes those messages to stdout.\n\nSupported preprocessors, that can be configured in yaml file can be found here: [preprocessors](/docs/0.11/artefacts/preprocessors).\nSupported postprocessors and more about it: [postprocessors](/docs/0.11/artefacts/postprocessors). \nSupported codecs, that can be configured in yaml file can be found here: [codecs](/docs/0.11/artefacts/codecs)\n\n![Tremor Dot Diagram](/img/blog-images/LFX-blog-jigyasa/dot-diagram.png)\n\n- Create a topic using the following `gcloud` command:\n\n```bash\ngcloud pubsub topics create <topic-name>\n```\n\n- Set the env variable\n\n```bash\nexport GOOGLE_APPLICATION_CREDENTIALS=\"<path-to-service-token-json-file>\"\n```\n\n- Command used to run tremor:\n\n```bash\ntremor server run -f outbound.trickle inbound.trickle test.yaml | jq .\n```\n\nRefer to the [gpub](/docs/0.11/artefacts/offramps#gpub) and [gsub](/docs/0.11/artefacts/onramps#gsub) docs to perform opertaions.\n<!-- docs on the website are not updated rn! -->\n<!-- REMOVING IT BECAUSE IT'S IN THE DOCS\n- After running tremor, create a subscription:\n\n```bash\n{\"command\": \"create_subscription\", \"project\": \"<project-id>\", \"topic\": \"<topic-name>\", \"subscription\": \"<name-of-subscription>\", \"message_ordering\": <`message-ordering`>}\n```\n\n*where:*\n\n***<`message-ordering`>** - can be set to `true` or `false` . To receive the messages in order, set the message ordering property on the subscription you receive messages from. Receiving messages in order might increase latency.*\n\n***<`project-id`>** - id of the GCP project*\n\n***<`topic-name`>** - Name of the Pub/Sub topic*\n\n- To send a message:\n\n```bash\n{\"command\": \"send_message\", \"project\":\"<project-id>\", \"topic\":\"<topic-name>\", \"data\": <`data`>, \"ordering_key\": \"<ordering-key>\"}\n```\n\n*where:*\n\n***<`data`>** - `json` message to be sent to the topic*\n\n***<`ordering-key`>** - If non-empty, identifies related messages for which publish order should be respected. If a Subscription has enable_message_ordering set to true, messages published with the same non-empty ordering_key value will be delivered to subscribers in the order in which they are received by the pub/sub system. All PubsubMessages published in a given PublishRequest must specify the same ordering_key value.* -->\n\n## Testing for gsub onramp (Pub/sub)\n\nGoogle Cloud Pub/Sub guarantees delivery of all messages and also preserves the order of messages if the subscription has `message-ordering` set.\n\nHowever, we wish to test the property of guranteed delivery and message-ordering for gsub in events like poor network connectivity. In order to test, before sending the message to pub/sub, we add a field `count` in the event (json) that increments every time we send a message. This would be done in the outbound trickle file. To validate that all the messages are received in order, we have a validation logic in the inbound trickle file that checks if the difference between the `count` value of the current message and the previous message is one, the order is maintained.\n\nFor this purpose, we also use a write-ahead log or `wal` that builds on circuit breaker and acknowledgement mechanisms to provide guaranteed delivery. The write-ahead log is useful in situations where sources/onramps do not offer guaranteed delivery themselves, but the data being distributed downstream can benefit from protection against loss and duplication.\n\nWe have 3 different configurations for the outbound trickle file - using a [transient wal](https://github.com/tremor-rs/tremor-www/docs/0.11/recipes/transient_gd), [persistent wal](https://github.com/tremor-rs/tremor-www/docs/0.11/recipes/persistent_gd) and no wal. The cofigurations are as follows:\n\n**No wal**\n\n```trickle\ndefine script counter\nscript\n  let count = match state==null of\n    case true =>\n      0\n    default =>\n      state.count + 1\n  end;\n\n  let state = {\"count\": count};\n  {\"command\": \"send_message\", \"project\":\"<project-id>\", \"topic\":\"<topic-name>\", \"data\": merge event of {\"count\": state.count} end, \"ordering_key\": \"<ordering-key>\"}\nend;\n\ncreate script counter;\n\nselect event from in into counter;\nselect event from counter into out;\n```\n\n**Transient-wal**\n\n```trickle\ndefine qos::wal operator in_memory_wal\nwith\n  read_count = 20,\n  max_elements = 1000, # Capacity limit of 1000 stored events\n  max_bytes = 10485760 # Capacity limit of 1MB of events\nend;\n\ncreate operator in_memory_wal;\n\ndefine script counter\nscript\n  let count = match state==null of\n    case true =>\n      0\n    default =>\n      state.count + 1\n  end;\n\n  let state = {\"count\": count};\n  {\"command\": \"send_message\", \"project\":\"<project-id>\", \"topic\":\"<topic-name>\", \"data\": merge event of {\"count\": state.count} end, \"ordering_key\": \"<ordering-key>\"}\nend;\n\ncreate script counter;\n\nselect event from in into counter;\nselect event from counter into in_memory_wal;\nselect event from in_memory_wal into out;\n```\n\n**Persistent-wal**\n\n```trickle\ndefine qos::wal operator on_disk_wal\nwith\n  read_count = 20,\n  max_elements = 1000, # Capacity limit of 1000 stored events\n  max_bytes = 10485760 # Capacity limit of 1MB of events\nend;\ncreate operator on_disk_wal;\n\ndefine script counter\nscript\n  let count = match state==null of\n    case true =>\n      0\n    default =>\n      state.count + 1\n  end;\n\n  let state = {\"count\": count};\n  {\"command\": \"send_message\", \"project\":\"<project-id>\", \"topic\":\"<topic-name>\", \"data\": merge event of {\"count\": state.count} end, \"ordering_key\": \"<ordering-key>\"}\nend;\n\ncreate script counter;\n\nselect event from in into counter;\nselect event from counter into on_disk_wal;\nselect event from on_disk_wal into out;\n```\n\nIn the **inbound** trickle, we have the validation logic as follows:\n\n```trickle\ndefine script validate\nscript\n  match state == null of\n    case true =>\n      let valid = match event.data.count == 0 of \n        case true =>\n          true      \n        default =>\n          false\n      end,\n      let state = {\"prev\": event.data.count},\n      {\"response\": event, \"valid\": valid} \n      \n    default =>\n      let valid = match state.prev + 1 == event.data.count of \n        case true =>\n          true\n        default =>\n          false\n      end,\n      let state = {\"prev\": event.data.count},\n      \n      {\"response\":event, \"valid\": valid}\n  end;\nend;\n\ncreate script validate;\n\nselect {\"data\": event, \"meta\": $} from in into validate;\nselect event from validate into out;\n```\n\nFor the testing, we run the sink (a.k.a offramp) to send messages and source (a.k.a onramp) to receive messages separately.\n\n![Testing gsub](/img/blog-images/LFX-blog-jigyasa/validation-testing-image.png)\n\n\n---\n***Note:***\n*On stopping the server and resarting right afterwards, we see that we lost 1 message (id 7) which was acknwledged inside tremor but not yet fully delivered to the console by gsub.*\n\n---\n\nIn all the 3 cases, we obtain similar results. We observe that on restarting tremor, we may lose in flight messages (events) that were already acknowledged at the time the server went down and thus not fully delivered by the downstream system. We may also observe duplicate messages (messages being received more than once). However, the order of messages is preserved. \nHence, for the `gsub` onramp, a `wal` can assist with partial recovery of downstream system but it is not guarenteed to be lossless.\n\n\n## Network Failure Recovery\n\n![Network Failure Recovery testing](/img/blog-images/LFX-blog-jigyasa/network-failure-testing.png)\n\nWhile testing in poor connectivity, the pivot point (where it works) was observed when downlink and uplink packets dropped varies between 47%-50%. \n\n## Use of Connectors\n\n- Bulk batch rolling event/log storage to GCS\n- Distribution of openTelemetry logs/trace/metrics over GCP pub/sub\n\n## The Tremor community\n\nThe Tremor community is absolutely great. As I was contributing to it as a part of my internship, I was lucky to have direct access to the Tremor developers working at Wayfair whenever I had any questions. We used to have a lot of meetings in the General Voice channel on discord with the Tremor developers and anyone could join in and ask questions, discuss ideas and share what they are working on. This used to be super helpful.\n\nApart from that, on the first Tuesday of every month we used to have office hours where everyone joins in and there used to be discussions on topics like: \"Why did tremor go open source\", \"Good practices for contributing to open-source\", and Q/As. They used to be a lot of fun.\n\nI am so grateful to my mentors: Darach, Heinz and Matthias for being super kind and always encouraging me to ask questions and clarifying all my doubts. Also, thanks to Ana for always being so nice and helping with my Rust errors. They all are amazing and I thank them for their time and help.\n\n## Final Thoughts\n\nIt was an overall great journey contributing to Tremor. I learned so much in these 3 months' time with the support of my mentors. I'm very grateful to CNCF for organizing this mentorship program as it gave me an opportunity to learn about event processing, distributed systems, Rust, Cloud-Native technologies, etc. I wouldn't have learned so much in these 3 months' time had I not been a part of this mentorship program. It was definitely a fun learning experience."
    },
    {
      "id": "/2021/02/12/v010-release",
      "metadata": {
        "permalink": "/blog/2021/02/12/v010-release",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2021-02-12-v010-release.md",
        "source": "@site/blog/2021-02-12-v010-release.md",
        "title": "Releasing Tremor v0.10!",
        "description": "Releasing Tremor v0.10.",
        "date": "2021-02-12T00:00:00.000Z",
        "formattedDate": "February 12, 2021",
        "tags": [
          {
            "label": "releases",
            "permalink": "/blog/tags/releases"
          }
        ],
        "readingTime": 4.53,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Releasing Tremor v0.10!",
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "releases"
          ],
          "draft": false,
          "description": "Releasing Tremor v0.10.",
          "hide_table_of_contents": false
        },
        "prevItem": {
          "title": "Google Cloud Storage and Pub/Sub Connectors",
          "permalink": "/blog/2021/06/29/T17-LFX-Blog-Jigyasa-gcloud"
        },
        "nextItem": {
          "title": "Releasing Tremor v0.9!",
          "permalink": "/blog/2020/10/16/v09-release"
        }
      },
      "content": "![v0.10](/img/blog/2021-02-19/tremor-release-0.10.jpg)\n\n<!---<span style=\"font-size: 16px; line-height: 24px; color: rgba(49, 52, 57, 0.65)\">Montage based upon photo by <a href=\"https://unsplash.com/@aberkecz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Ádám Berkecz</a> on <a href=\"https://unsplash.com/s/photos/dolphins?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>--->\n\n## Summary\n\nThis release is the last minor release before we start turning Tremor into a truly distributed event processing and data distribution engine. We focused on small things that improve usability and ironed out some rough edges here and there.\n\n## TL;DR\n\n* We extended our type system and codecs by the `binary` type.\n* Elasticsearch offramp now supports Linked Transport.\n* String interpolation done right, now with `#{}` instead of just `{}`\n* Release now includes prebuilt binaries, DEB packages and RPMs\n\n## New Release Artefacts\n\nTo make your life easier installing and Tremor more pleasant, we added new release artefacts. We've now got [prebuilt binaries](https://github.com/tremor-rs/tremor-runtime/releases/download/v0.10.0/tremor-0.10.0-x86_64-unknown-linux-gnu.tar.gz) wrapped up in a `tar.gz` for `amd64` linux, [DEB](https://github.com/tremor-rs/tremor-runtime/releases/download/v0.10.0/tremor_0.10.0_amd64.deb), and [RPM](https://github.com/tremor-rs/tremor-runtime/releases/download/v0.10.0/tremor-0.10.0-1.x86_64.rpm) packages. And, lets not forget our well-known [Docker Image](https://hub.docker.com/repository/docker/tremorproject/tremor).\n\n![install prebuilt binary](/img/blog/2021-02-19/2021-02-19_prebuilt_binary.gif)\n\nWe are going to explore more channels for release artefacts in the future to get you up and running with Tremor in no time.\n\nIn addition to those new release channels, we enabled thin-lto for all builds, which should improve compile-time while providing all the benefits of full link time optimization (LTO). We also link OpenSSL, now statically, to avoid incompatibilities with OpenSSL versions provided by the OS.\n\n<!--truncate-->\n\n## Binary Type and Binary Codec\n\nTremor is built for handling JSON-like structured data. It can effectively handle wire formats like JSON, YAML, msgpack and many more. We can represent them all with the same internal model of dynamic structured values. One blind spot up to now has been binary data. The reason for this was that most of the aforementioned formats do not support raw binary data (except msgpack). But times have changed.\n\nWith Tremor, you can now receive, assemble and send binary data. Receiving is done by configuring your onramp of choice with the `binary` codec. Imagine building a HTTP proxy with Tremor, that is not interested in the actual body payload but does its internal routing work only by looking at the headers. Previously, Tremor had to parse and deserialize the whole body payload. Now, it is able to conveniently pass those bytes through without ever touching them, and thus be even faster and more efficient for similar use cases.\n\nHere is an example config for the needed onramps and offramps;\n\n```yaml\nonramp:\n  - id: http_input\n    type: rest\n    codec: binary\n    linked: true\n    config:\n      host: 0.0.0.0\n      port: 8080\n\nofframp:\n  - id: http_output1\n    type: rest\n    codec: binary\n    linked: true\n    config:\n      endpoint: http://host01.example.com\n      method: GET\n```\n\nAnd here is a very simple corresponding pipeline:\n\n```trickle\nselect event\nfrom in\nwhere $request.method == \"GET\" && array::contains($request.headers[\"content-type\"], \"application/json\")\ninto out;\n```\n\nYou are able to assemble complex binary events from structured data within tremor-script itself, like TCP packets:\n\n```\nlet tcp_packet = <<\n  event.src.port:16,  event.dst.port:16,\n  event.seq:32,\n  event.ack:32,\n  event.offset:4, event.res:4, event.flags:8, event.win:16,\n  event.checksum:16, event.urgent:16,\n  event.data/binary\n>>;\n```\n\n## Elasticsearch Offramp as Linked Transport\n\nWe enhanced our [`elastic` offramp](https://docs.tremor.rs/artefacts/offramps/#elastic) to emit 1 event back to Tremor for each document indexed to Elasticsearch, be it successful or not. You will get all the Elasticsearch metadata like the `_version` and `_id` of the indexed document and also the whole payload to be indexed, which is especially useful in the face of indexing errors, e.g. from mismatched document schemas.\n\nAn `elastic` offramp configured like this:\n\n```yaml\nofframp:\n  - id: elastic\n    type: elastic\n    linked: true\n    config:\n      nodes:\n        - elastic01:9200\n        - elastic02:9200\n        - elastic03:9200\n```\n\nwill, for an event like this:\n\n```json\n{\"data\": [1, 2, 3]}\n```\n\nsend you back a response payload like this if everything went well via the offramps `out` port:\n\n```json\n{\n    \"source\": {\n        \"event_id\": \"1:0:0\",\n        \"origin\": \"tremor-file://root/data.json\"\n    },\n    \"payload\": {\n        \"data\": [1, 2, 3]\n    },\n    \"success\": true\n}\n```\n\nwith the following document metadata in `$elastic`:\n\n```json\n{\n    \"id\": \"TxQutncB0ovN9WdBcg2i\",\n    \"index\": \"tremor_test\",\n    \"doc_type\": \"_doc\",\n    \"version\": 1\n}\n```\n\nAnd, in case indexing failed, you would get an event like this via the offramps `err` port:\n\n```json\n{\n   \"source\": {\n        \"event_id\": \"1:0:0\",\n        \"origin\": \"tremor-file://root/data.json\"\n    },\n    \"payload\": {\n        \"data\": [1, 2, 3]\n    },\n    \"success\": false,\n    \"error\": {\n        \"caused_by\": {\n            \"reason\": \"Current token (VALUE_NUMBER_INT) not of boolean type\\n at [Source: (byte[])\\\"POST //_bulk HTTP/1.1\\r\\ncontent-type: application/json\\r\\ncontent-length: 346\\r\\nuser-agent: reqwest/0.9.24\\r\\naccept: */*\\r\\naccept-encoding: gzip\\r\\nhost: 127.0.0.1:9200\\r\\n\\r\\n{\\\"index\\\":{\\\"_index\\\":\\\"tremor_test\\\",\\\"_type\\\":\\\"_doc\\\"}}\\n{\\\"data\\\":\\\"[1, 2, 3]\\\"}\\n\\\"[truncated 10 bytes]; line: 1, column: 13]\",\n            \"type\": \"json_parse_exception\"\n        },\n        \"reason\": \"failed to parse field [data] of type [boolean] in document with id 'TxQutncB0ovN9WdBcg2i'. Preview of field's value: '1'\",\n        \"type\": \"mapper_parsing_exception\"}\n}\n```\n\nSuch an error message will also contain the same metadata behing the `$elastic` metadata key.\nHaving detailed error data and the original payload at hand will enable users to handle success and error in new ways: Retries in case of errors, signalling upstream applications, try something completely different with that event payload.\n\n## String Interpolation Done Right\n\nWe changed the syntax for string interpolation to now use `#{}` for interpolating arbitrary expressions into a string literal, as we discovered some quirks in how it worked before (with `{}`). Creating JSON object strings `{\"key\": \"value\"}` or regex quantifiers `[1-9][0-9]{2, 3}` have been inconvenient to write and there were surprises together with using the `string::format` function.\n\nWhere we previously had written:\n\n```tremor\nlet json_string = \"\"\"\n{{ \"key\": \"value\"}}\n\"\"\";\nlet regex = \"[1-9][0-9]\\{2, 3\\}\";\n```\n\nwe can now express as:\n\n```tremor\nlet json_string = \"\"\"\n{ \"key\": \"value\"}\n\"\"\";\nlet regex = \"[1-9][0-9]{2, 3}\";\n```\n\nwhich is much better e.g. for templating purposes.\n\n## Questions/Comments\n\nOn the Community Discord: https://chat.tremor.rs"
    },
    {
      "id": "/2020/10/16/v09-release",
      "metadata": {
        "permalink": "/blog/2020/10/16/v09-release",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2020-10-16-v09-release.md",
        "source": "@site/blog/2020-10-16-v09-release.md",
        "title": "Releasing Tremor v0.9!",
        "description": "Releasing Tremor v0.9",
        "date": "2020-10-16T00:00:00.000Z",
        "formattedDate": "October 16, 2020",
        "tags": [
          {
            "label": "releases",
            "permalink": "/blog/tags/releases"
          }
        ],
        "readingTime": 7.34,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "The Tremor Team",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Releasing Tremor v0.9!",
          "author": "The Tremor Team",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "releases"
          ],
          "draft": false,
          "hide_table_of_contents": false,
          "description": "Releasing Tremor v0.9",
          "image": "/img/blog/2020-10-16/v0.9.png"
        },
        "prevItem": {
          "title": "Releasing Tremor v0.10!",
          "permalink": "/blog/2021/02/12/v010-release"
        },
        "nextItem": {
          "title": "To async or Not to async",
          "permalink": "/blog/2020/08/06/to-async-or-not-to-async"
        }
      },
      "content": "## Summary\n\n![v0.9](/img/blog/2020-10-16/v0.9.png)\n\n[Tremor](https://www.tremor.rs/) is an open source event processing and data distribution engine designed to interpose or intercept data in complex systems primarily to inject quality of service, correct data flows and to enrich or support complex traffic shaping, routing and load-balancing based on contextual, situational or content derived dynamic conditions.\n\nTremor has a powerful ETL language designed for flexibly pattern matching structured data such as JSON efficiently (SIMD-accelerated), and a declarative flow-based SQL language designed for rich JSON-like data to describe data processing and data flow graphs with declarative QoS constraints.\n\nTremor has been in large scale global production at Wayfair for 2 years now, and is gaining adoption in other organizations.\n\nIn this release, we return to Tremor’s roots and focus on quality of service by adding linked-transports to interpose RPC-like and synchronous-blocking protocols. We add circuit breakers to manage upstream and downstream byzantine events, and we provide mechanisms that offer shades of delivery guarantees or intrinsic transactions that, when combined with suitable upstream or downstream systems, can produce lossless data transfers for certain routes whilst remaining best-effort for routes that do not support lossless delivery or recovery in and of themselves with minimal loss.\n\nLastly, but most importantly, this is the first release of Tremor as a Linux Foundation/CNCF early-stage sandbox project. We would like to thank everyone at Wayfair in Boston and Berlin, the Linux Foundation and the CNCF who facilitated, helped, nurtured, transitioned DNS entries and worked with the legals to make this transition to fully open governance happen. A huge thanks to Chris and Amye at the Linux Foundation.\n\n<!--truncate-->\n\n## TL;DR\n\nRead on for details after these headings:\n\n* Refactored Concurrency Model\n* Unified Command Line Interface\n* Linked Transports\n* Circuit Breakers & ‘Guaranteed’ Delivery\n* Behavioural Changes\n\nStop here, unless you like details.\n\n## Refactored Concurrency Model\n\nThe maturity of concurrency and synchronization primitives within the rust programming language has transformed massively over the past 18 months. As these primitives have now stabilised and libraries based on these primitives are now stabilising, we have migrated the tremor runtime model to be fully internally asynchronous, non-blocking and task-driven, where possible.\n\nThere are still code paths within tremor, such as in kafka adapters that integrate with native libraries where a configurable number of threads can be configured and spun up- but we no longer have a thread per pipeline model.\n\nThis means that tremor application designers can now configure, deploy and run 1000s of pipelines in the same instance of tremor. In concert with the modularity theme in tremor v0.8, the quality of life/service theme of v0.9 further expands the flexibility available to tremor application designers and operators to design very high performance and highly efficient data processing and distribution solutions based on tremor.\n\n![08_09_comparison](/img/blog/2020-10-16/08_09_comparison.png)\n\n*Feel the awesome power of asynchronous runtimes*\n\n## Unified Command Line Interface\n\nTremor has matured to the point that we have outgrown the legacy developer and operator tooling. In this release, we have unified, enhanced and extended developer and operator tooling to boldly go into a much improved quality of life for tremor users.\n\nThe new [unified command line tool](docs/0.11/operations/cli) `tremor` can generate auto-completion for your shell (anything from zsh to powershell), generate documentation for your modules, run Tremor, debug the language intermediate forms, and has benchmark, integration, command-driven and unit testing frameworks built in.\n\n![cli1](/img/blog/2020-10-16/cli1.gif)\n![cli2](/img/blog/2020-10-16/cli2.gif)\n\n<!-- alex ignore german -->\nEverything is syntax-highlighted and should conform to whichever theme you have running in your terminal. It’s like a universal tool - but more reliable because it's German but cool, because it's a Berliner(in the JFK, not cake sense...)\n\n## Linked Transports\n\n[Linked Transports](/docs/0.11/operations/linked-transports/) allow bidirectional event flows in a request/response style to be built and routed through a tremor pipeline. This enables Tremor users to introspect, route, or even directly reply to incoming messages and intercept and manipulate outgoing responses. Tremor can thus be used as proxy, load-balancer or API-Gateway before or in between existing REST APIs or websocket servers.\n\n\nUsers can now support and implement their own domain specific REST APIs that can interact with the wider ecosystem of systems interconnected with Tremor- roll your own control plane and consolidate to a single plane of control- without deploying a separate solution or service.\n\n![linked-transports](/img/blog/2020-10-16/linked-transports.png)\n\n(note: replies can only be delivered to feet in 0.9, we’re trying to extend that to other limbs in later releases).\n\n## Circuit breakers & “Guaranteed” delivery\n\nThe signal and contraflow control events within Tremor have been built upon in v0.9 to provide an event acknowledgement mechanism- this, in turn, provides the foundation for [guaranteed delivery and circuit breakers](/docs/0.11/operations/gdcb/), which enables finer-grained declarative quality of service mechanisms within tremor.\n\nWe can now configure Tremor applications or algorithms to `pick up where they left off` even if the tremor processes are stopped and restarted. Under certain conditions (based on configuration), we can recover entire end-to-end flows- such as the lossless distribution of messages across kafka sources and sinks regardless of which participant stops and restarts.\n\nIf you choose UDP, we cannot guarantee lossless delivery; but Tremor, even on a horrible quality network, should still minimise loss and recover gracefully- it won’t do so without message loss unless there’s some application-level handling of recovery.\n\nFully lossless transactional delivery is 10% the throughput of regular data distribution. It's as slow as Apache Kafka for now- but we will put effort into tuning performance here if the use case arises.\n\nCircuit breakers enable us to detect downstream system failures beyond backpressure, and make informed decisions: to either discard, reroute or stop dataflow. This allows a more ingrained control over behaviour in non-optimal conditions compared to “always drop” earlier tremor versions implemented.\n\nDelivery Guarantees describes a set of functionality that improves the delivery guarantees of a tremor system. What guarantees can be given depends heavily on the upstream and downstream systems, and the protocols used to communicate with them.\n\n![cb-gd](/img/blog/2020-10-16/cb-gd.gif)\n\n## Open Source Community Changes\n\nTremor’s proposal to to adjoin the CNCF as an early stage standbox project was accepted by the CNCF TOC, and formal onboarding into the CNCF began and completed on time in September. This means that the tremor project’s copyright is now held by the Linux Foundation on behalf of the maintainers.\n\nIn practice, what does this mean? Day to day, there is no impact- currently all maintainers of the tremor project are sponsored by Wayfair. But the project now also has the support of the Linux Foundation and the CNCF and this, in turn, makes it easier for external organizations to adopt and contribute to it in support of their own business needs and open source governance strategies.\n\nTremor is visible on the [CNCF Sandbox Project page](https://www.cncf.io/sandbox-projects/) and via the [CNCF Landscape](https://landscape.cncf.io/). The tremor project can now access development services from the CNCF and LF, ranging from artwork and website design through to visibility, marketing and promotion of the project at LF, CNCF and other conferences and events.\n\n## Behavioral Changes\n\n* **REST offramp/sink:**\n    * In an effort to streamline, the REST sink no longer adds newlines for batched events; this can now be done using the “lines” postprocessor.\n    * `put`, as an option, is no longer supported; instead, `method` is now used.\n    * Only supports one `endpoint` instead of multiple. The Round-robin operator with multiple offramps can be used as a much more capable replacement.\n\n* **Heredocs:**\n    * Leading indentation is no longer stripped.\n    * Heredocs now perform string interpolation, allowing it to be used for templating of textual content. In result, {and} needs to be escaped.\n\n\n* The **tremor-server**, **tremor-query**, **tremor-script**, and **tremor-tool** binaries are now all unified in the self-name **tremor** binary. The binary also replaces the legacy benchmark and integration testing frameworks: the 3rd party coyote command, test harness, and introduces a new unit testing facility for tremor-script. It’s one command to rule them all.\n\n\n* **Circuit breakers** are enabled and active by default- this is a significant behavioral change in sinks/offramps that completely disconnect; this will now stop the message flow on sources/onramps. Care should be taken in a production environment with non-resilient, non-robust and non-redundant downstream connectivity as this is now an operational concern that can benefit from a much finer-grained configuration surface.\n\n\n* The **generic::backpressure** operator has been renamed **qos::backpressure**. Using the old name will emit a warning in this release, but this backwards compatibility consideration will be addressed and the old name removed in the next release.\n\n* The operators **runtime::tremor**, **grouper::bucket** and **script** inside of **trickle** have their **error** output renamed **err**.\n\n* **Linked transports** introduce a source nature to sinks and a sink nature to sources. This feature is in preview mode and how to configure it is very likely to change as usability issues or misconceptions are ironed out. (v0.10)\n\n\n## Questions/Comments\n\nOn the our [discord server](https://chat.tremor.rs)."
    },
    {
      "id": "/2020/08/06/to-async-or-not-to-async",
      "metadata": {
        "permalink": "/blog/2020/08/06/to-async-or-not-to-async",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2020-08-06-to-async-or-not-to-async.md",
        "source": "@site/blog/2020-08-06-to-async-or-not-to-async.md",
        "title": "To async or Not to async",
        "description": "Moving from threads to async tasks.",
        "date": "2020-08-06T00:00:00.000Z",
        "formattedDate": "August 6, 2020",
        "tags": [
          {
            "label": "dev",
            "permalink": "/blog/tags/dev"
          },
          {
            "label": "rust",
            "permalink": "/blog/tags/rust"
          }
        ],
        "readingTime": 5.525,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "The Tremor Team",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "To async or Not to async",
          "author": "The Tremor Team",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "dev",
            "rust"
          ],
          "draft": false,
          "image": "/img/async.png",
          "description": "Moving from threads to async tasks."
        },
        "prevItem": {
          "title": "Releasing Tremor v0.9!",
          "permalink": "/blog/2020/10/16/v09-release"
        },
        "nextItem": {
          "title": "Rust & Tell Berlin- March 2020",
          "permalink": "/blog/2020/03/31/rust-and-tell"
        }
      },
      "content": "With the upcoming Tremor release, 0.9.0, we're moving from threads as a basis for ramps and pipelines to async tasks.\n\nLet's talk about why this is significant, what is changing, and how the architecture is changing.\n\nNote that this is not a comprehensive treatise on threads or async tasks.\n\n## The Tremor That Was (threads)\n\nThreads are a basic building block of programs that run multiple pieces of code concurrently.\nThe operating system is responsible for coordinating across competing resource demands.\n\nThe OS can preempt, pause, and resume threads. We can leverage infinite or tight loops without the risk of completely blocking the system. These guarantees make concurrent code more accessible, with tools like`crossbeam-channels` to build upon.\n\nThreads work especially well in use cases where the system and logical concurrency models are well aligned; or, we can map application threads to logical cores on the system being used. Each thread can happily work away on its part of the logic and pass the result on to the next. The one thread per core model is what tremor 0.8 and earlier used. We had a thread for the onramp, a thread for the pipeline, and a thread for the offramp. As the computational cost of decoding, processing, and encoding was often in the same ballpark, this worked exceptionally well. We managed to push up to 400MB/s of JSON through the system this way (including parsing, tremor-script logic, and serialization).\n\nThis design can degenerate badly if there are more ramps and pipelines than cores on the system in use. Throughput degrades rapidly (as in up to 2 orders of magnitude worse at 30:1 ratio). At the time of writing this, the deployment model was one pipeline/ramp group on a four-core system, so it worked well in practice.\n\nHowever, this places a burden on operators having to think about concurrency and parallelism to tune tremor for optimal performance and capacity.\n\nIn SMP systems, we observe other undesireable effects: The moment two communicating threads don't share the same underlying cache, performance plummets. This scenario exists when threads reside on two different CPUs or CCXs ([thank you AMD for making me learn so much about CPU caches](https://blog.licenser.net/2020/01/multithreaded-rust-on-threadripper/)). As long as two communicating threads share the same cache, data shared between them can avoid trips to main memory and cache coherency protocol overheads. When two threads communicate across different caches, reads/writes may catastrophically collide and introduce overheads that drastically reduce overall performance.\n\n<!--truncate-->\n\n## Async/Futures\n\nFutures, and in rust `async/await` (short async from here on), work differently than threads. With threads, the operating system has ultimate control over which thread is scheduled to work when. With async we can more flexibly manage scheduling in application code. This has many advantages in systems software.\n\nInstead of the operating system preempting a thread, tasks require coordination within the application. The advantage is that since we can control where we take a pause, we can provide soft guarantees that the thread of control yields to the task schedulers in a way that better fits the application. A good example is async-io, where we allow another task to work whenever we have to wait for some IO.\n\nIn Tremor, we use channels extensively to coordinate event flows. They connect sources, sinks, and pipelines. Every time a channel is empty or full, we have to wait for a event that fills or drains a now blocked channel: This is a good juncture to let other tasks get ahead with their work. In tremor, these opportunities are fairly common.\n\nThe cooperative model is not without issues: If we select the wrong time to let other tasks work, we can hurt performance or even break the system. Giving up control in the right moment is especially tricky since it is sometimes happening implicitly. A task that loops without yielding forever is an extreme example. In OS managed threads, the OS can preempt a thread of control, so this is a non-issue. In user-managed tasks, however, this is an issue that needs to be protected against.\n\nIn rust, calling `.await` is effectively, not a guarantee. We cannot know if an async function ever yields. We can ensure that we yield control via yield_now. However, this comes at a cost: namely, that we might yield in situations where it is not strictly necessary.\n\nWith regards to performance, tasks are typically cheaper from a context switching perspective, and we have finer grained control. On the other hand, we lose control over where a task runs, while we can pin threads to cores to schedule affinity on SMP systems, tasks may migrate across cores or runners move freely.\n\nIn Tremor, we have adopted the `smol` small and fast async runtime. When two tasks can run consecutively on the same executor, `smol` will schedule them in different executors. A significant improvement over the thread-based tremor runtime is that `smol` does not aggressively steal work from other schedulers if they are not overloaded. This avoids the runtime trashing CPU caches based on [micro-benchmarking results](https://github.com/async-rs/async-std/issues/848).\n\n## Behavioural Improvements\n\nIn previous releases of Tremor, the runtime focused on situations where applications had a limited and bounded number of stable long-lived concurrent pipelines in each instance. While multiple running artefacts were supported, in practice, tremor was deployed on systems with up to 4 logical cores.\n\nThis works exceptionally well with plain old threads. Starting with v0.9, Tremor is expanding to support an arbitrary number of running artefacts in a typical running instance, with a different logical core topology than production deployments to date.\n\nDeploying a higher number of pipelines per instance changes our needs of the underlying concurrency mechanisms considerably. The plain old threads design will no longer scale to meet these changing requirements and the move to task-based scheduling with executors favours emerging workloads whilst incurring a negligible overhead to classic tremor workloads.\n\n## Initial Results\n\nAb initio, the switch has some practical implications, mainly an improvement in performance.\n\nIn Tremor v0.8.0, colocating pipelines required careful capacity planning and tuning by experienced operators. In tremor v0.9.0, this constraint has been lifted and the capacity planning burden drastically simplified. Improvements in `smol` itself over the last few versions means that we have broken the 500MB/s throughput barrier for the first time with the new task-based runtime, which is quite a nice bonus.\n\nLet's end with some pretty graphs. After all, a picture says more than a thousand words.\n\nAs a short explanation, this uses the json-throughput benchmark we have developed for Tremor running with deployments of one onramp, one pipeline, and one offramp to 64 onramps, 64 pipelines, and one offramp.\n\n![3 core performance](/img/blog/2020-08-06/async-3-cores.png)\n\n![48 core performance](/img/blog/2020-08-06/async-48-cores.png)"
    },
    {
      "id": "/2020/03/31/rust-and-tell",
      "metadata": {
        "permalink": "/blog/2020/03/31/rust-and-tell",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2020-03-31-rust-and-tell.md",
        "source": "@site/blog/2020-03-31-rust-and-tell.md",
        "title": "Rust & Tell Berlin- March 2020",
        "description": "Presenting Tremor at Rust & Tell Berlin- March 2020.",
        "date": "2020-03-31T00:00:00.000Z",
        "formattedDate": "March 31, 2020",
        "tags": [
          {
            "label": "talks",
            "permalink": "/blog/tags/talks"
          }
        ],
        "readingTime": 0.265,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Rust & Tell Berlin- March 2020",
          "author": "The Tremor Team",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "talks"
          ],
          "draft": false,
          "hide_table_of_content": false,
          "image": "/img/rust&tell.jpg",
          "description": "Presenting Tremor at Rust & Tell Berlin- March 2020."
        },
        "prevItem": {
          "title": "To async or Not to async",
          "permalink": "/blog/2020/08/06/to-async-or-not-to-async"
        },
        "nextItem": {
          "title": "Improving our Influx Parser- A Story in Four Acts",
          "permalink": "/blog/2020/03/06/influx-perf"
        }
      },
      "content": "We had the great pleasure of spending some time with the crowd of Rust & Tell today. At the meetup, we got the chance to share some of the stories of tremor and Event Processing Cartography. Long story short, if you're curious, the talk was [recorded](https://youtu.be/43KS_nCqiIM?t=1932), and we got [the slides](/slides/2020-03-31-RustAndTellBerlin-functions.pdf) right here!"
    },
    {
      "id": "/2020/03/06/influx-perf",
      "metadata": {
        "permalink": "/blog/2020/03/06/influx-perf",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2020-03-06-influx-perf.md",
        "source": "@site/blog/2020-03-06-influx-perf.md",
        "title": "Improving our Influx Parser- A Story in Four Acts",
        "description": "The process of improving the performance of our influx line protocol parser.",
        "date": "2020-03-06T00:00:00.000Z",
        "formattedDate": "March 6, 2020",
        "tags": [
          {
            "label": "perf",
            "permalink": "/blog/tags/perf"
          }
        ],
        "readingTime": 8.85,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "The Tremor Team",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Improving our Influx Parser- A Story in Four Acts",
          "author": "The Tremor Team",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "perf"
          ],
          "draft": false,
          "hide_table_of_contents": false,
          "description": "The process of improving the performance of our influx line protocol parser."
        },
        "prevItem": {
          "title": "Rust & Tell Berlin- March 2020",
          "permalink": "/blog/2020/03/31/rust-and-tell"
        },
        "nextItem": {
          "title": "Tremor is now Open Source!",
          "permalink": "/blog/2020/02/22/welcome"
        }
      },
      "content": "Yesterday, we spent the day on a report [that our influx parser was slow](https://github.com/tremor-rs/tremor-runtime/issues/82), and it turns out it was indeed.\n \nThis is an exciting topic as a few days ago, we [gave a talk at BoBKonf 2020](https://bobkonf.de/2020/ennis-gies.html) on this topic, so this is a great opportunity to show some of the topics and our process in action.\n \nAll the topics in this blog are links; the main one above this text is to the pull request, the titles of each section link to the commit that implements the topic discussed. Go ahead, click on some, and take a look!\n \nThere are two tools worth introducing here that we used during this performance session.\n \nOne is [perf](http://brendangregg.com/perf.html), which we used with a minimal setup of `perf record` and `perf report`. We use this to get a glance at where code is spending time. This is not perfect, but it is quick for decent results.\n \nThe other one is [criterion](https://docs.rs/criterion/0.3.1/criterion/), an excellent Rust framework for microbenchmarks based on the [haskell framework](https://hackage.haskell.org/package/criterion) with the same name. It is so helpful since it allows us to show changes in performance between changes. That makes it perfect for the kind of incremental improvements our process favors.\n\n<!--truncate-->\n \n## [Act 1 - Allocation](https://github.com/tremor-rs/tremor-runtime/pull/87/commits/42ee11637bc5cd3a215cce1cb841afe791b944b4)\n \nWe talked a bit about allocations and how they can slow down programs in our talk. We tackled two main areas there, and both of them applied to this benchmark.\n \nFirst, we switched our allocator to ensure we use the same allocator in both our builds, and the benchmark can make a significant difference!\n \nSecond, we found a few places where we used `String::new()` and then push to this String - this is one of the patterns we mentioned in our talk, and as you can see in this PR, something we still do wrong at times.\n \nFrom prior experience, we know that tag names, values, and field names rarely, if ever, are larger than `256` characters, so we preallocate with this to eliminate almost all string relocations during parsing.\n \nAs you can see, this change already had a decent impact on performance.\n \n```\nbase-value            time:   [540.03 ns 540.27 ns 540.53 ns]\n                       change: [-14.017% -13.948% -13.884%] (p = 0.00 < 0.05)\n                       Performance has improved.\n \nint-value               time:   [314.67 ns 314.90 ns 315.14 ns]\n                       change: [-8.9227% -8.8709% -8.8179%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 13 outliers among 100 measurements (13.00%)\n 1 (1.00%) low mild\n 12 (12.00%) high mild\n \nstr-value               time:   [460.68 ns 460.92 ns 461.16 ns]\n                       change: [-11.668% -11.617% -11.564%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 4 outliers among 100 measurements (4.00%)\n 1 (1.00%) low mild\n 2 (2.00%) high mild\n 1 (1.00%) high severe\n \nescaped-value           time:   [477.57 ns 478.02 ns 478.51 ns]\n                       change: [-13.262% -12.894% -12.594%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 1 outliers among 100 measurements (1.00%)\n 1 (1.00%) high mild\n```\n \n## [Act 2 - Degeneralisation](https://github.com/tremor-rs/tremor-runtime/pull/87/commits/d1490fb940ad99ca3570e4af8c5f5407c4d054e6)\n \nWhen we originally wrote the code, what we did is generalize the \"find a character\" logic between the cases where we were looking for one, two, or three distinct characters to terminate a token.\n \nThat made sense from the perspective of not duplicating code, however looking at the output of perf, it showed that we're spending an awful lot of time in this one particular function.\n \nSo we split this function into its three cases and implemented each on its own, allowing simplified code for one and two termination characters. This simplifies the logic and, in result, improves performance for those cases.\n \n \n```\nbase-value            time:   [533.13 ns 534.49 ns 536.02 ns]\n                       change: [-1.5482% -1.3801% -1.1996%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 3 outliers among 100 measurements (3.00%)\n 2 (2.00%) high mild\n 1 (1.00%) high severe\n \nint-value               time:   [287.45 ns 287.61 ns 287.78 ns]\n                       change: [-8.5277% -8.4504% -8.3783%] (p = 0.00 < 0.05)\n                       Performance has improved.\n \nstr-value               time:   [428.11 ns 428.38 ns 428.68 ns]\n                       change: [-7.2129% -7.1458% -7.0775%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 2 outliers among 100 measurements (2.00%)\n 1 (1.00%) low mild\n 1 (1.00%) high mild\n \nescaped-value           time:   [446.53 ns 447.30 ns 448.53 ns]\n                       change: [-6.6970% -6.5679% -6.4161%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 7 outliers among 100 measurements (7.00%)\n 6 (6.00%) high mild\n 1 (1.00%) high severe\n```\n \n## [Act 3 - Outside help](https://github.com/tremor-rs/tremor-runtime/pull/87/commits/6c9ee7ce64d1474bbd609f7ad99e4303b0ee98df)\n \nNot all performance improvements have to be written in code, sometimes asking the right question and looking for the right thing can do the trick.\n \n[lexical](https://docs.rs/lexical/) is a rust library that implements a faster version of number parsing, which is a significant part of what influx line protocol is.\n \nThe changes are minimal, and as you can see, the impact isn't that huge, but every percentage point counts.\n \n```\nbase-value            time:   [522.24 ns 522.45 ns 522.69 ns]\n                       change: [-0.3955% -0.2589% -0.1477%] (p = 0.00 < 0.05)\n                       Change within noise threshold.\nFound 13 outliers among 100 measurements (13.00%)\n 2 (2.00%) low mild\n 4 (4.00%) high mild\n 7 (7.00%) high severe\n \nint-value               time:   [295.19 ns 295.38 ns 295.56 ns]\n                       change: [-1.9771% -1.6929% -1.5006%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 5 outliers among 100 measurements (5.00%)\n 3 (3.00%) low mild\n 1 (1.00%) high mild\n 1 (1.00%) high severe\n \nstr-value               time:   [421.03 ns 421.25 ns 421.46 ns]\n                       change: [-3.0571% -2.9466% -2.8421%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 8 outliers among 100 measurements (8.00%)\n 3 (3.00%) low severe\n 1 (1.00%) low mild\n 3 (3.00%) high mild\n 1 (1.00%) high severe\n \nescaped-value           time:   [433.66 ns 434.61 ns 435.77 ns]\n                       change: [-2.9065% -2.7290% -2.5090%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 4 outliers among 100 measurements (4.00%)\n 1 (1.00%) high mild\n 3 (3.00%) high severe\n```\n \n## [Act 4 - Borrow vs. Owned](https://github.com/tremor-rs/tremor-runtime/pull/87/commits/eb24fd9c3f5982a2dae743abd41a75a4253eec07)\n \nThe last act is a bit more exciting, so we'll spend extra time on it (both here and when implementing it).\n \nThis touches on something we didn't discuss in detail during our talk for the sake of time. It is that owned values instead of borrowed values are\nsignificantly more expensive.\n \nWhile 'owned' and 'borrowed' are very Rust-specific terms, you can think about it this way:\n \nAn owned value is a value that has its own memory, on creation, it allocates that memory copies the data in, and when it gets freed, the memory too gets freed.\n \nA borrowed value doesn't own the memory it refers to. Instead, it borrows the memory from another value, and now those two are tied to each other. Rust uses lifetimes to represent this- this is a vast topic of its own, so we'll not go into details here, but think about it that a borrowed value in some way is a pointer to someone else's memory.\n \nFor influx data, a lot of the strings can are perfectly fine represented inside the initial memory; they don't need modification or change to be then used in the final data representation.\n \nThe first implementation ignored this fact and always created a newly owned data structure - this is expensive (as you will see below). However, it's not only that. Not all strings can be passed, pointing to the original memory. Influx uses some escaping in its line protocol that makes this impossible.\n \nFortunately, Rust has a data structure that allows representing the situation where we often return borrowed data but sometimes need to own it- it's named a `Cow`. No, not that cow, it doesn't eat grass, it is a Copy On Write structure that we can use to cover the \"we sometimes need to own the data\" situation.\n \nIn short, a `Cow< '_, str>` allows returning either a borrowed `&str` or an owned String - perfect for our use case!\n \nSince most of the time we can return the `&str` we use a trick I picked up from the [json crate](https://github.com/maciejhirsz/json-rust/blob/master/src/codegen.rs#L67-L99) that is to split out the logic in a base and a complex case where the base case can perform the common operation quickly and only if it is required we switch to the complex and more costly implementation.\n \nIn our case, this means we assume that all strings can be returned as borrowed, and only if we find an escape sequence, we switch to a more complex implementation. While this has some extra cost on the rare case, it makes the typical case rather cheap.\n \n```\nbase-value            time:   [385.62 ns 385.85 ns 386.06 ns]\n                       change: [-25.171% -25.122% -25.073%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 5 outliers among 100 measurements (5.00%)\n 1 (1.00%) low severe\n 3 (3.00%) low mild\n 1 (1.00%) high mild\n \nint-value               time:   [240.91 ns 241.37 ns 241.97 ns]\n                       change: [-18.169% -18.051% -17.905%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 1 outliers among 100 measurements (1.00%)\n 1 (1.00%) high severe\n \nstr-value               time:   [308.08 ns 308.17 ns 308.27 ns]\n                       change: [-26.978% -26.901% -26.833%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 8 outliers among 100 measurements (8.00%)\n 1 (1.00%) low severe\n 4 (4.00%) low mild\n 3 (3.00%) high mild\n \nescaped-value           time:   [368.73 ns 369.05 ns 369.38 ns]\n                       change: [-15.303% -15.233% -15.160%] (p = 0.00 < 0.05)\n                       Performance has improved.\nFound 3 outliers among 100 measurements (3.00%)\n 1 (1.00%) low mild\n```\n\n## [Conclusion](https://github.com/tremor-rs/tremor-runtime/pull/87)\n\nSo we performed 3 rudimentary and one more complex tweaks, and this doubled the performance of our influx parsing. As you can see, a few tweaks, when added together, can have some massive impact.\n\nThe most important take away here, however, is the process and that it is iterative.\n\nWe begin each round by looking at measurements, in this case, perf data. Then collect baseline data, in this case, with criterion. From there, we form a theory what could improve the results, implement a solution based on this theory, and finally validate the results with another run of criterion to see the relative diference.\n\nAnd here the final results of all changes combined:\n\n```\nGnuplot not found, using plotters backend\nbase-value            time:   [376.98 ns 377.26 ns 377.52 ns]                         \n                        change: [-55.627% -55.569% -55.518%] (p = 0.00 < 0.05)\n                        Performance has improved.\nFound 3 outliers among 100 measurements (3.00%)\n  2 (2.00%) low mild\n  1 (1.00%) high mild\n\nint-value               time:   [233.04 ns 233.19 ns 233.34 ns]                      \n                        change: [-47.584% -47.507% -47.435%] (p = 0.00 < 0.05)\n                        Performance has improved.\n\nstr-value               time:   [302.36 ns 302.43 ns 302.50 ns]                      \n                        change: [-58.246% -58.202% -58.159%] (p = 0.00 < 0.05)\n                        Performance has improved.\nFound 6 outliers among 100 measurements (6.00%)\n  2 (2.00%) low mild\n  4 (4.00%) high mild\n\nescaped-value           time:   [364.08 ns 364.35 ns 364.67 ns]                          \n                        change: [-52.159% -52.084% -52.004%] (p = 0.00 < 0.05)\n                        Performance has improved.\nFound 8 outliers among 100 measurements (8.00%)\n  8 (8.00%) high severe\n```"
    },
    {
      "id": "/2020/02/22/welcome",
      "metadata": {
        "permalink": "/blog/2020/02/22/welcome",
        "editUrl": "https://github.com/tremor-rs/tremor-www/tree/main/blog/2020-02-22-welcome.md",
        "source": "@site/blog/2020-02-22-welcome.md",
        "title": "Tremor is now Open Source!",
        "description": "Announcement of Tremor as an OSS project.",
        "date": "2020-02-22T00:00:00.000Z",
        "formattedDate": "February 22, 2020",
        "tags": [
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "welcome",
            "permalink": "/blog/tags/welcome"
          },
          {
            "label": "announcement",
            "permalink": "/blog/tags/announcement"
          },
          {
            "label": "open-source",
            "permalink": "/blog/tags/open-source"
          }
        ],
        "readingTime": 0.275,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "The Tremor Team",
            "url": "https://github.com/tremor-rs",
            "imageURL": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4"
          }
        ],
        "frontMatter": {
          "title": "Tremor is now Open Source!",
          "author": "The Tremor Team",
          "author_url": "https://github.com/tremor-rs",
          "author_image_url": "https://avatars.githubusercontent.com/u/60009416?s=200&v=4",
          "tags": [
            "hello",
            "welcome",
            "announcement",
            "open-source"
          ],
          "image": "/img/logo-minimalism.png",
          "draft": false,
          "hide_table_of_contents": false,
          "description": "Announcement of Tremor as an OSS project."
        },
        "prevItem": {
          "title": "Improving our Influx Parser- A Story in Four Acts",
          "permalink": "/blog/2020/03/06/influx-perf"
        }
      },
      "content": ">\n> The tremor project was released as an Open Source software project\n> on 22nd February 2020 at 20:02:02.\n>\n\nCatch us at [BOB2020](https://bobkonf.de/2020/en/) on 28th February,\n2020 in Berlin where we will be [talking](https://bobkonf.de/2020/ennis-gies.html) about our usage of the [Rust](https://www.rust-lang.org/) programming language to build high performance and high density production systems with Tremor."
    }
  ]
}