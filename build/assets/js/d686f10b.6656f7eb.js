"use strict";(self.webpackChunktremor_website=self.webpackChunktremor_website||[]).push([[8254],{12310:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>a,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>u});var i=t(58168),l=(t(96540),t(15680));t(40281);const r={},a="Polling",o={unversionedId:"recipes/polling_alerts/index",id:"version-0.11/recipes/polling_alerts/index",title:"Polling",description:"All the application code here is available from the docs git repository.",source:"@site/versioned_docs/version-0.11/recipes/38_polling_alerts/index.md",sourceDirName:"recipes/38_polling_alerts",slug:"/recipes/polling_alerts/",permalink:"/docs/0.11/recipes/polling_alerts/",draft:!1,editUrl:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.11/recipes/38_polling_alerts/index.md",tags:[],version:"0.11",frontMatter:{},sidebar:"version-0.11/tutorialSidebar",previous:{title:"Configurator",permalink:"/docs/0.11/recipes/configurator/"},next:{title:"Ingesting documents from kafka into elastic",permalink:"/docs/0.11/recipes/kafka_elastic_correlation/"}},s={},u=[{value:"Environment",id:"environment",level:2},{value:"Business Logic",id:"business-logic",level:2},{value:"Polling",id:"polling-1",level:3},{value:"Alerting",id:"alerting",level:3},{value:"Command line testing during logic development",id:"command-line-testing-during-logic-development",level:2}],p={toc:u},c="wrapper";function m(e){let{components:n,...r}=e;return(0,l.yg)(c,(0,i.A)({},p,r,{components:n,mdxType:"MDXLayout"}),(0,l.yg)("h1",{id:"polling"},"Polling"),(0,l.yg)("admonition",{type:"note"},(0,l.yg)("p",{parentName:"admonition"},"All the application code here is available from the docs ",(0,l.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.11/recipes/38_polling_alerts/index.md"},"git repository"),".")),(0,l.yg)("p",null,"This example demonstrates using Tremor to periodically poll a data source (we use influx as it can quickly generate data) and make decisions based on the results - in our case alert us on low CPU or memory."),(0,l.yg)("p",null,"We will not look deep into the query used or the alerts defined as they're only supporting elements to the story we're trying to tell here: periodic, reactive workflows. To this end, we leverage a good bit of the configuration introduced in ",(0,l.yg)("a",{parentName:"p",href:"/docs/0.11/recipes/influx/"},"the influx example"),"."),(0,l.yg)("h2",{id:"environment"},"Environment"),(0,l.yg)("p",null,"As mentioned above, we reuse a lot of the influx logic, so we ignore the following artifacts:"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},"onramp: ",(0,l.yg)("inlineCode",{parentName:"li"},"udp-input")),(0,l.yg)("li",{parentName:"ul"},"offramp: ",(0,l.yg)("inlineCode",{parentName:"li"},"influx-output")),(0,l.yg)("li",{parentName:"ul"},"query: ",(0,l.yg)("inlineCode",{parentName:"li"},"ingress")),(0,l.yg)("li",{parentName:"ul"},"binding: ",(0,l.yg)("inlineCode",{parentName:"li"},"ingress")),(0,l.yg)("li",{parentName:"ul"},"mapping: ",(0,l.yg)("inlineCode",{parentName:"li"},"ingress"))),(0,l.yg)("p",null,"Also there are two new pipelines:"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("inlineCode",{parentName:"li"},"poll")," - translates a tick into a query"),(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("inlineCode",{parentName:"li"},"alert")," - translates the result and evaluates if an alert should be triggered")),(0,l.yg)("p",null,"We also have a new onramp (",(0,l.yg)("inlineCode",{parentName:"p"},"tick"),") and offramp (",(0,l.yg)("inlineCode",{parentName:"p"},"influx-query"),")."),(0,l.yg)("p",null,"For the sake of not repeating the previous workshop we will focus on those new parts exclusively."),(0,l.yg)("h2",{id:"business-logic"},"Business Logic"),(0,l.yg)("h3",{id:"polling-1"},"Polling"),(0,l.yg)("p",null,"This section deals with polling, in our case we want to query influxdb on a periodic interval."),(0,l.yg)("p",null,"To this end we use a ",(0,l.yg)("inlineCode",{parentName:"p"},"metronome")," onramp that triggers an event every 10s. We send the events into ",(0,l.yg)("a",{target:"_blank",href:t(42556).A},(0,l.yg)("code",null,"poll.trickle"))," where we create a influx request out of the metronom event."),(0,l.yg)("p",null,"The ",(0,l.yg)("inlineCode",{parentName:"p"},"poll")," pipeline then connects to the linked influx offramp to run the query."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-trickle"},'# poll.trickle\n# This file is for for turning ticks into queries\n\n# this turns the `metronom` tick into a query\ndefine script query\nwith\n  host = "",\n  db = ""\nscript\n  use std::url;\n  # we define the query to gather data\n  # this is the original, for the sake of dockerizing it we ignore the host in the final query since we don\'t know what it will be\n  # let query = "SELECT mean(\\"usage_idle\\") AS \\"cpu_idle\\", mean(\\"active\\") AS \\"mem_active\\" FROM \\"tremor\\".\\"autogen\\".\\"cpu\\", \\"tremor\\".\\"autogen\\".\\"mem\\" WHERE time > now() - 1h AND time < now() AND \\"host\\"=\'#{ args.host }\' GROUP BY time(1h) FILL(null)";\n  let query = "SELECT mean(\\"usage_idle\\") AS \\"cpu_idle\\", mean(\\"active\\") AS \\"mem_active\\" FROM \\"tremor\\".\\"autogen\\".\\"cpu\\", \\"tremor\\".\\"autogen\\".\\"mem\\" WHERE time > now() - 1h AND time < now() GROUP BY time(1h) FILL(null)";\n  # we encode this to a rest offramp query parameter using `url::encode`\n  let $endpoint.query = "db=#{ args.db }&epock=ms&q=#{ url::encode(query) }";\n  let event.meta = $;\n  # we can end this script\n  event\nend;\n\n# we create a script for a given host\ncreate script query with\n  host = "d111f17774f7"\nend;\n# we wire it all up\nselect event from in into query;\nselect event from query into out;\n')),(0,l.yg)("h3",{id:"alerting"},"Alerting"),(0,l.yg)("p",null,"The ",(0,l.yg)("a",{target:"_blank",href:t(94243).A},(0,l.yg)("code",null,"alert.trickle"))," pipeline takes the reply from Influx and alert if the values we see are above a given limit."),(0,l.yg)("p",null,"Since the influx reply uses a unique datamodle, we need to unscramble the results, this sadly is a trail and error process based on what influx returns."),(0,l.yg)("p",null,"Once we have extracted the data we can pass it into an alerting script that checks a few conditions in a given order. The first condition that is met will trigger the coresponding alert."),(0,l.yg)("p",null,"You can adopt the alert conditions in the ",(0,l.yg)("inlineCode",{parentName:"p"},"with")," section of the script."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-trickle"},'# This script takes the responses and turns them into alerts\n\n# The script that does all the logic, we define our alerts here\ndefine script alert with\n  cpu_limit = 100,\n  mem_limit = 19518531180\nscript\n  match event of\n    case %{cpu_idle < args.cpu_limit, mem_active > args.mem_limit} => emit "EVERYTHING IS ON FIRE"\n    case %{cpu_idle < args.cpu_limit} => match event of\n      case %{cpu_system > 50} => emit "OS BROKEN"\n      default => emit "CPU BUSY"\n    end\n\n    case %{mem_active > args.mem_limit } => emit "MEM LOW"\n    default => drop\n  end\nend;\n\ncreate script alert;\n\n# Since the influx reply is hard to work with we santize it here so we can write our alerts\n# in a cleaner fashipn\n#\n# example result:\n# ```\n# {"results":[{"statement_id":0,"series":[{"columns":["time","cpu_idle1","mem_active"],"values":[["2021-03-02T15:00:00Z",98.856058199546,null],["2021-03-02T16:00:00Z",97.09260215835516,null]],"name":"cpu"},{"columns":["time","cpu_idle1","mem_active"],"values":[["2021-03-02T15:00:00Z",null,19519109501.023254],["2021-03-02T16:00:00Z",null,19959332287.756653]],"name":"mem"}]}]}\n# ```\ncreate stream extracted;\nselect {\n  "#{event.results[0].series[0].columns[1]}": event.results[0].series[0].values[1][1],\n  "#{event.results[0].series[1].columns[2]}": event.results[0].series[1].values[1][2],\n} from in into extracted;\n\n# we wire it all up\nselect event from extracted into alert;\nselect event from alert into out;\n\n# we could use this for debugging\n# select event from in into out;\n')),(0,l.yg)("h2",{id:"command-line-testing-during-logic-development"},"Command line testing during logic development"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"$ docker compose up\n  ... lots of logs ...\n")),(0,l.yg)("p",null,"Then watch alerts on stdout from ",(0,l.yg)("inlineCode",{parentName:"p"},"docker compose"),"."))}m.isMDXComponent=!0},94243:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/files/alert-af3d820a233d97730f9d3413e814ae77.trickle"},42556:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/files/poll-fe863acce5d3284f4fad09bbb0952218.trickle"}}]);