"use strict";(self.webpackChunktremor_website=self.webpackChunktremor_website||[]).push([[4508],{28928:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>p});var i=t(58168),r=(t(96540),t(15680)),o=t(40281);const a={sidebar_position:1},s="Metrics",l={unversionedId:"guides/metrics",id:"version-0.12/guides/metrics",title:"Metrics",description:"One case you can deploy tremor for is to work with metrics. Not as a store but as a preprocessor, aggregator, and filter for metrics stores.",source:"@site/versioned_docs/version-0.12/guides/metrics.md",sourceDirName:"guides",slug:"/guides/metrics",permalink:"/docs/0.12/guides/metrics",draft:!1,editUrl:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md",tags:[],version:"0.12",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"indexSidebar",previous:{title:"Basics",permalink:"/docs/0.12/guides/basics"},next:{title:"Logstash",permalink:"/docs/0.12/guides/old/logstash/"}},c={},p=[{value:"Topics",id:"topics",level:2},{value:"Foundation",id:"foundation",level:2},{value:"UDP Server",id:"udp-server",level:3},{value:"Pipeline, wiring up and running",id:"pipeline-wiring-up-and-running",level:3},{value:"Batching",id:"batching",level:2},{value:"Adding the Batch operator",id:"adding-the-batch-operator",level:3},{value:"Running",id:"running",level:3},{value:"Aggregation",id:"aggregation",level:2},{value:"Grouping",id:"grouping",level:3},{value:"Windowing",id:"windowing",level:3},{value:"Aggregating",id:"aggregating",level:3},{value:"Normalisation",id:"normalisation",level:3},{value:"Running",id:"running-1",level:3},{value:"Tremor metrics",id:"tremor-metrics",level:2},{value:"Connectors",id:"connectors",level:3},{value:"Pipeline",id:"pipeline",level:3},{value:"Metric Connector &amp; Wiring",id:"metric-connector--wiring",level:3},{value:"Other backends",id:"other-backends",level:2},{value:"TDengine",id:"tdengine",level:3},{value:"QuestDB",id:"questdb",level:3}],d={toc:p},g="wrapper";function u(e){let{components:n,...t}=e;return(0,r.yg)(g,(0,i.A)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"metrics"},"Metrics"),(0,r.yg)("p",null,"One case you can deploy tremor for is to work with metrics. Not as a store but as a preprocessor, aggregator, and filter for metrics stores."),(0,r.yg)("p",null,"In this guide, we'll see how to use tremor for this. We'll set up an example where tremor batch, aggregates, and then forwards metrics. In addition, we'll take a look at tremor's metrics."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   This example expects that you have some knowledge of tremor or went through the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/guides/basics"},"basics guide"),". We won't explain the concepts covered there again here."),(0,r.yg)("p",{parentName:"admonition"},"   In addition, we use ",(0,r.yg)("inlineCode",{parentName:"p"},"docker compose")," for this guide as it requires additional software, and we want to avoid you having to install and configure a bunch of other services. We expect some familiarity with this as we will not explain the details.")),(0,r.yg)("p",null,"All code for this guide can found ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/"},"on github"),"."),(0,r.yg)("h2",{id:"topics"},"Topics"),(0,r.yg)("p",null,"This guide introduces the following new concepts."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"codecs"),(0,r.yg)("li",{parentName:"ul"},"Post- and Preprocessors"),(0,r.yg)("li",{parentName:"ul"},"Connector configuration"),(0,r.yg)("li",{parentName:"ul"},"pipeline operators"),(0,r.yg)("li",{parentName:"ul"},"streams"),(0,r.yg)("li",{parentName:"ul"},"aggregation"),(0,r.yg)("li",{parentName:"ul"},"time-based windows"),(0,r.yg)("li",{parentName:"ul"},"tremors internal metrics")),(0,r.yg)("h2",{id:"foundation"},"Foundation"),(0,r.yg)("p",null,"Let us start with the basic deployment:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"influxdb for storage"),(0,r.yg)("li",{parentName:"ul"},"chronograph for display"),(0,r.yg)("li",{parentName:"ul"},"telegraf as an agent to collect some data"),(0,r.yg)("li",{parentName:"ul"},"tremor for aggregation and filtering")),(0,r.yg)("p",null,"A high level visualization of the application components:"),(0,r.yg)(o.K,{chart:"graph LR\n    A{telegraf UDP} --\x3e|influx line protocol| B(tremor)\n    B --\x3e|Influx API| C{InfluxDB HTTP}\n    D{Chronograf} --- C   ",mdxType:"Mermaid"}),(0,r.yg)("p",null,"The docker-compose file for this is ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/01_basic"},"here"),"."),(0,r.yg)("h3",{id:"udp-server"},"UDP Server"),(0,r.yg)("p",null,"Something new here is that we fully define our connectors instead of using a pre-defined canned connector."),(0,r.yg)("p",null,"For the input, we use a ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/connectors/udp"},(0,r.yg)("inlineCode",{parentName:"a"},"udp_server"))," connector. In the ",(0,r.yg)("inlineCode",{parentName:"p"},"with")," clause, we can pass in the configuration."),(0,r.yg)("p",null,"Here are the fields of interest we have not discussed before."),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"codec")," is an option that can be passed to (nearly) all connectors, and it defines how data that arrives over this connection is decoded. In our case we use ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/codecs/influx"},(0,r.yg)("inlineCode",{parentName:"a"},"influx"))," to decode the influxdb line protocol."),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"preprocessors")," are also an option that can be passed to (nearly) all connectors. You can use preprocessors to perform some processing on the byte stream that the connector provides. In our case, we use ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/preprocessors/separate"},(0,r.yg)("inlineCode",{parentName:"a"},"separate")),". This preprocessor will separate the byte stream with a given character or byte, by default, the ",(0,r.yg)("inlineCode",{parentName:"p"},"\\n")," newline."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   Some connectors provide structured output instead of a byte stream. Structured connectors can't use a ",(0,r.yg)("inlineCode",{parentName:"p"},"codec"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"preprocessors")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"postprocessor")," - after all, their output is already well defined.\n::::"),(0,r.yg)("p",{parentName:"admonition"},"The ",(0,r.yg)("inlineCode",{parentName:"p"},"config")," section holds a specific configuration to the connector type selected. Since we use the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/connectors/udp"},(0,r.yg)("inlineCode",{parentName:"a"},"udp_server")),", we only have to specify the ",(0,r.yg)("inlineCode",{parentName:"p"},"URL")," we want to listen on."),(0,r.yg)("p",{parentName:"admonition"},"With this, we get:"),(0,r.yg)("pre",{parentName:"admonition"},(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'define flow metrics\nflow\n  # define the udp server\n  define connector upd_in from udp_server\n  with\n    # define the codec we use, in this case `influx` for the influx wire protocol\n    codec = "influx",\n    # define the preprocessors, we use separate to seperate events by lines\n    preprocessors = ["separate"],\n    # configure the connector itself, we listen to `0.0.0.0` on port `4242`\n    config = {\n      "url": "0.0.0.0:4242",\n    }\n  end;\nend;\n')),(0,r.yg)("h3",{parentName:"admonition",id:"http-client"},"HTTP Client"),(0,r.yg)("p",{parentName:"admonition"},"On the other side we use a ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/connectors/http"},(0,r.yg)("inlineCode",{parentName:"a"},"http_client")),". Since influxdb does not have a custom transport we are not forced to implement a ",(0,r.yg)("inlineCode",{parentName:"p"},"influx")," connector. Instead we can use the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/codecs/influx"},(0,r.yg)("inlineCode",{parentName:"a"},"influx")," codec")," and a http or udp connectors.")),(0,r.yg)("p",null,"   Connector naming follows a scheme here. Generally, something is named ",(0,r.yg)("inlineCode",{parentName:"p"},"server")," if it accepts connections and ",(0,r.yg)("inlineCode",{parentName:"p"},"client")," if it initiates connections.\nWhile there is a correlation between clients writing and servers reading, this is incidental and not a rule. A ",(0,r.yg)("inlineCode",{parentName:"p"},"client")," connection could be reading and not a writing connector.\n:::"),(0,r.yg)("p",null,"Our connector config here is slightly more elaborate. In addition to the ",(0,r.yg)("inlineCode",{parentName:"p"},"URL"),", defining the target to write to, we also have a ",(0,r.yg)("inlineCode",{parentName:"p"},"headers")," map that specifies the HTTP headers. This demonstrates nicely that more complex configurations are possible."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'define flow metrics\nflow\n  # define the udp server\n  define connector upd_in from udp_server\n  with\n    # define the codec we use, in this case `influx` for the influx wire protocol\n    codec = "influx",\n    # define the preprocessors, we use separate to seperate events by lines\n    preprocessors = ["separate"],\n    # configure the connector itself, we listen to `0.0.0.0` on port `4242`\n    config = {\n      "url": "0.0.0.0:4242",\n    }\n  end;\n  \n  # define our http client\n  define connector influx_out from http_client\n  with\n    # we use the influx codec here as well\n    codec = "influx",\n    # configure the endpoint we\'re writing to\n    config = {\n      "url": "http://influxdb:8086/write?db=tremor",\n      # We use a custom header to identify that we\'re tremor\n      "headers": {"Client": ["Tremor"]}\n    }\n  end;\nend;\n\ndeploy flow metrics;\n')),(0,r.yg)("h3",{id:"pipeline-wiring-up-and-running"},"Pipeline, wiring up and running"),(0,r.yg)("p",null,"As in the basics tutorial, we will use the ",(0,r.yg)("inlineCode",{parentName:"p"},"passthrough")," pipeline from the ",(0,r.yg)("inlineCode",{parentName:"p"},"tremor::pipelines")," module. If you went through the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/guides/basics"},"basics guide"),", this is the same as before."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'define flow metrics\nflow\n  # import the pipeline module\n  use tremor::pipelines;\n  # define the udp server\n  define connector upd_in from udp_server\n  with\n    # define the codec we use, in this case `influx` for the influx wire protocol\n    codec = "influx",\n    # define the preprocessors, we use separate to seperate events by lines\n    preprocessors = ["separate"],\n    # configure the connector itself, we listen to `0.0.0.0` on port `4242`\n    config = {\n      "url": "0.0.0.0:4242",\n    }\n  end;\n  \n  # define our http client\n  define connector influx_out from http_client\n  with\n    # we use the influx codec here as well\n    codec = "influx",\n    # configure  the endpoint we\'re writing to\n    config = {\n      "url": "http://influxdb:8086/write?db=tremor",\n      # We use a custom header to identify that we\'re tremor\n      "headers": {"Client": ["Tremor"]}\n    }\n  end;\n\n  # Create the UDP server\n  create connector upd_in;\n\n  # Create the HTTP client\n  create connector influx_out;\n\n  # Create our pipeline\n  create pipeline passthrough from pipelines::passthrough;\n\n  # Connect the udp server to the pipeline\n  connect /connector/upd_in to /pipeline/passthrough;\n  # Connect the pipeline to the inflix client\n  connect /pipeline/passthrough to /connector/influx_out;\n\nend;\n\n# start our \ndeploy flow metrics;\n')),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/01_basic"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the chronograf UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:8888"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:8888")),"."),(0,r.yg)("h2",{id:"batching"},"Batching"),(0,r.yg)("p",null,"Tremor processes events one by one, meaning that each metric is considered its event. The upside of this is how events arrive. If it's one event per UDP message or 100 makes no difference. The downside is that InfluxDB requires events to be submitted in batches to maintain performance."),(0,r.yg)("p",null,"Since InfluxDB isn't the only destination that benefits from batched events, tremor provides a ",(0,r.yg)("a",{parentName:"p",href:"../reference/operators#genericbatch"},"batching operator"),"."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   Batching using the ",(0,r.yg)("a",{parentName:"p",href:"../reference/operators#genericbatch"},"batching operator")," is handled inside the connector. HTTP, for example, will combine a batch into a single request, but different connectors might handle this differently.")),(0,r.yg)("h3",{id:"adding-the-batch-operator"},"Adding the Batch operator"),(0,r.yg)("p",null,"Operators are small pieces of logic that are written in rust. You can put them inside of a pipeline to perform specific actions. In our example, we use the batch operator."),(0,r.yg)("p",null,"Their use is similar to what you already know from pipelines and connectors. You first define operators with a set of configuration parameters, then create them for use."),(0,r.yg)("p",null,"We then use ",(0,r.yg)("inlineCode",{parentName:"p"},"select")," to wire it up in the pipeline."),(0,r.yg)("p",null,"We use a maximum of ",(0,r.yg)("inlineCode",{parentName:"p"},"3000")," events and a maximum delay of ",(0,r.yg)("inlineCode",{parentName:"p"},"5s")," for our operator."),(0,r.yg)("p",null,"Note that we select from ",(0,r.yg)("inlineCode",{parentName:"p"},"in")," into ",(0,r.yg)("inlineCode",{parentName:"p"},"batch")," and from ",(0,r.yg)("inlineCode",{parentName:"p"},"batch")," into ",(0,r.yg)("inlineCode",{parentName:"p"},"out"),", wiring up the event chain."),(0,r.yg)("p",null,"We also need to update our HTTP Client to use a postprocessor, namely the ",(0,r.yg)("inlineCode",{parentName:"p"},"separate")," one, to join batch elements back together with newlines."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'define flow metrics\nflow\n\n  # define the udp server\n  define connector upd_in from udp_server\n  with\n    # define the codec we use, in this case `influx` for the influx wire protocol\n    codec = "influx",\n    # define the preprocessors, we use separate to seperate events by lines\n    preprocessors = ["separate"],\n    # configure the connector itself, we listen to `0.0.0.0` on port `4242`\n    config = {\n      "url": "0.0.0.0:4242",\n    }\n  end;\n\n\n  # define our http client\n  define connector influx_out from http_client\n  with\n    # we use the influx codec here as well\n    codec = "influx",\n    # define the postprocessor, we use separate to seperate events by lines\n    postprocessor = ["separate"],       \n    # configure  the endpoint we\'re writing to\n    config = {\n      "url": "http://influxdb:8086/write?db=tremor",\n      # We use a custom header to identify that we\'re tremor\n      "headers": {"Client": ["Tremor"]}\n    }\n  end;\n\n  # define our metrics pipeline to batch metrics\n  define pipeline metrics\n  pipeline\n    # define our batch operator.\n    # A batch will collect up to 3000 events, but never wait more then 5 seconds\n    # before emitting.\n    define operator batch from generic::batch\n    with\n      count = 3000,\n      timeout = nanos::from_seconds(5)\n    end;\n\n    create operator batch;\n\n    select event from in into batch;\n    select event from batch into out;\n  end;\n\n  # Create the udp server\n  create connector upd_in;\n\n  # Create the http client\n  create connector influx_out;\n\n  # Create our pipeline\n  create pipeline metrics from metrics;\n\n  # Connect the udp server to the pipeline\n  connect /connector/upd_in to /pipeline/metrics;\n  # Connect the pipeline to the inflix client\n  connect /pipeline/metrics to /connector/influx_out;\n\nend;\n\n# start our \ndeploy flow metrics;\n')),(0,r.yg)("h3",{id:"running"},"Running"),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/02_batching"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the chronograf UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:8888"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:8888")),"."),(0,r.yg)("h2",{id:"aggregation"},"Aggregation"),(0,r.yg)("p",null,"Let's talk about aggregation. Sometimes it's helpful to aggregate some metrics before they're stored in a database. One reason could be to downsample the input. Another could be to create histograms for databases that don't natively support them."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   The techniques used for aggregation aren't specific to metrics. You can apply the same methods to any event stream.")),(0,r.yg)("p",null,'The aggregation we\'re looking for is "The histogram for each metric over a 10s and 1min window."'),(0,r.yg)("h3",{id:"grouping"},"Grouping"),(0,r.yg)("p",null,"To aggregate the metrics, we get in a useful we need to group our data by the ",(0,r.yg)("inlineCode",{parentName:"p"},'"each metric"')," from our definition. Since we're using influx data as our input, a metric is identified by three fields:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"The ",(0,r.yg)("inlineCode",{parentName:"li"},"measurement")),(0,r.yg)("li",{parentName:"ul"},"The ",(0,r.yg)("inlineCode",{parentName:"li"},"tags")),(0,r.yg)("li",{parentName:"ul"},"The ",(0,r.yg)("inlineCode",{parentName:"li"},"field"))),(0,r.yg)("p",null,"Since influx combines multiple fields in a message, we first have to unroll this into each field being a single event."),(0,r.yg)("p",null,"::: note\nWe use ",(0,r.yg)("inlineCode",{parentName:"p"},"create stream")," here. Streams are just named nodes that have no own function or overhead. They serve as a way to chain up selects.\n:::"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'    # use types for checking if values are a number\n    use std::type;\n\n    # use record for exploding keys\n    use std::record;\n\n    # create our pre-aggregation stream\n    create stream aggregate;\n\n    # We change the structure of our event to be easier digestible for aggregation\n    select {\n        "measurement": event.measurement,\n        "tags": event.tags,\n        "field": group[2],\n        "value": event.fields[group[2]],\n        "timestamp": event.timestamp,\n    }\n    from in\n    group by set(event.measurement, event.tags, each(record::keys(event.fields)))\n    into aggregate\n    having type::is_number(event.value);\n')),(0,r.yg)("p",null,"What we do here is for ",(0,r.yg)("inlineCode",{parentName:"p"},"each")," ",(0,r.yg)("inlineCode",{parentName:"p"},"key")," in ",(0,r.yg)("inlineCode",{parentName:"p"},"fields"),", we create a metric, so if our record has two fields, we flatten that out and have two events. We then create a set of this field, the tags for the metric, and the measurement for the metric. This gives us a unique identifier for the metric/"),(0,r.yg)("p",null,"This is needed to not confuse the values for different fields."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   We use ",(0,r.yg)("inlineCode",{parentName:"p"},"group[2]")," here, which refers to the second element of the current group (indexing starts at 0). For a string of the entire group, you can access ",(0,r.yg)("inlineCode",{parentName:"p"},"n+1"),"( in our example, since we have three elements, it would be ",(0,r.yg)("inlineCode",{parentName:"p"},"group[3]"),").")),(0,r.yg)("h3",{id:"windowing"},"Windowing"),(0,r.yg)("p",null,"To aggregate over a time range, we use time-based tumbling windows. We can define them the same way we define everything else, a ",(0,r.yg)("inlineCode",{parentName:"p"},"define")," statement. They are, however, not created. Instead, they're bound to the select statement they're used in."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},"    # use nanos for time\n    use std::time::nanos;\n\n    # define a 10 second window\n    define window `10secs` from tumbling\n    with\n      interval = nanos::from_seconds(10)\n    end;\n\n    # define a 1 minute window\n    define window `1min` from tumbling\n    with\n      interval = nanos::from_minutes(1)\n    end;\n")),(0,r.yg)("h3",{id:"aggregating"},"Aggregating"),(0,r.yg)("p",null,"Once we have defined the windows, we can now use them to aggregate our data. We do this in a new select statement. After the ",(0,r.yg)("inlineCode",{parentName:"p"},"from")," section, we have a square bracket and the window names. This syntax is what we call tilt frames. They're chained windows that will emit based on conditions."),(0,r.yg)("p",null,"We use the  ",(0,r.yg)("a",{parentName:"p",href:"../reference/stdlib/aggr/stats#hdrnumber-array"},(0,r.yg)("inlineCode",{parentName:"a"},"aggr::stats::hdr"))," function that creates a histogram from the incoming data and outputs the given set of percentiles."),(0,r.yg)("p",null,"In addition we use the ",(0,r.yg)("a",{parentName:"p",href:"../reference/stdlib/aggr/win#first"},(0,r.yg)("inlineCode",{parentName:"a"},"aggr::win::first"))," to get the first timestamp."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"   We are using two windows here, a 10s one and a 1min one. The upside of using the tilt framing mechanism here is that we can do this without a loss in precision, as the 1min window is not an aggregate of six 10s windows but rather an aggregate of the raw data of them without having to duplicate it.")),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'    # create a stream for normalization\n    create stream normalize;\n\n    select\n    {\n        "measurement": event.measurement,\n        "tags": patch event.tags of insert "window" => window end,\n        "stats": aggr::stats::hdr(event.value, [ "0.5", "0.9", "0.99", "0.999" ]),\n        "field": event.field,\n        "timestamp": aggr::win::first(event.timestamp), # we can\'t use min since it\'s a float\n    }\n    from aggregate[`10secs`, `1min`]\n    group by set(event.measurement, event.tags, event.field)\n    into normalize;\n')),(0,r.yg)("h3",{id:"normalisation"},"Normalisation"),(0,r.yg)("p",null,"Last but not least we need to normalize this data basck to something the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/codecs/influx"},"influx codec")," understands."),(0,r.yg)("p",null,"We can do this with another select statement."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'select {\n  "measurement":  event.measurement,\n  "tags":  event.tags,\n  "fields":  {\n    "count_#{event.field}":  event.stats.count,\n    "min_#{event.field}":  event.stats.min,\n    "max_#{event.field}":  event.stats.max,\n    "mean_#{event.field}":  event.stats.mean,\n    "stdev_#{event.field}":  event.stats.stdev,\n    "var_#{event.field}":  event.stats.var,\n    "p50_#{event.field}":  event.stats.percentiles["0.5"],\n    "p90_#{event.field}":  event.stats.percentiles["0.9"],\n    "p99_#{event.field}":  event.stats.percentiles["0.99"],\n    "p99.9_#{event.field}":  event.stats.percentiles["0.999"]\n  },\n  "timestamp": event.timestamp,\n}\nfrom normalize\ninto batch;\n')),(0,r.yg)("h3",{id:"running-1"},"Running"),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/03_aggregation"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the chronograf UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:8888"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:8888")),"."),(0,r.yg)("h2",{id:"tremor-metrics"},"Tremor metrics"),(0,r.yg)("p",null,"Finally, let us talk about how to access tremors own metrics. We choose to allow tremor to process them and forward them as required. This avoids an extra step for configuring metrics, implementing connectivity, or forcing the users into a specific way of monitoring."),(0,r.yg)("p",null,"This is done using the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/connectors/metrics"},(0,r.yg)("inlineCode",{parentName:"a"},"metrics connector")),"."),(0,r.yg)("h3",{id:"connectors"},"Connectors"),(0,r.yg)("p",null,"To enable metrics collection for connectors, we need to update their configuration. Namely we add the ",(0,r.yg)("inlineCode",{parentName:"p"},"metrics_interval_s")," option. We choose 5 seconds to keep the overhead low."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'  # define the udp server\n  define connector upd_in from udp_server\n  with\n    # define metrics interval\n    metrics_interval_s = 5,\n    # define the codec we use, in this case `influx` for the influx wire protocol\n    codec = "influx",\n    # define the preprocessors, we use separate to seperate events by lines\n    preprocessors = ["separate"],\n    # configure the connector itself, we listen to `0.0.0.0` on port `4242`\n    config = {\n      "url": "0.0.0.0:4242",\n    }\n  end;\n  \n  # define our http client\n  define connector influx_out from http_client\n  with\n    # define metrics interval\n    metrics_interval_s = 5,\n    # we use the influx codec here as well\n    codec = "influx",\n    # define the postprocessors, we use separate to seperate events by lines\n    postprocessors = ["separate"],\n    # configure  the endpoint we\'re writing to    \n    config = {\n      "url": "http://influxdb:8086/write?db=tremor",\n      # We use a custom header to identify that we\'re tremor\n      "headers": {"Client": ["Tremor"]}\n    }\n  end;\n')),(0,r.yg)("h3",{id:"pipeline"},"Pipeline"),(0,r.yg)("p",null,"The pipeline has to be set up as well. As pipelines don't come with a ",(0,r.yg)("inlineCode",{parentName:"p"},"with")," section, it is configured as part of a configuration directive with the same name."),(0,r.yg)("p",null,"We choose the same 5-second interval."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},"  define connector metrics from metrics;\n\n  # define our metrics pipeline to batch metrics\n  define pipeline metrics\n  pipeline\n    #!config metrics_interval_s = 5\n  # ...\n")),(0,r.yg)("h3",{id:"metric-connector--wiring"},"Metric Connector & Wiring"),(0,r.yg)("p",null,"So with all our connectors and pipelines configured, we have to wire up the connector to the metrics pipeline. This works since, for internal metrics, we use the same structure as the ",(0,r.yg)("a",{parentName:"p",href:"/docs/0.12/reference/codecs/influx"},(0,r.yg)("inlineCode",{parentName:"a"},"influx")," codec"),"."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},"define flow metrics\nflow\n  # ...\n\n  # Define our hasher\n  define connector metrics from metrics;\n  # Create the internal metrics collector\n  create connector metrics;\n  # Connect the metrics to the pipeline\n  connect /connector/metrics to /pipeline/metrics;\n  \n  #...\n")),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/04_interal"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the chronograf UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:8888"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:8888")),"."),(0,r.yg)("h2",{id:"other-backends"},"Other backends"),(0,r.yg)("p",null,"While this example is written using InfluxDB as a backend, it works equally with other backends."),(0,r.yg)("h3",{id:"tdengine"},"TDengine"),(0,r.yg)("p",null,"TDengine can quickly replace influx. The only difference is that we need to change the ",(0,r.yg)("inlineCode",{parentName:"p"},"url")," in the ",(0,r.yg)("inlineCode",{parentName:"p"},"http_client")),(0,r.yg)("p",null,"A high-level visualization of TDengine replacing InfluxDB via the Influx API:"),(0,r.yg)(o.K,{chart:"graph LR\n    A{telegraf UDP} --\x3e|influx line protocol| B(tremor)\n    B --\x3e|Influx API| C{TDengine}",mdxType:"Mermaid"}),(0,r.yg)("p",null,"The connector definition for ",(0,r.yg)("inlineCode",{parentName:"p"},"TDengine")," has a slightly different endpoint\nspecification, but the application is otherwise the same:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-tremor"},'  # define our http client\n  define connector influx_out from http_client\n  with\n    # define metrics interval\n    metrics_interval_s = 5,\n    # we use the influx codec here as well\n    codec = "influx",\n    # define the postprocessors, we use separate to seperate events by lines\n    postprocessors = ["separate"],\n    # configure  the endpoint we\'re writing to    \n    config = {\n      "url": "http://tdengine:6041/influxdb/v1/write?db=tremor&u=root&p=taosdata",\n      # We use a custom header to identify that we\'re tremor\n      "headers": {"Client": ["Tremor"]}\n    }\n  end;\n')),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/05_tdengine"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the grafana UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:3000"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:3000")),"."),(0,r.yg)("p",null,"Note that you need to log in with user ",(0,r.yg)("inlineCode",{parentName:"p"},"admin")," and password ",(0,r.yg)("inlineCode",{parentName:"p"},"admin")),(0,r.yg)("h3",{id:"questdb"},"QuestDB"),(0,r.yg)("p",null,"QuestDB can also replace influx. There are a few differences however as Quest has\nconstraints on column names and does not support the HTTP protocol for Influx Line\nProtocol. We can choose UDP based or TCP based distribution for QuestDB."),(0,r.yg)("p",null,"A high-level visualization of QuestDB replacing InfluxDB via the Influx API:"),(0,r.yg)(o.K,{chart:"graph LR\n    A{telegraf UDP} --\x3e|influx line protocol over UDP| B(tremor)\n    B --\x3e|Influx Line Protocol over TCP| C{QuestDB}",mdxType:"Mermaid"}),(0,r.yg)("p",null,"The connector definition for ",(0,r.yg)("inlineCode",{parentName:"p"},"QuestDB")," has a slightly different endpoint\nspecification and uses the TCP protocol for connectivity, but the\nconfiguration is otherwise the same:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-troy"},'  # define our http client\n  define connector influx_out from tcp_client\n  with\n    # define metrics interval\n    metrics_interval_s = 5,\n    # we use the influx codec here as well\n    codec = "influx",\n    # define the postprocessors, we use separate to seperate events by lines\n    postprocessors = ["separate"],\n    config = {\n      "url": "questdb:9009",\n    },\n  end;\n')),(0,r.yg)("p",null,"We also need to replace some column names to conform to quest db constraints, we do this\nthrough the ",(0,r.yg)("inlineCode",{parentName:"p"},"re::replace_all")," regular expression from tremor's standard library for convenience."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-troy"},'    # We change the structure of our event to be easier digestible for aggregation\n    select {\n        "measurement": re::replace_all("[ :\\\\./]", event.measurement, "_"), # QuestDB limitations\n        "tags": event.tags,\n        "field": group[2],\n        "value": event.fields[group[2]],\n        "timestamp": event.timestamp,\n    }\n    from in\n    group by set(event.measurement, event.tags, each(record::keys(event.fields)))\n    into aggregate\n    having type::is_number(event.value);\n')),(0,r.yg)("p",null,"Now with that set you can grab ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.12/guides/metrics.md/../code/metrics/06_questdb"},"the entire config from github")," and start it with ",(0,r.yg)("inlineCode",{parentName:"p"},"docker-compose up"),"."),(0,r.yg)("p",null,"You can find the grafana UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:3000"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:3000")),".\nYou can find the QuestDB Console UI at ",(0,r.yg)("a",{parentName:"p",href:"http://localhost:9000"},(0,r.yg)("inlineCode",{parentName:"a"},"http://localhost:9000")),"."),(0,r.yg)("p",null,"Note that you need to log in with user ",(0,r.yg)("inlineCode",{parentName:"p"},"admin")," and password ",(0,r.yg)("inlineCode",{parentName:"p"},"admin")," in the Grafana UI."))}u.isMDXComponent=!0}}]);