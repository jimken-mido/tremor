"use strict";(self.webpackChunktremor_website=self.webpackChunktremor_website||[]).push([[5176],{98360:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var a=n(58168),s=(n(96540),n(15680));n(40281);const i={},o="Logstash",r={unversionedId:"recipes/logstash/index",id:"version-0.11/recipes/logstash/index",title:"Logstash",description:"All the application code here is available from the docs git repository.",source:"@site/versioned_docs/version-0.11/recipes/10_logstash/index.md",sourceDirName:"recipes/10_logstash",slug:"/recipes/logstash/",permalink:"/docs/0.11/recipes/logstash/",draft:!1,editUrl:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.11/recipes/10_logstash/index.md",tags:[],version:"0.11",frontMatter:{},sidebar:"version-0.11/tutorialSidebar",previous:{title:"Validate",permalink:"/docs/0.11/recipes/validate/"},next:{title:"Influx",permalink:"/docs/0.11/recipes/influx/"}},l={},c=[{value:"Environment",id:"environment",level:2},{value:"Business Logic",id:"business-logic",level:2},{value:"Command line testing during logic development",id:"command-line-testing-during-logic-development",level:2},{value:"Discussion",id:"discussion",level:3}],d={toc:c},p="wrapper";function h(e){let{components:t,...i}=e;return(0,s.yg)(p,(0,a.A)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,s.yg)("h1",{id:"logstash"},"Logstash"),(0,s.yg)("admonition",{type:"note"},(0,s.yg)("p",{parentName:"admonition"},"All the application code here is available from the docs ",(0,s.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-www/tree/main/versioned_docs/version-0.11/recipes/10_logstash/index.md"},"git repository"),".")),(0,s.yg)("p",null,"This example shows how handling apache logs with a tremor and elastic search could work. The example is a lot more complex than the initial showcases and combines three components."),(0,s.yg)("p",null,"Kibana, which once started with docker-compose can be reached ",(0,s.yg)("a",{parentName:"p",href:"http://localhost:5601"},"locally"),". It allows browsing through the logs. If you have never used Kibana before you can get started by clicking on ",(0,s.yg)("strong",{parentName:"p"},"Management")," then in the ",(0,s.yg)("strong",{parentName:"p"},"Elasticsearch")," section on ",(0,s.yg)("strong",{parentName:"p"},"Index Management"),"."),(0,s.yg)("p",null,"Elastic Search, which stores the logs submitted."),(0,s.yg)("p",null,"Tremor, which takes the apache logs, parses and classifies them then submits them to indexes in elastic search."),(0,s.yg)("p",null,"In addition the file ",(0,s.yg)("inlineCode",{parentName:"p"},"demo/data/apache_access_logs.xz")," ",(0,s.yg)("a",{parentName:"p",href:"https://github.com/tremor-rs/tremor-runtime/tree/main/demo/data"},"Link")," is used as example payload."),(0,s.yg)("h2",{id:"environment"},"Environment"),(0,s.yg)("p",null,"In the ",(0,s.yg)("a",{target:"_blank",href:n(65141).A},(0,s.yg)("code",null,"example.trickle"))," we define scripts that ",(0,s.yg)("inlineCode",{parentName:"p"},"extract")," and ",(0,s.yg)("inlineCode",{parentName:"p"},"categorize")," apache logs. Any log that is not conforming ther predefined format will be dropped. All other configuration is the same as per the previous example and is elided here for brevity."),(0,s.yg)("h2",{id:"business-logic"},"Business Logic"),(0,s.yg)("pre",null,(0,s.yg)("code",{parentName:"pre",className:"language-trickle"},'define script extract                                                          # define the script that parses our apache logs\nscript\n  match {"raw": event} of                                                      # we use the dissect extractor to parse the apache log\n    case r = %{ raw ~= dissect|%{ip} %{} %{} [%{timestamp}] "%{method} %{path} %{proto}" %{code:int} %{cost:int}\\\\n| }\n            => r.raw                                                           # this first case is hit if the log includes an execution time (cost) for the request\n    case r = %{ raw ~= dissect|%{ip} %{} %{} [%{timestamp}] "%{method} %{path} %{proto}" %{code:int} %{}\\\\n| }\n            => r.raw\n    default => emit => "bad"\n  end\nend;\n\n')),(0,s.yg)("pre",null,(0,s.yg)("code",{parentName:"pre",className:"language-trickle"},'define script categorize                                                       # define the script that classifies the logs\nwith\n  user_error_index = "errors",                                                 # we use "with" here to default some configuration for\n  server_error_index = "errors",                                               # the script, we could then re-use this script in multiple\n  ok_index = "requests",                                                       # places with different indexes\n  other_index = "requests"\nscript\n  let $doc_type = "log";                                                      # doc_type is used by the offramp, the $ denotes this is stored in event metadata\n  let $index = match event of\n    case e = %{present code} when e.code >= 200 and e.code < 400              # for http codes between 200 and 400 (exclusive) - those are success codes\n      => args.ok_index\n    case e = %{present code} when e.code >= 400 and e.code < 500              # 400 to 500 (exclusive) are client side errors\n      => args.user_error_index\n    case e = %{present code} when e.code >= 500 and e.code < 600\n      => args.server_error_index                                              # 500 to 500 (exclusive) are server side errors\n    default => args.other_index                                               # if we get any other code we just use a default index\n  end;\n  event                                                                       # emit the event with it\'s new metadata\nend;\n')),(0,s.yg)("h2",{id:"command-line-testing-during-logic-development"},"Command line testing during logic development"),(0,s.yg)("pre",null,(0,s.yg)("code",{parentName:"pre",className:"language-bash"},"$ docker-compose up\n  ... lots of logs ...\n")),(0,s.yg)("p",null,"Inject test messages via ",(0,s.yg)("a",{parentName:"p",href:"https://github.com/vi/websocat"},"websocat")),(0,s.yg)("admonition",{type:"note"},(0,s.yg)("p",{parentName:"admonition"},"Can be installed via ",(0,s.yg)("inlineCode",{parentName:"p"},"cargo install websocat")," for the lazy/impatient amongst us")),(0,s.yg)("pre",null,(0,s.yg)("code",{parentName:"pre",className:"language-bash"},"$ xzcat logs.xz | websocat ws://localhost:4242\n...\n")),(0,s.yg)("p",null,"Open the ",(0,s.yg)("a",{parentName:"p",href:"http://localhost:5601/app/kibana#/management/kibana/indices/"},"Kibana index management")," and create indexes to view the data."),(0,s.yg)("h3",{id:"discussion"},"Discussion"),(0,s.yg)("p",null,"This is a fairly complex example that combines everything we've seen in the prior examples and a bit more. It should serve as a starting point of how to use tremor to ingest, process, filter and classify data with tremor into an upstream system."),(0,s.yg)("admonition",{type:"tip"},(0,s.yg)("p",{parentName:"admonition"},"When using this as a baseline be aware that around things like batching tuning will be involved to make the numbers fit with the infrastructure it is pointed at. Also since it is not an ongoing data stream we omitted backpressure or classification based rate limiting from the example.")))}h.isMDXComponent=!0},65141:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/files/example-5e9e4c6571f63302b4ea5365f6200347.trickle"}}]);